{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "zi9TMpLm4tRy",
    "XFYdSgrG4ljq",
    "zMH_HKa545qh",
    "cSv-GMFs5RCy",
    "Ffug_y2zIzDX",
    "_PL810rqpkER",
    "dT8aHcTIpNRK",
    "-EhSLsB6p1mY",
    "VUqjM4d_-O33",
    "tzR0x4iy-UnG",
    "2tbwhug1ZlJS",
    "ar5VpKpobcPa",
    "4_palmjLii_x"
   ],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## **Installations**"
   ],
   "metadata": {
    "id": "zi9TMpLm4tRy",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install torchaudio\n",
    "!pip install torch-geometric"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rF8Ncxhu7vJm",
    "outputId": "2ed3331d-3454-4a03-cd78-203b61ea017a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.2.0-cp39-cp39-win_amd64.whl (198.5 MB)\n",
      "                                              0.0/198.5 MB ? eta -:--:--\n",
      "                                              0.0/198.5 MB ? eta -:--:--\n",
      "                                              0.0/198.5 MB ? eta -:--:--\n",
      "                                              0.0/198.5 MB ? eta -:--:--\n",
      "                                              0.0/198.5 MB ? eta -:--:--\n",
      "                                              0.0/198.5 MB ? eta -:--:--\n",
      "                                              0.0/198.5 MB ? eta -:--:--\n",
      "                                              0.0/198.5 MB ? eta -:--:--\n",
      "                                              0.0/198.5 MB ? eta -:--:--\n",
      "                                              0.0/198.5 MB ? eta -:--:--\n",
      "                                              0.0/198.5 MB ? eta -:--:--\n",
      "                                              0.0/198.5 MB ? eta -:--:--\n",
      "                                              0.0/198.5 MB ? eta -:--:--\n",
      "                                              0.0/198.5 MB ? eta -:--:--\n",
      "                                             0.0/198.5 MB 30.5 kB/s eta 1:48:33\n",
      "                                             0.1/198.5 MB 83.7 kB/s eta 0:39:31\n",
      "                                            0.1/198.5 MB 107.1 kB/s eta 0:30:53\n",
      "                                            0.1/198.5 MB 126.1 kB/s eta 0:26:14\n",
      "                                            0.1/198.5 MB 128.7 kB/s eta 0:25:42\n",
      "                                            0.1/198.5 MB 128.7 kB/s eta 0:25:42\n",
      "                                            0.1/198.5 MB 142.1 kB/s eta 0:23:17\n",
      "                                            0.2/198.5 MB 143.4 kB/s eta 0:23:04\n",
      "                                            0.2/198.5 MB 158.9 kB/s eta 0:20:49\n",
      "                                            0.2/198.5 MB 171.0 kB/s eta 0:19:20\n",
      "                                            0.2/198.5 MB 172.9 kB/s eta 0:19:07\n",
      "                                            0.2/198.5 MB 187.3 kB/s eta 0:17:39\n",
      "                                            0.3/198.5 MB 196.6 kB/s eta 0:16:49\n",
      "                                            0.3/198.5 MB 202.9 kB/s eta 0:16:17\n",
      "                                            0.3/198.5 MB 208.2 kB/s eta 0:15:53\n",
      "                                            0.3/198.5 MB 216.0 kB/s eta 0:15:18\n",
      "                                            0.3/198.5 MB 223.2 kB/s eta 0:14:48\n",
      "                                            0.4/198.5 MB 232.1 kB/s eta 0:14:14\n",
      "                                            0.4/198.5 MB 231.7 kB/s eta 0:14:16\n",
      "                                            0.4/198.5 MB 241.8 kB/s eta 0:13:40\n",
      "                                            0.4/198.5 MB 241.2 kB/s eta 0:13:42\n",
      "                                            0.4/198.5 MB 248.9 kB/s eta 0:13:16\n",
      "                                            0.5/198.5 MB 253.9 kB/s eta 0:13:00\n",
      "                                            0.5/198.5 MB 260.0 kB/s eta 0:12:42\n",
      "                                            0.5/198.5 MB 261.1 kB/s eta 0:12:39\n",
      "                                            0.5/198.5 MB 265.5 kB/s eta 0:12:26\n",
      "                                            0.5/198.5 MB 269.6 kB/s eta 0:12:15\n",
      "                                            0.6/198.5 MB 278.7 kB/s eta 0:11:51\n",
      "                                            0.6/198.5 MB 277.3 kB/s eta 0:11:54\n",
      "                                            0.6/198.5 MB 288.7 kB/s eta 0:11:26\n",
      "                                            0.6/198.5 MB 289.1 kB/s eta 0:11:25\n",
      "                                            0.6/198.5 MB 294.5 kB/s eta 0:11:12\n",
      "                                            0.7/198.5 MB 290.9 kB/s eta 0:11:21\n",
      "                                            0.7/198.5 MB 302.9 kB/s eta 0:10:54\n",
      "                                            0.7/198.5 MB 301.2 kB/s eta 0:10:57\n",
      "                                            0.7/198.5 MB 305.9 kB/s eta 0:10:47\n",
      "                                            0.7/198.5 MB 302.2 kB/s eta 0:10:55\n",
      "                                            0.8/198.5 MB 313.1 kB/s eta 0:10:32\n",
      "                                            0.8/198.5 MB 311.3 kB/s eta 0:10:36\n",
      "                                            0.8/198.5 MB 315.8 kB/s eta 0:10:27\n",
      "                                            0.8/198.5 MB 319.9 kB/s eta 0:10:18\n",
      "                                            0.9/198.5 MB 321.9 kB/s eta 0:10:14\n",
      "                                            0.9/198.5 MB 320.1 kB/s eta 0:10:18\n",
      "                                            0.9/198.5 MB 322.2 kB/s eta 0:10:14\n",
      "                                            0.9/198.5 MB 325.8 kB/s eta 0:10:07\n",
      "                                            0.9/198.5 MB 327.8 kB/s eta 0:10:03\n",
      "                                            1.0/198.5 MB 331.2 kB/s eta 0:09:57\n",
      "                                            1.0/198.5 MB 332.9 kB/s eta 0:09:54\n",
      "                                            1.0/198.5 MB 334.5 kB/s eta 0:09:51\n",
      "                                            1.0/198.5 MB 339.4 kB/s eta 0:09:42\n",
      "                                            1.1/198.5 MB 342.7 kB/s eta 0:09:37\n",
      "                                            1.1/198.5 MB 342.5 kB/s eta 0:09:37\n",
      "                                            1.1/198.5 MB 343.8 kB/s eta 0:09:35\n",
      "                                            1.1/198.5 MB 346.8 kB/s eta 0:09:30\n",
      "                                            1.1/198.5 MB 349.7 kB/s eta 0:09:25\n",
      "                                            1.2/198.5 MB 350.8 kB/s eta 0:09:23\n",
      "                                            1.2/198.5 MB 350.6 kB/s eta 0:09:23\n",
      "                                            1.2/198.5 MB 353.4 kB/s eta 0:09:19\n",
      "                                            1.2/198.5 MB 355.9 kB/s eta 0:09:15\n",
      "                                            1.3/198.5 MB 358.3 kB/s eta 0:09:11\n",
      "                                            1.3/198.5 MB 359.3 kB/s eta 0:09:09\n",
      "                                            1.3/198.5 MB 361.9 kB/s eta 0:09:05\n",
      "                                            1.3/198.5 MB 364.1 kB/s eta 0:09:02\n",
      "                                            1.3/198.5 MB 364.1 kB/s eta 0:09:02\n",
      "                                            1.4/198.5 MB 363.2 kB/s eta 0:09:03\n",
      "                                            1.4/198.5 MB 366.8 kB/s eta 0:08:58\n",
      "                                            1.4/198.5 MB 366.8 kB/s eta 0:08:58\n",
      "                                            1.4/198.5 MB 365.9 kB/s eta 0:08:59\n",
      "                                            1.5/198.5 MB 368.1 kB/s eta 0:08:56\n",
      "                                            1.5/198.5 MB 370.4 kB/s eta 0:08:52\n",
      "                                            1.5/198.5 MB 372.4 kB/s eta 0:08:50\n",
      "                                            1.5/198.5 MB 374.1 kB/s eta 0:08:47\n",
      "                                            1.6/198.5 MB 374.8 kB/s eta 0:08:46\n",
      "                                            1.6/198.5 MB 373.1 kB/s eta 0:08:48\n",
      "                                            1.6/198.5 MB 376.3 kB/s eta 0:08:44\n",
      "                                            1.6/198.5 MB 376.3 kB/s eta 0:08:44\n",
      "                                            1.6/198.5 MB 376.5 kB/s eta 0:08:43\n",
      "                                            1.7/198.5 MB 378.2 kB/s eta 0:08:41\n",
      "                                            1.7/198.5 MB 380.2 kB/s eta 0:08:38\n",
      "                                            1.7/198.5 MB 378.5 kB/s eta 0:08:40\n",
      "                                            1.7/198.5 MB 382.3 kB/s eta 0:08:35\n",
      "                                            1.7/198.5 MB 381.9 kB/s eta 0:08:36\n",
      "                                            1.8/198.5 MB 383.8 kB/s eta 0:08:33\n",
      "                                            1.8/198.5 MB 384.0 kB/s eta 0:08:33\n",
      "                                            1.8/198.5 MB 384.5 kB/s eta 0:08:32\n",
      "                                            1.8/198.5 MB 385.4 kB/s eta 0:08:31\n",
      "                                            1.9/198.5 MB 385.5 kB/s eta 0:08:31\n",
      "                                            1.9/198.5 MB 388.1 kB/s eta 0:08:27\n",
      "                                            1.9/198.5 MB 389.9 kB/s eta 0:08:25\n",
      "                                            1.9/198.5 MB 387.0 kB/s eta 0:08:29\n",
      "                                            1.9/198.5 MB 388.7 kB/s eta 0:08:26\n",
      "                                            2.0/198.5 MB 391.2 kB/s eta 0:08:23\n",
      "                                            2.0/198.5 MB 391.2 kB/s eta 0:08:23\n",
      "                                            2.0/198.5 MB 392.8 kB/s eta 0:08:21\n",
      "                                            2.0/198.5 MB 392.5 kB/s eta 0:08:21\n",
      "                                            2.0/198.5 MB 392.5 kB/s eta 0:08:21\n",
      "                                            2.0/198.5 MB 390.5 kB/s eta 0:08:24\n",
      "                                            2.1/198.5 MB 394.4 kB/s eta 0:08:19\n",
      "                                            2.1/198.5 MB 394.0 kB/s eta 0:08:19\n",
      "                                            2.1/198.5 MB 393.3 kB/s eta 0:08:20\n",
      "                                            2.2/198.5 MB 394.7 kB/s eta 0:08:18\n",
      "                                            2.2/198.5 MB 395.9 kB/s eta 0:08:16\n",
      "                                            2.2/198.5 MB 395.5 kB/s eta 0:08:17\n",
      "                                            2.2/198.5 MB 395.8 kB/s eta 0:08:16\n",
      "                                            2.2/198.5 MB 396.9 kB/s eta 0:08:15\n",
      "                                            2.3/198.5 MB 399.4 kB/s eta 0:08:12\n",
      "                                            2.3/198.5 MB 396.8 kB/s eta 0:08:15\n",
      "                                            2.3/198.5 MB 400.7 kB/s eta 0:08:10\n",
      "                                            2.3/198.5 MB 400.7 kB/s eta 0:08:10\n",
      "                                            2.3/198.5 MB 400.7 kB/s eta 0:08:10\n",
      "                                            2.4/198.5 MB 401.6 kB/s eta 0:08:09\n",
      "                                            2.4/198.5 MB 401.6 kB/s eta 0:08:09\n",
      "                                            2.4/198.5 MB 401.6 kB/s eta 0:08:09\n",
      "                                            2.4/198.5 MB 396.3 kB/s eta 0:08:15\n",
      "                                            2.4/198.5 MB 397.6 kB/s eta 0:08:14\n",
      "                                            2.5/198.5 MB 398.6 kB/s eta 0:08:12\n",
      "                                            2.5/198.5 MB 398.9 kB/s eta 0:08:12\n",
      "                                            2.5/198.5 MB 398.5 kB/s eta 0:08:12\n",
      "                                            2.5/198.5 MB 401.1 kB/s eta 0:08:09\n",
      "                                            2.5/198.5 MB 402.3 kB/s eta 0:08:08\n",
      "                                            2.6/198.5 MB 402.0 kB/s eta 0:08:08\n",
      "                                            2.6/198.5 MB 403.4 kB/s eta 0:08:06\n",
      "                                            2.6/198.5 MB 403.1 kB/s eta 0:08:07\n",
      "                                            2.6/198.5 MB 403.9 kB/s eta 0:08:05\n",
      "                                            2.7/198.5 MB 404.2 kB/s eta 0:08:05\n",
      "                                            2.7/198.5 MB 405.9 kB/s eta 0:08:03\n",
      "                                            2.7/198.5 MB 407.1 kB/s eta 0:08:01\n",
      "                                            2.7/198.5 MB 407.9 kB/s eta 0:08:00\n",
      "                                            2.8/198.5 MB 409.1 kB/s eta 0:07:59\n",
      "                                            2.8/198.5 MB 409.8 kB/s eta 0:07:58\n",
      "                                            2.8/198.5 MB 409.4 kB/s eta 0:07:58\n",
      "                                            2.8/198.5 MB 410.6 kB/s eta 0:07:57\n",
      "                                            2.9/198.5 MB 413.3 kB/s eta 0:07:54\n",
      "                                            2.9/198.5 MB 412.9 kB/s eta 0:07:54\n",
      "                                            2.9/198.5 MB 415.1 kB/s eta 0:07:52\n",
      "                                            2.9/198.5 MB 414.7 kB/s eta 0:07:52\n",
      "                                            3.0/198.5 MB 416.3 kB/s eta 0:07:50\n",
      "                                            3.0/198.5 MB 417.3 kB/s eta 0:07:49\n",
      "                                            3.0/198.5 MB 419.9 kB/s eta 0:07:46\n",
      "                                            3.1/198.5 MB 421.4 kB/s eta 0:07:44\n",
      "                                            3.1/198.5 MB 421.4 kB/s eta 0:07:44\n",
      "                                            3.1/198.5 MB 421.1 kB/s eta 0:07:44\n",
      "                                            3.2/198.5 MB 424.5 kB/s eta 0:07:41\n",
      "                                            3.2/198.5 MB 424.5 kB/s eta 0:07:41\n",
      "                                            3.2/198.5 MB 423.7 kB/s eta 0:07:42\n",
      "                                            3.2/198.5 MB 425.6 kB/s eta 0:07:39\n",
      "                                            3.2/198.5 MB 426.6 kB/s eta 0:07:38\n",
      "                                            3.3/198.5 MB 428.0 kB/s eta 0:07:37\n",
      "                                            3.3/198.5 MB 429.4 kB/s eta 0:07:35\n",
      "                                            3.3/198.5 MB 430.7 kB/s eta 0:07:34\n",
      "                                            3.4/198.5 MB 431.7 kB/s eta 0:07:33\n",
      "                                            3.4/198.5 MB 433.0 kB/s eta 0:07:31\n",
      "                                            3.4/198.5 MB 433.9 kB/s eta 0:07:30\n",
      "                                            3.5/198.5 MB 434.8 kB/s eta 0:07:29\n",
      "                                            3.5/198.5 MB 437.4 kB/s eta 0:07:26\n",
      "                                            3.5/198.5 MB 439.0 kB/s eta 0:07:25\n",
      "                                            3.6/198.5 MB 440.3 kB/s eta 0:07:23\n",
      "                                            3.6/198.5 MB 442.4 kB/s eta 0:07:21\n",
      "                                            3.6/198.5 MB 443.6 kB/s eta 0:07:20\n",
      "                                            3.7/198.5 MB 444.0 kB/s eta 0:07:19\n",
      "                                            3.7/198.5 MB 447.3 kB/s eta 0:07:16\n",
      "                                            3.7/198.5 MB 447.6 kB/s eta 0:07:16\n",
      "                                            3.8/198.5 MB 446.7 kB/s eta 0:07:16\n",
      "                                            3.8/198.5 MB 452.3 kB/s eta 0:07:11\n",
      "                                            3.8/198.5 MB 451.1 kB/s eta 0:07:12\n",
      "                                            3.9/198.5 MB 454.2 kB/s eta 0:07:09\n",
      "                                            3.9/198.5 MB 455.3 kB/s eta 0:07:08\n",
      "                                            4.0/198.5 MB 457.9 kB/s eta 0:07:05\n",
      "                                            4.0/198.5 MB 459.9 kB/s eta 0:07:04\n",
      "                                            4.0/198.5 MB 459.3 kB/s eta 0:07:04\n",
      "                                            4.0/198.5 MB 461.9 kB/s eta 0:07:01\n",
      "                                            4.1/198.5 MB 466.8 kB/s eta 0:06:57\n",
      "                                            4.1/198.5 MB 465.5 kB/s eta 0:06:58\n",
      "                                            4.2/198.5 MB 466.5 kB/s eta 0:06:57\n",
      "                                            4.2/198.5 MB 469.4 kB/s eta 0:06:54\n",
      "                                            4.2/198.5 MB 471.6 kB/s eta 0:06:52\n",
      "                                            4.3/198.5 MB 471.4 kB/s eta 0:06:53\n",
      "                                            4.3/198.5 MB 475.7 kB/s eta 0:06:49\n",
      "                                            4.4/198.5 MB 478.1 kB/s eta 0:06:47\n",
      "                                            4.4/198.5 MB 478.7 kB/s eta 0:06:46\n",
      "                                            4.4/198.5 MB 481.0 kB/s eta 0:06:44\n",
      "                                            4.5/198.5 MB 483.0 kB/s eta 0:06:42\n",
      "                                            4.5/198.5 MB 486.0 kB/s eta 0:06:40\n",
      "                                            4.6/198.5 MB 486.9 kB/s eta 0:06:39\n",
      "                                            4.6/198.5 MB 489.9 kB/s eta 0:06:36\n",
      "                                            4.7/198.5 MB 492.9 kB/s eta 0:06:34\n",
      "                                            4.7/198.5 MB 495.8 kB/s eta 0:06:31\n",
      "                                            4.8/198.5 MB 496.6 kB/s eta 0:06:31\n",
      "                                            4.8/198.5 MB 500.6 kB/s eta 0:06:27\n",
      "                                            4.9/198.5 MB 504.6 kB/s eta 0:06:24\n",
      "                                            4.9/198.5 MB 505.8 kB/s eta 0:06:23\n",
      "                                            5.0/198.5 MB 508.1 kB/s eta 0:06:21\n",
      "                                            5.0/198.5 MB 508.8 kB/s eta 0:06:21\n",
      "                                            5.0/198.5 MB 511.6 kB/s eta 0:06:19\n",
      "                                            5.1/198.5 MB 515.4 kB/s eta 0:06:16\n",
      "                                            5.1/198.5 MB 515.0 kB/s eta 0:06:16\n",
      "                                            5.2/198.5 MB 521.9 kB/s eta 0:06:11\n",
      "     -                                      5.2/198.5 MB 523.3 kB/s eta 0:06:10\n",
      "     -                                      5.3/198.5 MB 523.7 kB/s eta 0:06:09\n",
      "     -                                      5.3/198.5 MB 527.8 kB/s eta 0:06:07\n",
      "     -                                      5.4/198.5 MB 531.2 kB/s eta 0:06:04\n",
      "     -                                      5.4/198.5 MB 530.5 kB/s eta 0:06:04\n",
      "     -                                      5.5/198.5 MB 533.5 kB/s eta 0:06:02\n",
      "     -                                      5.5/198.5 MB 535.0 kB/s eta 0:06:01\n",
      "     -                                      5.6/198.5 MB 539.6 kB/s eta 0:05:58\n",
      "     -                                      5.7/198.5 MB 543.0 kB/s eta 0:05:56\n",
      "     -                                      5.7/198.5 MB 545.5 kB/s eta 0:05:54\n",
      "     -                                      5.8/198.5 MB 548.9 kB/s eta 0:05:52\n",
      "     -                                      5.8/198.5 MB 552.2 kB/s eta 0:05:49\n",
      "     -                                      5.9/198.5 MB 558.6 kB/s eta 0:05:45\n",
      "     -                                      6.0/198.5 MB 561.8 kB/s eta 0:05:43\n",
      "     -                                      6.0/198.5 MB 563.1 kB/s eta 0:05:42\n",
      "     -                                      6.0/198.5 MB 563.1 kB/s eta 0:05:42\n",
      "     -                                      6.1/198.5 MB 561.2 kB/s eta 0:05:43\n",
      "     -                                      6.1/198.5 MB 565.4 kB/s eta 0:05:41\n",
      "     -                                      6.2/198.5 MB 575.0 kB/s eta 0:05:35\n",
      "     -                                      6.3/198.5 MB 572.7 kB/s eta 0:05:36\n",
      "     -                                      6.3/198.5 MB 573.1 kB/s eta 0:05:36\n",
      "     -                                      6.4/198.5 MB 577.2 kB/s eta 0:05:33\n",
      "     -                                      6.4/198.5 MB 579.2 kB/s eta 0:05:32\n",
      "     -                                      6.5/198.5 MB 582.5 kB/s eta 0:05:30\n",
      "     -                                      6.6/198.5 MB 588.3 kB/s eta 0:05:27\n",
      "     -                                      6.6/198.5 MB 591.2 kB/s eta 0:05:25\n",
      "     -                                      6.7/198.5 MB 595.2 kB/s eta 0:05:23\n",
      "     -                                      6.8/198.5 MB 600.0 kB/s eta 0:05:20\n",
      "     -                                      6.9/198.5 MB 604.7 kB/s eta 0:05:17\n",
      "     -                                      7.0/198.5 MB 610.3 kB/s eta 0:05:14\n",
      "     -                                      7.0/198.5 MB 612.3 kB/s eta 0:05:13\n",
      "     -                                      7.1/198.5 MB 617.9 kB/s eta 0:05:10\n",
      "     -                                      7.2/198.5 MB 622.5 kB/s eta 0:05:08\n",
      "     -                                      7.3/198.5 MB 629.7 kB/s eta 0:05:04\n",
      "     -                                      7.4/198.5 MB 634.2 kB/s eta 0:05:02\n",
      "     -                                      7.4/198.5 MB 638.7 kB/s eta 0:05:00\n",
      "     -                                      7.5/198.5 MB 640.5 kB/s eta 0:04:59\n",
      "     -                                      7.6/198.5 MB 643.2 kB/s eta 0:04:57\n",
      "     -                                      7.7/198.5 MB 649.3 kB/s eta 0:04:54\n",
      "     -                                      7.8/198.5 MB 655.4 kB/s eta 0:04:52\n",
      "     -                                      7.8/198.5 MB 656.3 kB/s eta 0:04:51\n",
      "     -                                      7.9/198.5 MB 662.2 kB/s eta 0:04:48\n",
      "     -                                      8.0/198.5 MB 663.1 kB/s eta 0:04:48\n",
      "     -                                      8.1/198.5 MB 669.8 kB/s eta 0:04:45\n",
      "     -                                      8.2/198.5 MB 674.0 kB/s eta 0:04:43\n",
      "     -                                      8.2/198.5 MB 675.6 kB/s eta 0:04:42\n",
      "     -                                      8.3/198.5 MB 684.0 kB/s eta 0:04:39\n",
      "     -                                      8.4/198.5 MB 687.3 kB/s eta 0:04:37\n",
      "     -                                      8.4/198.5 MB 688.8 kB/s eta 0:04:36\n",
      "     -                                      8.6/198.5 MB 693.6 kB/s eta 0:04:34\n",
      "     -                                      8.6/198.5 MB 697.6 kB/s eta 0:04:33\n",
      "     -                                      8.7/198.5 MB 704.1 kB/s eta 0:04:30\n",
      "     -                                      8.8/198.5 MB 706.3 kB/s eta 0:04:29\n",
      "     -                                      8.9/198.5 MB 707.8 kB/s eta 0:04:28\n",
      "     -                                      8.9/198.5 MB 710.0 kB/s eta 0:04:28\n",
      "     -                                      9.0/198.5 MB 713.9 kB/s eta 0:04:26\n",
      "     -                                      9.1/198.5 MB 717.8 kB/s eta 0:04:24\n",
      "     -                                      9.1/198.5 MB 719.2 kB/s eta 0:04:24\n",
      "     -                                      9.2/198.5 MB 723.7 kB/s eta 0:04:22\n",
      "     -                                      9.3/198.5 MB 723.5 kB/s eta 0:04:22\n",
      "     -                                      9.3/198.5 MB 727.2 kB/s eta 0:04:21\n",
      "     -                                      9.4/198.5 MB 730.1 kB/s eta 0:04:19\n",
      "     -                                      9.5/198.5 MB 733.8 kB/s eta 0:04:18\n",
      "     -                                      9.5/198.5 MB 732.8 kB/s eta 0:04:18\n",
      "     -                                      9.5/198.5 MB 732.8 kB/s eta 0:04:18\n",
      "     -                                      9.7/198.5 MB 738.5 kB/s eta 0:04:16\n",
      "     -                                      9.7/198.5 MB 742.9 kB/s eta 0:04:15\n",
      "     -                                      9.8/198.5 MB 747.3 kB/s eta 0:04:13\n",
      "     -                                      9.8/198.5 MB 747.3 kB/s eta 0:04:13\n",
      "     -                                      9.9/198.5 MB 747.5 kB/s eta 0:04:13\n",
      "     -                                     10.0/198.5 MB 750.8 kB/s eta 0:04:12\n",
      "     -                                     10.1/198.5 MB 752.9 kB/s eta 0:04:11\n",
      "     -                                     10.1/198.5 MB 757.1 kB/s eta 0:04:09\n",
      "     -                                     10.2/198.5 MB 760.5 kB/s eta 0:04:08\n",
      "     -                                     10.3/198.5 MB 801.3 kB/s eta 0:03:55\n",
      "     -                                     10.3/198.5 MB 805.3 kB/s eta 0:03:54\n",
      "     -                                     10.4/198.5 MB 816.4 kB/s eta 0:03:51\n",
      "     -                                     10.5/198.5 MB 821.5 kB/s eta 0:03:49\n",
      "     -                                     10.5/198.5 MB 827.6 kB/s eta 0:03:48\n",
      "     -                                     10.6/198.5 MB 843.7 kB/s eta 0:03:43\n",
      "     -                                     10.6/198.5 MB 844.8 kB/s eta 0:03:43\n",
      "     --                                    10.8/198.5 MB 861.5 kB/s eta 0:03:38\n",
      "     --                                    10.8/198.5 MB 869.4 kB/s eta 0:03:36\n",
      "     --                                    10.9/198.5 MB 869.4 kB/s eta 0:03:36\n",
      "     --                                    11.0/198.5 MB 888.3 kB/s eta 0:03:32\n",
      "     --                                    11.0/198.5 MB 893.2 kB/s eta 0:03:30\n",
      "     --                                    11.1/198.5 MB 895.6 kB/s eta 0:03:30\n",
      "     --                                    11.2/198.5 MB 909.3 kB/s eta 0:03:27\n",
      "     --                                    11.2/198.5 MB 914.4 kB/s eta 0:03:25\n",
      "     --                                    11.3/198.5 MB 920.9 kB/s eta 0:03:24\n",
      "     --                                    11.4/198.5 MB 927.3 kB/s eta 0:03:22\n",
      "     --                                    11.4/198.5 MB 935.3 kB/s eta 0:03:21\n",
      "     --                                    11.5/198.5 MB 944.8 kB/s eta 0:03:18\n",
      "     --                                    11.6/198.5 MB 959.9 kB/s eta 0:03:15\n",
      "     --                                    11.6/198.5 MB 968.5 kB/s eta 0:03:13\n",
      "     --                                    11.7/198.5 MB 981.6 kB/s eta 0:03:11\n",
      "     --                                    11.8/198.5 MB 999.6 kB/s eta 0:03:07\n",
      "     --                                      11.9/198.5 MB 1.0 MB/s eta 0:03:07\n",
      "     --                                      12.0/198.5 MB 1.0 MB/s eta 0:03:05\n",
      "     --                                      12.0/198.5 MB 1.0 MB/s eta 0:03:03\n",
      "     --                                      12.1/198.5 MB 1.0 MB/s eta 0:03:03\n",
      "     --                                      12.1/198.5 MB 1.0 MB/s eta 0:03:01\n",
      "     --                                      12.2/198.5 MB 1.0 MB/s eta 0:02:59\n",
      "     --                                      12.2/198.5 MB 1.1 MB/s eta 0:02:58\n",
      "     --                                      12.3/198.5 MB 1.1 MB/s eta 0:02:55\n",
      "     --                                      12.4/198.5 MB 1.1 MB/s eta 0:02:54\n",
      "     --                                      12.5/198.5 MB 1.1 MB/s eta 0:02:51\n",
      "     --                                      12.5/198.5 MB 1.1 MB/s eta 0:02:49\n",
      "     --                                      12.6/198.5 MB 1.1 MB/s eta 0:02:47\n",
      "     --                                      12.6/198.5 MB 1.1 MB/s eta 0:02:45\n",
      "     --                                      12.7/198.5 MB 1.1 MB/s eta 0:02:43\n",
      "     --                                      12.7/198.5 MB 1.1 MB/s eta 0:02:43\n",
      "     --                                      12.9/198.5 MB 1.2 MB/s eta 0:02:38\n",
      "     --                                      13.0/198.5 MB 1.2 MB/s eta 0:02:36\n",
      "     --                                      13.0/198.5 MB 1.2 MB/s eta 0:02:35\n",
      "     --                                      13.1/198.5 MB 1.2 MB/s eta 0:02:33\n",
      "     --                                      13.2/198.5 MB 1.2 MB/s eta 0:02:32\n",
      "     --                                      13.3/198.5 MB 1.2 MB/s eta 0:02:30\n",
      "     --                                      13.4/198.5 MB 1.3 MB/s eta 0:02:28\n",
      "     --                                      13.5/198.5 MB 1.3 MB/s eta 0:02:26\n",
      "     --                                      13.5/198.5 MB 1.3 MB/s eta 0:02:24\n",
      "     --                                      13.6/198.5 MB 1.3 MB/s eta 0:02:23\n",
      "     --                                      13.6/198.5 MB 1.3 MB/s eta 0:02:22\n",
      "     --                                      13.7/198.5 MB 1.3 MB/s eta 0:02:22\n",
      "     --                                      13.8/198.5 MB 1.3 MB/s eta 0:02:20\n",
      "     --                                      13.9/198.5 MB 1.3 MB/s eta 0:02:20\n",
      "     --                                      14.0/198.5 MB 1.4 MB/s eta 0:02:17\n",
      "     --                                      14.1/198.5 MB 1.4 MB/s eta 0:02:16\n",
      "     --                                      14.1/198.5 MB 1.4 MB/s eta 0:02:15\n",
      "     --                                      14.2/198.5 MB 1.4 MB/s eta 0:02:13\n",
      "     --                                      14.3/198.5 MB 1.4 MB/s eta 0:02:13\n",
      "     --                                      14.4/198.5 MB 1.4 MB/s eta 0:02:11\n",
      "     --                                      14.5/198.5 MB 1.4 MB/s eta 0:02:09\n",
      "     --                                      14.6/198.5 MB 1.4 MB/s eta 0:02:08\n",
      "     --                                      14.7/198.5 MB 1.5 MB/s eta 0:02:07\n",
      "     --                                      14.8/198.5 MB 1.5 MB/s eta 0:02:06\n",
      "     --                                      14.9/198.5 MB 1.5 MB/s eta 0:02:05\n",
      "     --                                      15.0/198.5 MB 1.5 MB/s eta 0:02:04\n",
      "     --                                      15.0/198.5 MB 1.5 MB/s eta 0:02:05\n",
      "     --                                      15.1/198.5 MB 1.5 MB/s eta 0:02:04\n",
      "     --                                      15.2/198.5 MB 1.5 MB/s eta 0:02:03\n",
      "     --                                      15.3/198.5 MB 1.5 MB/s eta 0:02:03\n",
      "     ---                                     15.4/198.5 MB 1.5 MB/s eta 0:02:01\n",
      "     ---                                     15.5/198.5 MB 1.5 MB/s eta 0:02:01\n",
      "     ---                                     15.6/198.5 MB 1.5 MB/s eta 0:02:00\n",
      "     ---                                     15.7/198.5 MB 1.5 MB/s eta 0:01:59\n",
      "     ---                                     15.7/198.5 MB 1.5 MB/s eta 0:01:59\n",
      "     ---                                     15.8/198.5 MB 1.6 MB/s eta 0:01:58\n",
      "     ---                                     15.9/198.5 MB 1.6 MB/s eta 0:01:58\n",
      "     ---                                     16.0/198.5 MB 1.6 MB/s eta 0:01:57\n",
      "     ---                                     16.1/198.5 MB 1.6 MB/s eta 0:01:57\n",
      "     ---                                     16.2/198.5 MB 1.6 MB/s eta 0:01:56\n",
      "     ---                                     16.3/198.5 MB 1.6 MB/s eta 0:01:53\n",
      "     ---                                     16.3/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ---                                     16.4/198.5 MB 1.6 MB/s eta 0:01:55\n",
      "     ---                                     16.5/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ---                                     16.6/198.5 MB 1.6 MB/s eta 0:01:53\n",
      "     ---                                     16.6/198.5 MB 1.6 MB/s eta 0:01:53\n",
      "     ---                                     16.7/198.5 MB 1.6 MB/s eta 0:01:53\n",
      "     ---                                     16.8/198.5 MB 1.6 MB/s eta 0:01:53\n",
      "     ---                                     16.9/198.5 MB 1.6 MB/s eta 0:01:53\n",
      "     ---                                     16.9/198.5 MB 1.6 MB/s eta 0:01:53\n",
      "     ---                                     17.0/198.5 MB 1.6 MB/s eta 0:01:53\n",
      "     ---                                     17.0/198.5 MB 1.6 MB/s eta 0:01:53\n",
      "     ---                                     17.1/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ---                                     17.2/198.5 MB 1.6 MB/s eta 0:01:53\n",
      "     ---                                     17.3/198.5 MB 1.6 MB/s eta 0:01:53\n",
      "     ---                                     17.3/198.5 MB 1.6 MB/s eta 0:01:53\n",
      "     ---                                     17.4/198.5 MB 1.6 MB/s eta 0:01:53\n",
      "     ---                                     17.5/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ---                                     17.6/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ---                                     17.7/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ---                                     17.7/198.5 MB 1.6 MB/s eta 0:01:53\n",
      "     ---                                     17.8/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ---                                     17.8/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ---                                     17.9/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ---                                     18.0/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ---                                     18.0/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ---                                     18.1/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ---                                     18.2/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ---                                     18.2/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ---                                     18.3/198.5 MB 1.6 MB/s eta 0:01:55\n",
      "     ---                                     18.4/198.5 MB 1.6 MB/s eta 0:01:55\n",
      "     ---                                     18.4/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ---                                     18.5/198.5 MB 1.6 MB/s eta 0:01:55\n",
      "     ---                                     18.6/198.5 MB 1.6 MB/s eta 0:01:55\n",
      "     ---                                     18.6/198.5 MB 1.6 MB/s eta 0:01:56\n",
      "     ---                                     18.6/198.5 MB 1.6 MB/s eta 0:01:56\n",
      "     ---                                     18.7/198.5 MB 1.6 MB/s eta 0:01:56\n",
      "     ---                                     18.7/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ---                                     18.7/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ---                                     18.8/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ---                                     18.8/198.5 MB 1.5 MB/s eta 0:01:58\n",
      "     ---                                     18.8/198.5 MB 1.5 MB/s eta 0:01:58\n",
      "     ---                                     18.9/198.5 MB 1.5 MB/s eta 0:01:59\n",
      "     ---                                     18.9/198.5 MB 1.5 MB/s eta 0:02:00\n",
      "     ---                                     19.0/198.5 MB 1.5 MB/s eta 0:02:00\n",
      "     ---                                     19.0/198.5 MB 1.5 MB/s eta 0:02:00\n",
      "     ---                                     19.1/198.5 MB 1.5 MB/s eta 0:02:00\n",
      "     ---                                     19.1/198.5 MB 1.5 MB/s eta 0:02:00\n",
      "     ---                                     19.2/198.5 MB 1.5 MB/s eta 0:02:00\n",
      "     ---                                     19.3/198.5 MB 1.5 MB/s eta 0:02:00\n",
      "     ---                                     19.4/198.5 MB 1.5 MB/s eta 0:02:00\n",
      "     ---                                     19.4/198.5 MB 1.5 MB/s eta 0:02:00\n",
      "     ---                                     19.5/198.5 MB 1.5 MB/s eta 0:01:59\n",
      "     ---                                     19.6/198.5 MB 1.5 MB/s eta 0:01:59\n",
      "     ---                                     19.7/198.5 MB 1.5 MB/s eta 0:01:59\n",
      "     ---                                     19.8/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ---                                     19.8/198.5 MB 1.5 MB/s eta 0:01:58\n",
      "     ---                                     19.9/198.5 MB 1.5 MB/s eta 0:01:58\n",
      "     ---                                     20.0/198.5 MB 1.5 MB/s eta 0:01:58\n",
      "     ---                                     20.0/198.5 MB 1.5 MB/s eta 0:01:59\n",
      "     ---                                     20.1/198.5 MB 1.5 MB/s eta 0:01:58\n",
      "     ---                                     20.1/198.5 MB 1.5 MB/s eta 0:01:59\n",
      "     ---                                     20.2/198.5 MB 1.5 MB/s eta 0:01:59\n",
      "     ---                                     20.3/198.5 MB 1.5 MB/s eta 0:01:58\n",
      "     ----                                    20.4/198.5 MB 1.5 MB/s eta 0:01:58\n",
      "     ----                                    20.4/198.5 MB 1.5 MB/s eta 0:01:58\n",
      "     ----                                    20.5/198.5 MB 1.5 MB/s eta 0:01:58\n",
      "     ----                                    20.6/198.5 MB 1.5 MB/s eta 0:01:58\n",
      "     ----                                    20.7/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    20.7/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    20.8/198.5 MB 1.5 MB/s eta 0:01:58\n",
      "     ----                                    20.9/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    20.9/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    21.0/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    21.1/198.5 MB 1.5 MB/s eta 0:01:56\n",
      "     ----                                    21.2/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    21.3/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    21.3/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    21.4/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    21.4/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    21.4/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    21.4/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    21.4/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    21.4/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    21.9/198.5 MB 1.5 MB/s eta 0:01:55\n",
      "     ----                                    22.0/198.5 MB 1.5 MB/s eta 0:01:55\n",
      "     ----                                    22.0/198.5 MB 1.5 MB/s eta 0:01:56\n",
      "     ----                                    22.2/198.5 MB 1.5 MB/s eta 0:01:55\n",
      "     ----                                    22.3/198.5 MB 1.5 MB/s eta 0:01:54\n",
      "     ----                                    22.3/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ----                                    22.3/198.5 MB 1.5 MB/s eta 0:01:55\n",
      "     ----                                    22.5/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ----                                    22.5/198.5 MB 1.5 MB/s eta 0:01:54\n",
      "     ----                                    22.6/198.5 MB 1.6 MB/s eta 0:01:54\n",
      "     ----                                    22.6/198.5 MB 1.5 MB/s eta 0:01:54\n",
      "     ----                                    22.7/198.5 MB 1.5 MB/s eta 0:01:55\n",
      "     ----                                    22.8/198.5 MB 1.5 MB/s eta 0:01:54\n",
      "     ----                                    22.8/198.5 MB 1.5 MB/s eta 0:01:54\n",
      "     ----                                    22.8/198.5 MB 1.5 MB/s eta 0:01:54\n",
      "     ----                                    22.9/198.5 MB 1.5 MB/s eta 0:01:55\n",
      "     ----                                    23.0/198.5 MB 1.5 MB/s eta 0:01:54\n",
      "     ----                                    23.1/198.5 MB 1.5 MB/s eta 0:01:54\n",
      "     ----                                    23.1/198.5 MB 1.5 MB/s eta 0:01:55\n",
      "     ----                                    23.2/198.5 MB 1.5 MB/s eta 0:01:55\n",
      "     ----                                    23.3/198.5 MB 1.5 MB/s eta 0:01:55\n",
      "     ----                                    23.3/198.5 MB 1.5 MB/s eta 0:01:55\n",
      "     ----                                    23.4/198.5 MB 1.5 MB/s eta 0:01:55\n",
      "     ----                                    23.4/198.5 MB 1.5 MB/s eta 0:01:55\n",
      "     ----                                    23.5/198.5 MB 1.5 MB/s eta 0:01:55\n",
      "     ----                                    23.6/198.5 MB 1.5 MB/s eta 0:01:56\n",
      "     ----                                    23.6/198.5 MB 1.5 MB/s eta 0:01:56\n",
      "     ----                                    23.7/198.5 MB 1.5 MB/s eta 0:01:56\n",
      "     ----                                    23.7/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    23.7/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    23.7/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    23.9/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    23.9/198.5 MB 1.5 MB/s eta 0:01:57\n",
      "     ----                                    23.9/198.5 MB 1.5 MB/s eta 0:01:58\n",
      "     ----                                    24.0/198.5 MB 1.5 MB/s eta 0:01:58\n",
      "     ----                                    24.0/198.5 MB 1.5 MB/s eta 0:01:58\n",
      "     ----                                    24.1/198.5 MB 1.5 MB/s eta 0:01:59\n",
      "     ----                                    24.1/198.5 MB 1.5 MB/s eta 0:01:59\n",
      "     ----                                    24.2/198.5 MB 1.5 MB/s eta 0:01:59\n",
      "     ----                                    24.2/198.5 MB 1.5 MB/s eta 0:01:59\n",
      "     ----                                    24.3/198.5 MB 1.5 MB/s eta 0:02:00\n",
      "     ----                                    24.3/198.5 MB 1.5 MB/s eta 0:02:01\n",
      "     ----                                    24.3/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ----                                    24.3/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ----                                    24.4/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ----                                    24.4/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ----                                    24.5/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ----                                    24.6/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ----                                    24.6/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ----                                    24.7/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ----                                    24.7/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ----                                    24.8/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ----                                    24.9/198.5 MB 1.4 MB/s eta 0:02:04\n",
      "     ----                                    24.9/198.5 MB 1.4 MB/s eta 0:02:04\n",
      "     ----                                    25.0/198.5 MB 1.4 MB/s eta 0:02:05\n",
      "     ----                                    25.1/198.5 MB 1.4 MB/s eta 0:02:04\n",
      "     ----                                    25.1/198.5 MB 1.4 MB/s eta 0:02:04\n",
      "     ----                                    25.1/198.5 MB 1.4 MB/s eta 0:02:05\n",
      "     ----                                    25.2/198.5 MB 1.4 MB/s eta 0:02:05\n",
      "     ----                                    25.2/198.5 MB 1.4 MB/s eta 0:02:05\n",
      "     ----                                    25.3/198.5 MB 1.4 MB/s eta 0:02:05\n",
      "     ----                                    25.4/198.5 MB 1.4 MB/s eta 0:02:06\n",
      "     ----                                    25.4/198.5 MB 1.4 MB/s eta 0:02:06\n",
      "     -----                                   25.5/198.5 MB 1.4 MB/s eta 0:02:06\n",
      "     -----                                   25.5/198.5 MB 1.4 MB/s eta 0:02:07\n",
      "     -----                                   25.6/198.5 MB 1.4 MB/s eta 0:02:07\n",
      "     -----                                   25.7/198.5 MB 1.4 MB/s eta 0:02:07\n",
      "     -----                                   25.7/198.5 MB 1.4 MB/s eta 0:02:07\n",
      "     -----                                   25.8/198.5 MB 1.4 MB/s eta 0:02:07\n",
      "     -----                                   25.9/198.5 MB 1.4 MB/s eta 0:02:06\n",
      "     -----                                   26.0/198.5 MB 1.4 MB/s eta 0:02:07\n",
      "     -----                                   26.0/198.5 MB 1.4 MB/s eta 0:02:07\n",
      "     -----                                   26.1/198.5 MB 1.4 MB/s eta 0:02:07\n",
      "     -----                                   26.2/198.5 MB 1.4 MB/s eta 0:02:08\n",
      "     -----                                   26.2/198.5 MB 1.4 MB/s eta 0:02:08\n",
      "     -----                                   26.3/198.5 MB 1.4 MB/s eta 0:02:08\n",
      "     -----                                   26.4/198.5 MB 1.3 MB/s eta 0:02:08\n",
      "     -----                                   26.4/198.5 MB 1.3 MB/s eta 0:02:08\n",
      "     -----                                   26.5/198.5 MB 1.3 MB/s eta 0:02:09\n",
      "     -----                                   26.6/198.5 MB 1.3 MB/s eta 0:02:08\n",
      "     -----                                   26.6/198.5 MB 1.3 MB/s eta 0:02:09\n",
      "     -----                                   26.7/198.5 MB 1.3 MB/s eta 0:02:09\n",
      "     -----                                   26.7/198.5 MB 1.3 MB/s eta 0:02:09\n",
      "     -----                                   26.8/198.5 MB 1.3 MB/s eta 0:02:09\n",
      "     -----                                   26.9/198.5 MB 1.3 MB/s eta 0:02:08\n",
      "     -----                                   26.9/198.5 MB 1.3 MB/s eta 0:02:08\n",
      "     -----                                   27.0/198.5 MB 1.3 MB/s eta 0:02:09\n",
      "     -----                                   27.0/198.5 MB 1.3 MB/s eta 0:02:09\n",
      "     -----                                   27.1/198.5 MB 1.3 MB/s eta 0:02:10\n",
      "     -----                                   27.1/198.5 MB 1.3 MB/s eta 0:02:10\n",
      "     -----                                   27.2/198.5 MB 1.3 MB/s eta 0:02:10\n",
      "     -----                                   27.2/198.5 MB 1.3 MB/s eta 0:02:09\n",
      "     -----                                   27.3/198.5 MB 1.3 MB/s eta 0:02:10\n",
      "     -----                                   27.4/198.5 MB 1.3 MB/s eta 0:02:10\n",
      "     -----                                   27.5/198.5 MB 1.3 MB/s eta 0:02:10\n",
      "     -----                                   27.5/198.5 MB 1.3 MB/s eta 0:02:10\n",
      "     -----                                   27.6/198.5 MB 1.3 MB/s eta 0:02:09\n",
      "     -----                                   27.7/198.5 MB 1.3 MB/s eta 0:02:09\n",
      "     -----                                   27.7/198.5 MB 1.3 MB/s eta 0:02:10\n",
      "     -----                                   27.8/198.5 MB 1.3 MB/s eta 0:02:09\n",
      "     -----                                   27.9/198.5 MB 1.3 MB/s eta 0:02:09\n",
      "     -----                                   28.0/198.5 MB 1.3 MB/s eta 0:02:09\n",
      "     -----                                   28.0/198.5 MB 1.3 MB/s eta 0:02:09\n",
      "     -----                                   28.1/198.5 MB 1.3 MB/s eta 0:02:08\n",
      "     -----                                   28.2/198.5 MB 1.3 MB/s eta 0:02:08\n",
      "     -----                                   28.3/198.5 MB 1.3 MB/s eta 0:02:08\n",
      "     -----                                   28.3/198.5 MB 1.3 MB/s eta 0:02:08\n",
      "     -----                                   28.4/198.5 MB 1.3 MB/s eta 0:02:08\n",
      "     -----                                   28.5/198.5 MB 1.3 MB/s eta 0:02:09\n",
      "     -----                                   28.5/198.5 MB 1.3 MB/s eta 0:02:08\n",
      "     -----                                   28.6/198.5 MB 1.3 MB/s eta 0:02:08\n",
      "     -----                                   28.8/198.5 MB 1.3 MB/s eta 0:02:07\n",
      "     -----                                   28.8/198.5 MB 1.3 MB/s eta 0:02:07\n",
      "     -----                                   28.9/198.5 MB 1.4 MB/s eta 0:02:06\n",
      "     -----                                   29.0/198.5 MB 1.4 MB/s eta 0:02:04\n",
      "     -----                                   29.1/198.5 MB 1.4 MB/s eta 0:02:04\n",
      "     -----                                   29.1/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     -----                                   29.1/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     -----                                   29.3/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     -----                                   29.3/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     -----                                   29.4/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     -----                                   29.5/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     -----                                   29.5/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     -----                                   29.6/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     -----                                   29.7/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     -----                                   29.8/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     -----                                   29.9/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     -----                                   29.9/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     -----                                   30.0/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     -----                                   30.1/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     -----                                   30.1/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     -----                                   30.2/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     -----                                   30.3/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     -----                                   30.4/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     -----                                   30.4/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     -----                                   30.5/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     -----                                   30.5/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ------                                  30.6/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  30.7/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ------                                  30.8/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ------                                  30.8/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  30.9/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  30.9/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ------                                  31.0/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ------                                  31.1/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  31.1/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  31.2/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  31.3/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  31.3/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  31.3/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  31.4/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  31.5/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  31.6/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  31.7/198.5 MB 1.4 MB/s eta 0:01:58\n",
      "     ------                                  31.7/198.5 MB 1.4 MB/s eta 0:01:58\n",
      "     ------                                  31.8/198.5 MB 1.4 MB/s eta 0:01:59\n",
      "     ------                                  31.9/198.5 MB 1.4 MB/s eta 0:02:00\n",
      "     ------                                  31.9/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ------                                  32.0/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ------                                  32.1/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  32.1/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ------                                  32.2/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  32.3/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ------                                  32.3/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ------                                  32.4/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ------                                  32.5/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ------                                  32.5/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ------                                  32.6/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ------                                  32.7/198.5 MB 1.3 MB/s eta 0:02:03\n",
      "     ------                                  32.8/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ------                                  32.8/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ------                                  32.9/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  33.0/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  33.0/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  33.1/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ------                                  33.1/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ------                                  33.1/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ------                                  33.3/198.5 MB 1.4 MB/s eta 0:02:03\n",
      "     ------                                  33.3/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  33.4/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  33.4/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  33.5/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  33.5/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  33.6/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  33.7/198.5 MB 1.3 MB/s eta 0:02:03\n",
      "     ------                                  33.7/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  33.8/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ------                                  33.9/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ------                                  33.9/198.5 MB 1.4 MB/s eta 0:02:00\n",
      "     ------                                  34.0/198.5 MB 1.4 MB/s eta 0:02:00\n",
      "     ------                                  34.0/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ------                                  34.1/198.5 MB 1.4 MB/s eta 0:02:02\n",
      "     ------                                  34.2/198.5 MB 1.4 MB/s eta 0:02:00\n",
      "     ------                                  34.2/198.5 MB 1.4 MB/s eta 0:02:00\n",
      "     ------                                  34.2/198.5 MB 1.4 MB/s eta 0:02:00\n",
      "     ------                                  34.2/198.5 MB 1.4 MB/s eta 0:02:00\n",
      "     ------                                  34.3/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ------                                  34.4/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ------                                  34.4/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ------                                  34.5/198.5 MB 1.4 MB/s eta 0:02:01\n",
      "     ------                                  34.5/198.5 MB 1.4 MB/s eta 0:01:59\n",
      "     ------                                  34.6/198.5 MB 1.4 MB/s eta 0:01:59\n",
      "     ------                                  34.6/198.5 MB 1.4 MB/s eta 0:02:00\n",
      "     ------                                  34.7/198.5 MB 1.4 MB/s eta 0:01:59\n",
      "     ------                                  34.7/198.5 MB 1.4 MB/s eta 0:01:59\n",
      "     ------                                  34.8/198.5 MB 1.4 MB/s eta 0:01:59\n",
      "     ------                                  34.9/198.5 MB 1.4 MB/s eta 0:01:58\n",
      "     ------                                  34.9/198.5 MB 1.4 MB/s eta 0:01:59\n",
      "     ------                                  35.0/198.5 MB 1.4 MB/s eta 0:01:59\n",
      "     ------                                  35.1/198.5 MB 1.4 MB/s eta 0:01:59\n",
      "     ------                                  35.1/198.5 MB 1.4 MB/s eta 0:01:59\n",
      "     ------                                  35.2/198.5 MB 1.4 MB/s eta 0:01:58\n",
      "     ------                                  35.2/198.5 MB 1.4 MB/s eta 0:01:58\n",
      "     ------                                  35.3/198.5 MB 1.4 MB/s eta 0:01:59\n",
      "     ------                                  35.4/198.5 MB 1.4 MB/s eta 0:01:58\n",
      "     ------                                  35.4/198.5 MB 1.4 MB/s eta 0:01:58\n",
      "     ------                                  35.5/198.5 MB 1.4 MB/s eta 0:01:57\n",
      "     ------                                  35.6/198.5 MB 1.4 MB/s eta 0:01:57\n",
      "     -------                                 35.6/198.5 MB 1.4 MB/s eta 0:01:57\n",
      "     -------                                 35.7/198.5 MB 1.4 MB/s eta 0:01:57\n",
      "     -------                                 35.8/198.5 MB 1.4 MB/s eta 0:01:57\n",
      "     -------                                 35.9/198.5 MB 1.4 MB/s eta 0:01:57\n",
      "     -------                                 35.9/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 36.0/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 36.0/198.5 MB 1.4 MB/s eta 0:01:57\n",
      "     -------                                 36.1/198.5 MB 1.4 MB/s eta 0:01:57\n",
      "     -------                                 36.2/198.5 MB 1.4 MB/s eta 0:01:57\n",
      "     -------                                 36.3/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 36.4/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 36.4/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 36.5/198.5 MB 1.4 MB/s eta 0:01:57\n",
      "     -------                                 36.6/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 36.6/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 36.6/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 36.7/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 36.8/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 36.8/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 36.9/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 37.0/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 37.0/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 37.1/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 37.2/198.5 MB 1.4 MB/s eta 0:01:56\n",
      "     -------                                 37.3/198.5 MB 1.4 MB/s eta 0:01:55\n",
      "     -------                                 37.3/198.5 MB 1.4 MB/s eta 0:01:55\n",
      "     -------                                 37.3/198.5 MB 1.4 MB/s eta 0:01:55\n",
      "     -------                                 37.4/198.5 MB 1.4 MB/s eta 0:01:55\n",
      "     -------                                 37.5/198.5 MB 1.4 MB/s eta 0:01:55\n",
      "     -------                                 37.6/198.5 MB 1.4 MB/s eta 0:01:55\n",
      "     -------                                 37.7/198.5 MB 1.4 MB/s eta 0:01:54\n",
      "     -------                                 37.8/198.5 MB 1.4 MB/s eta 0:01:54\n",
      "     -------                                 37.8/198.5 MB 1.4 MB/s eta 0:01:54\n",
      "     -------                                 37.9/198.5 MB 1.4 MB/s eta 0:01:55\n",
      "     -------                                 38.0/198.5 MB 1.4 MB/s eta 0:01:54\n",
      "     -------                                 38.0/198.5 MB 1.4 MB/s eta 0:01:54\n",
      "     -------                                 38.1/198.5 MB 1.4 MB/s eta 0:01:54\n",
      "     -------                                 38.2/198.5 MB 1.4 MB/s eta 0:01:54\n",
      "     -------                                 38.2/198.5 MB 1.4 MB/s eta 0:01:54\n",
      "     -------                                 38.3/198.5 MB 1.4 MB/s eta 0:01:54\n",
      "     -------                                 38.4/198.5 MB 1.4 MB/s eta 0:01:54\n",
      "     -------                                 38.5/198.5 MB 1.4 MB/s eta 0:01:54\n",
      "     -------                                 38.6/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 38.7/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 38.7/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 38.8/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 38.9/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 39.0/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 39.0/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 39.1/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 39.2/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 39.3/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 39.4/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 39.4/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 39.5/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     -------                                 39.5/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     -------                                 39.7/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     -------                                 39.8/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     -------                                 39.8/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     -------                                 39.9/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     -------                                 39.9/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     -------                                 40.0/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     -------                                 40.1/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 40.2/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     -------                                 40.2/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     -------                                 40.2/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 40.3/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     -------                                 40.4/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 40.4/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 40.5/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 40.5/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 40.6/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     -------                                 40.7/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                40.7/198.5 MB 1.4 MB/s eta 0:01:54\n",
      "     --------                                40.8/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                40.9/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                40.9/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                41.0/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                41.0/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                41.1/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                41.2/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                41.2/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                41.3/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                41.4/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                41.4/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                41.4/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                41.5/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                41.6/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                41.7/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                41.7/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                41.8/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                41.9/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                41.9/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                42.0/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                42.0/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                42.1/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                42.2/198.5 MB 1.4 MB/s eta 0:01:51\n",
      "     --------                                42.3/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                42.4/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                42.4/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                42.4/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                42.5/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                42.6/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                42.6/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                42.7/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                42.8/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                42.8/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                42.9/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                43.0/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                43.0/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                43.1/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                43.2/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                43.2/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                43.3/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                43.3/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                43.4/198.5 MB 1.4 MB/s eta 0:01:51\n",
      "     --------                                43.4/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                43.5/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                43.6/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                43.6/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                43.7/198.5 MB 1.4 MB/s eta 0:01:51\n",
      "     --------                                43.8/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                43.8/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                43.9/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                43.9/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                44.0/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                44.1/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                44.2/198.5 MB 1.4 MB/s eta 0:01:51\n",
      "     --------                                44.2/198.5 MB 1.4 MB/s eta 0:01:51\n",
      "     --------                                44.3/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                44.3/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                44.3/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     --------                                44.3/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                44.3/198.5 MB 1.4 MB/s eta 0:01:53\n",
      "     --------                                44.5/198.5 MB 1.4 MB/s eta 0:01:50\n",
      "     --------                                44.5/198.5 MB 1.4 MB/s eta 0:01:51\n",
      "     --------                                44.7/198.5 MB 1.4 MB/s eta 0:01:50\n",
      "     --------                                44.8/198.5 MB 1.4 MB/s eta 0:01:50\n",
      "     --------                                44.9/198.5 MB 1.4 MB/s eta 0:01:49\n",
      "     --------                                44.9/198.5 MB 1.4 MB/s eta 0:01:49\n",
      "     --------                                45.0/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     --------                                45.1/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     --------                                45.1/198.5 MB 1.4 MB/s eta 0:01:49\n",
      "     --------                                45.2/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     --------                                45.3/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     --------                                45.3/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     --------                                45.4/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     --------                                45.5/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     --------                                45.5/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     --------                                45.6/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     --------                                45.7/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     --------                                45.7/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     ---------                               45.8/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     ---------                               45.9/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               45.9/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               46.0/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     ---------                               46.1/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     ---------                               46.1/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               46.2/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     ---------                               46.2/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     ---------                               46.3/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               46.4/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     ---------                               46.4/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     ---------                               46.5/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               46.6/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               46.7/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               46.8/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               46.8/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               46.9/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               46.9/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               46.9/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               47.0/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               47.1/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               47.1/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               47.2/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               47.3/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ---------                               47.3/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     ---------                               47.4/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     ---------                               47.4/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     ---------                               47.4/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     ---------                               47.5/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     ---------                               47.5/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     ---------                               47.6/198.5 MB 1.4 MB/s eta 0:01:48\n",
      "     ---------                               47.6/198.5 MB 1.4 MB/s eta 0:01:49\n",
      "     ---------                               47.7/198.5 MB 1.4 MB/s eta 0:01:49\n",
      "     ---------                               47.7/198.5 MB 1.4 MB/s eta 0:01:49\n",
      "     ---------                               47.7/198.5 MB 1.4 MB/s eta 0:01:50\n",
      "     ---------                               47.7/198.5 MB 1.4 MB/s eta 0:01:50\n",
      "     ---------                               47.8/198.5 MB 1.4 MB/s eta 0:01:51\n",
      "     ---------                               47.9/198.5 MB 1.4 MB/s eta 0:01:50\n",
      "     ---------                               47.9/198.5 MB 1.4 MB/s eta 0:01:51\n",
      "     ---------                               48.0/198.5 MB 1.4 MB/s eta 0:01:51\n",
      "     ---------                               48.1/198.5 MB 1.4 MB/s eta 0:01:51\n",
      "     ---------                               48.1/198.5 MB 1.4 MB/s eta 0:01:51\n",
      "     ---------                               48.1/198.5 MB 1.4 MB/s eta 0:01:51\n",
      "     ---------                               48.2/198.5 MB 1.4 MB/s eta 0:01:52\n",
      "     ---------                               48.3/198.5 MB 1.4 MB/s eta 0:01:51\n",
      "     ---------                               48.3/198.5 MB 1.3 MB/s eta 0:01:52\n",
      "     ---------                               48.4/198.5 MB 1.3 MB/s eta 0:01:52\n",
      "     ---------                               48.4/198.5 MB 1.3 MB/s eta 0:01:52\n",
      "     ---------                               48.5/198.5 MB 1.3 MB/s eta 0:01:52\n",
      "     ---------                               48.6/198.5 MB 1.3 MB/s eta 0:01:52\n",
      "     ---------                               48.6/198.5 MB 1.3 MB/s eta 0:01:52\n",
      "     ---------                               48.7/198.5 MB 1.3 MB/s eta 0:01:52\n",
      "     ---------                               48.7/198.5 MB 1.3 MB/s eta 0:01:52\n",
      "     ---------                               48.8/198.5 MB 1.3 MB/s eta 0:01:53\n",
      "     ---------                               48.8/198.5 MB 1.3 MB/s eta 0:01:53\n",
      "     ---------                               48.9/198.5 MB 1.3 MB/s eta 0:01:53\n",
      "     ---------                               49.0/198.5 MB 1.3 MB/s eta 0:01:53\n",
      "     ---------                               49.0/198.5 MB 1.3 MB/s eta 0:01:53\n",
      "     ---------                               49.1/198.5 MB 1.3 MB/s eta 0:01:53\n",
      "     ---------                               49.1/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ---------                               49.2/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ---------                               49.2/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ---------                               49.3/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ---------                               49.3/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ---------                               49.4/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ---------                               49.5/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ---------                               49.5/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ---------                               49.6/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ---------                               49.7/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ---------                               49.7/198.5 MB 1.3 MB/s eta 0:01:55\n",
      "     ---------                               49.7/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ---------                               49.8/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ---------                               49.8/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ---------                               49.9/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ---------                               50.0/198.5 MB 1.3 MB/s eta 0:01:55\n",
      "     ---------                               50.0/198.5 MB 1.3 MB/s eta 0:01:55\n",
      "     ---------                               50.0/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ---------                               50.1/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ---------                               50.2/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ---------                               50.2/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ---------                               50.3/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ---------                               50.3/198.5 MB 1.3 MB/s eta 0:01:57\n",
      "     ---------                               50.4/198.5 MB 1.3 MB/s eta 0:01:57\n",
      "     ---------                               50.4/198.5 MB 1.3 MB/s eta 0:01:57\n",
      "     ---------                               50.5/198.5 MB 1.3 MB/s eta 0:01:57\n",
      "     ---------                               50.5/198.5 MB 1.3 MB/s eta 0:01:57\n",
      "     ---------                               50.6/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ---------                               50.6/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ---------                               50.6/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ---------                               50.8/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ---------                               50.9/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              50.9/198.5 MB 1.3 MB/s eta 0:01:57\n",
      "     ----------                              51.0/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              51.0/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              51.1/198.5 MB 1.3 MB/s eta 0:01:57\n",
      "     ----------                              51.2/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              51.2/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              51.3/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              51.4/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              51.4/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              51.5/198.5 MB 1.3 MB/s eta 0:01:55\n",
      "     ----------                              51.5/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              51.6/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              51.6/198.5 MB 1.3 MB/s eta 0:01:55\n",
      "     ----------                              51.7/198.5 MB 1.3 MB/s eta 0:01:55\n",
      "     ----------                              51.8/198.5 MB 1.3 MB/s eta 0:01:55\n",
      "     ----------                              51.8/198.5 MB 1.3 MB/s eta 0:01:55\n",
      "     ----------                              51.8/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              51.9/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              52.0/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              52.0/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              52.1/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              52.2/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              52.2/198.5 MB 1.3 MB/s eta 0:01:55\n",
      "     ----------                              52.3/198.5 MB 1.3 MB/s eta 0:01:55\n",
      "     ----------                              52.4/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              52.5/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              52.5/198.5 MB 1.3 MB/s eta 0:01:56\n",
      "     ----------                              52.6/198.5 MB 1.3 MB/s eta 0:01:55\n",
      "     ----------                              52.7/198.5 MB 1.3 MB/s eta 0:01:55\n",
      "     ----------                              52.8/198.5 MB 1.3 MB/s eta 0:01:55\n",
      "     ----------                              52.8/198.5 MB 1.3 MB/s eta 0:01:55\n",
      "     ----------                              52.9/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ----------                              53.0/198.5 MB 1.3 MB/s eta 0:01:55\n",
      "     ----------                              53.1/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ----------                              53.2/198.5 MB 1.3 MB/s eta 0:01:53\n",
      "     ----------                              53.2/198.5 MB 1.3 MB/s eta 0:01:54\n",
      "     ----------                              53.3/198.5 MB 1.3 MB/s eta 0:01:53\n",
      "     ----------                              53.4/198.5 MB 1.3 MB/s eta 0:01:53\n",
      "     ----------                              53.4/198.5 MB 1.3 MB/s eta 0:01:53\n",
      "     ----------                              53.5/198.5 MB 1.3 MB/s eta 0:01:53\n",
      "     ----------                              53.6/198.5 MB 1.3 MB/s eta 0:01:52\n",
      "     ----------                              53.7/198.5 MB 1.3 MB/s eta 0:01:52\n",
      "     ----------                              53.8/198.5 MB 1.3 MB/s eta 0:01:52\n",
      "     ----------                              53.9/198.5 MB 1.3 MB/s eta 0:01:51\n",
      "     ----------                              54.0/198.5 MB 1.3 MB/s eta 0:01:50\n",
      "     ----------                              54.1/198.5 MB 1.3 MB/s eta 0:01:50\n",
      "     ----------                              54.2/198.5 MB 1.3 MB/s eta 0:01:50\n",
      "     ----------                              54.3/198.5 MB 1.3 MB/s eta 0:01:49\n",
      "     ----------                              54.4/198.5 MB 1.3 MB/s eta 0:01:49\n",
      "     ----------                              54.4/198.5 MB 1.3 MB/s eta 0:01:49\n",
      "     ----------                              54.5/198.5 MB 1.4 MB/s eta 0:01:46\n",
      "     ----------                              54.6/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ----------                              54.6/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ----------                              54.7/198.5 MB 1.4 MB/s eta 0:01:47\n",
      "     ----------                              54.9/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     ----------                              54.9/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     ----------                              55.0/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     ----------                              55.1/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     ----------                              55.2/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     ----------                              55.2/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     ----------                              55.3/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     ----------                              55.4/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     ----------                              55.4/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     ----------                              55.5/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     ----------                              55.6/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     ----------                              55.6/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     ----------                              55.7/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ----------                              55.8/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ----------                              55.8/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     ----------                              55.9/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     ----------                              56.0/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             56.0/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     -----------                             56.1/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             56.1/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             56.1/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             56.1/198.5 MB 1.3 MB/s eta 0:01:48\n",
      "     -----------                             56.3/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             56.3/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             56.4/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             56.4/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             56.5/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             56.5/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             56.6/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             56.7/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             56.7/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             56.8/198.5 MB 1.3 MB/s eta 0:01:48\n",
      "     -----------                             56.8/198.5 MB 1.3 MB/s eta 0:01:48\n",
      "     -----------                             56.8/198.5 MB 1.3 MB/s eta 0:01:48\n",
      "     -----------                             56.9/198.5 MB 1.3 MB/s eta 0:01:49\n",
      "     -----------                             57.0/198.5 MB 1.3 MB/s eta 0:01:48\n",
      "     -----------                             57.1/198.5 MB 1.3 MB/s eta 0:01:48\n",
      "     -----------                             57.1/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     -----------                             57.2/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             57.3/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             57.3/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             57.4/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             57.4/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             57.5/198.5 MB 1.3 MB/s eta 0:01:48\n",
      "     -----------                             57.5/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             57.6/198.5 MB 1.3 MB/s eta 0:01:47\n",
      "     -----------                             57.7/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     -----------                             57.8/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     -----------                             57.8/198.5 MB 1.3 MB/s eta 0:01:45\n",
      "     -----------                             57.9/198.5 MB 1.4 MB/s eta 0:01:44\n",
      "     -----------                             58.1/198.5 MB 1.4 MB/s eta 0:01:42\n",
      "     -----------                             58.2/198.5 MB 1.4 MB/s eta 0:01:42\n",
      "     -----------                             58.3/198.5 MB 1.4 MB/s eta 0:01:42\n",
      "     -----------                             58.5/198.5 MB 1.4 MB/s eta 0:01:40\n",
      "     -----------                             58.6/198.5 MB 1.4 MB/s eta 0:01:39\n",
      "     -----------                             58.7/198.5 MB 1.4 MB/s eta 0:01:38\n",
      "     -----------                             58.8/198.5 MB 1.4 MB/s eta 0:01:37\n",
      "     -----------                             58.9/198.5 MB 1.4 MB/s eta 0:01:37\n",
      "     -----------                             58.9/198.5 MB 1.4 MB/s eta 0:01:37\n",
      "     -----------                             59.1/198.5 MB 1.5 MB/s eta 0:01:37\n",
      "     -----------                             59.1/198.5 MB 1.5 MB/s eta 0:01:36\n",
      "     -----------                             59.2/198.5 MB 1.5 MB/s eta 0:01:36\n",
      "     -----------                             59.3/198.5 MB 1.5 MB/s eta 0:01:35\n",
      "     -----------                             59.3/198.5 MB 1.5 MB/s eta 0:01:36\n",
      "     -----------                             59.4/198.5 MB 1.5 MB/s eta 0:01:35\n",
      "     -----------                             59.5/198.5 MB 1.5 MB/s eta 0:01:35\n",
      "     -----------                             59.6/198.5 MB 1.5 MB/s eta 0:01:34\n",
      "     -----------                             59.7/198.5 MB 1.5 MB/s eta 0:01:34\n",
      "     -----------                             59.8/198.5 MB 1.5 MB/s eta 0:01:34\n",
      "     -----------                             59.8/198.5 MB 1.5 MB/s eta 0:01:34\n",
      "     -----------                             60.0/198.5 MB 1.5 MB/s eta 0:01:33\n",
      "     -----------                             60.0/198.5 MB 1.5 MB/s eta 0:01:33\n",
      "     -----------                             60.1/198.5 MB 1.5 MB/s eta 0:01:32\n",
      "     -----------                             60.2/198.5 MB 1.5 MB/s eta 0:01:32\n",
      "     -----------                             60.3/198.5 MB 1.5 MB/s eta 0:01:31\n",
      "     -----------                             60.4/198.5 MB 1.5 MB/s eta 0:01:31\n",
      "     -----------                             60.4/198.5 MB 1.5 MB/s eta 0:01:31\n",
      "     -----------                             60.5/198.5 MB 1.5 MB/s eta 0:01:31\n",
      "     -----------                             60.6/198.5 MB 1.5 MB/s eta 0:01:30\n",
      "     -----------                             60.7/198.5 MB 1.6 MB/s eta 0:01:29\n",
      "     -----------                             60.7/198.5 MB 1.6 MB/s eta 0:01:29\n",
      "     -----------                             60.8/198.5 MB 1.5 MB/s eta 0:01:30\n",
      "     -----------                             60.9/198.5 MB 1.6 MB/s eta 0:01:28\n",
      "     -----------                             60.9/198.5 MB 1.6 MB/s eta 0:01:29\n",
      "     -----------                             61.0/198.5 MB 1.6 MB/s eta 0:01:29\n",
      "     ------------                            61.1/198.5 MB 1.6 MB/s eta 0:01:29\n",
      "     ------------                            61.1/198.5 MB 1.6 MB/s eta 0:01:29\n",
      "     ------------                            61.2/198.5 MB 1.6 MB/s eta 0:01:28\n",
      "     ------------                            61.3/198.5 MB 1.6 MB/s eta 0:01:28\n",
      "     ------------                            61.3/198.5 MB 1.6 MB/s eta 0:01:28\n",
      "     ------------                            61.3/198.5 MB 1.5 MB/s eta 0:01:29\n",
      "     ------------                            61.4/198.5 MB 1.5 MB/s eta 0:01:29\n",
      "     ------------                            61.5/198.5 MB 1.6 MB/s eta 0:01:29\n",
      "     ------------                            61.6/198.5 MB 1.6 MB/s eta 0:01:29\n",
      "     ------------                            61.7/198.5 MB 1.6 MB/s eta 0:01:28\n",
      "     ------------                            61.7/198.5 MB 1.6 MB/s eta 0:01:28\n",
      "     ------------                            61.8/198.5 MB 1.6 MB/s eta 0:01:28\n",
      "     ------------                            61.9/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            62.0/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            62.1/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            62.1/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            62.2/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            62.2/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            62.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            62.4/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            62.5/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            62.5/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            62.5/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            62.6/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            62.7/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            62.7/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            62.8/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            62.9/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            63.0/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            63.1/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            63.2/198.5 MB 1.6 MB/s eta 0:01:25\n",
      "     ------------                            63.3/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            63.3/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            63.4/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            63.4/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            63.4/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            63.4/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            63.6/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            63.6/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            63.7/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            63.8/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            63.9/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.0/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            64.1/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.2/198.5 MB 1.6 MB/s eta 0:01:26\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.3/198.5 MB 1.6 MB/s eta 0:01:27\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.3 MB/s eta 0:01:46\n",
      "     ------------                            64.4/198.5 MB 1.1 MB/s eta 0:01:58\n",
      "     -------------                           66.5/198.5 MB 1.3 MB/s eta 0:01:39\n",
      "     -------------                           66.5/198.5 MB 1.3 MB/s eta 0:01:39\n",
      "     -------------                           66.5/198.5 MB 1.3 MB/s eta 0:01:39\n",
      "     -------------                           66.6/198.5 MB 1.3 MB/s eta 0:01:40\n",
      "     -------------                           66.6/198.5 MB 1.3 MB/s eta 0:01:40\n",
      "     -------------                           66.6/198.5 MB 1.3 MB/s eta 0:01:40\n",
      "     -------------                           66.6/198.5 MB 1.3 MB/s eta 0:01:40\n",
      "     -------------                           66.6/198.5 MB 1.3 MB/s eta 0:01:40\n",
      "     -------------                           66.6/198.5 MB 1.3 MB/s eta 0:01:40\n",
      "     -------------                           66.6/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.3 MB/s eta 0:01:43\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     -------------                           66.7/198.5 MB 1.1 MB/s eta 0:02:00\n",
      "     ------------                          66.8/198.5 MB 978.6 kB/s eta 0:02:15\n",
      "     ------------                          66.8/198.5 MB 978.6 kB/s eta 0:02:15\n",
      "     ------------                          66.8/198.5 MB 978.6 kB/s eta 0:02:15\n",
      "     ------------                          66.8/198.5 MB 972.8 kB/s eta 0:02:16\n",
      "     ------------                          66.9/198.5 MB 975.7 kB/s eta 0:02:15\n",
      "     ------------                          66.9/198.5 MB 975.7 kB/s eta 0:02:15\n",
      "     ------------                          66.9/198.5 MB 968.5 kB/s eta 0:02:16\n",
      "     ------------                          66.9/198.5 MB 968.5 kB/s eta 0:02:16\n",
      "     ------------                          66.9/198.5 MB 968.5 kB/s eta 0:02:16\n",
      "     ------------                          67.0/198.5 MB 961.4 kB/s eta 0:02:17\n",
      "     ------------                          67.0/198.5 MB 961.4 kB/s eta 0:02:17\n",
      "     ------------                          67.0/198.5 MB 961.4 kB/s eta 0:02:17\n",
      "     ------------                          67.0/198.5 MB 947.5 kB/s eta 0:02:19\n",
      "     ------------                          67.0/198.5 MB 946.1 kB/s eta 0:02:19\n",
      "     ------------                          67.0/198.5 MB 951.6 kB/s eta 0:02:19\n",
      "     ------------                          67.1/198.5 MB 947.5 kB/s eta 0:02:19\n",
      "     ------------                          67.1/198.5 MB 943.4 kB/s eta 0:02:20\n",
      "     ------------                          67.1/198.5 MB 939.4 kB/s eta 0:02:20\n",
      "     ------------                          67.1/198.5 MB 936.6 kB/s eta 0:02:21\n",
      "     ------------                          67.2/198.5 MB 934.0 kB/s eta 0:02:21\n",
      "     ------------                          67.2/198.5 MB 934.0 kB/s eta 0:02:21\n",
      "     ------------                          67.2/198.5 MB 934.0 kB/s eta 0:02:21\n",
      "     ------------                          67.2/198.5 MB 934.0 kB/s eta 0:02:21\n",
      "     ------------                          67.2/198.5 MB 934.0 kB/s eta 0:02:21\n",
      "     ------------                          67.3/198.5 MB 917.0 kB/s eta 0:02:24\n",
      "     ------------                          67.3/198.5 MB 917.0 kB/s eta 0:02:24\n",
      "     ------------                          67.3/198.5 MB 917.0 kB/s eta 0:02:24\n",
      "     ------------                          67.3/198.5 MB 917.0 kB/s eta 0:02:24\n",
      "     ------------                          67.3/198.5 MB 917.0 kB/s eta 0:02:24\n",
      "     ------------                          67.3/198.5 MB 917.0 kB/s eta 0:02:24\n",
      "     ------------                          67.3/198.5 MB 898.1 kB/s eta 0:02:27\n",
      "     ------------                          67.3/198.5 MB 894.4 kB/s eta 0:02:27\n",
      "     ------------                          67.3/198.5 MB 894.4 kB/s eta 0:02:27\n",
      "     ------------                          67.4/198.5 MB 891.9 kB/s eta 0:02:28\n",
      "     ------------                          67.4/198.5 MB 888.4 kB/s eta 0:02:28\n",
      "     ------------                          67.4/198.5 MB 887.2 kB/s eta 0:02:28\n",
      "     ------------                          67.5/198.5 MB 883.6 kB/s eta 0:02:29\n",
      "     ------------                          67.5/198.5 MB 883.6 kB/s eta 0:02:29\n",
      "     ------------                          67.5/198.5 MB 884.8 kB/s eta 0:02:29\n",
      "     ------------                          67.5/198.5 MB 880.0 kB/s eta 0:02:29\n",
      "     ------------                          67.6/198.5 MB 878.8 kB/s eta 0:02:29\n",
      "     ------------                          67.6/198.5 MB 874.1 kB/s eta 0:02:30\n",
      "     ------------                          67.6/198.5 MB 874.1 kB/s eta 0:02:30\n",
      "     ------------                          67.6/198.5 MB 874.1 kB/s eta 0:02:30\n",
      "     ------------                          67.7/198.5 MB 870.6 kB/s eta 0:02:31\n",
      "     ------------                          67.7/198.5 MB 870.6 kB/s eta 0:02:31\n",
      "     ------------                          67.7/198.5 MB 868.3 kB/s eta 0:02:31\n",
      "     ------------                          67.7/198.5 MB 863.7 kB/s eta 0:02:32\n",
      "     ------------                          67.8/198.5 MB 861.5 kB/s eta 0:02:32\n",
      "     ------------                          67.8/198.5 MB 859.2 kB/s eta 0:02:33\n",
      "     ------------                          67.8/198.5 MB 858.1 kB/s eta 0:02:33\n",
      "     ------------                          67.8/198.5 MB 855.8 kB/s eta 0:02:33\n",
      "     ------------                          67.9/198.5 MB 854.7 kB/s eta 0:02:33\n",
      "     ------------                          67.9/198.5 MB 851.4 kB/s eta 0:02:34\n",
      "     ------------                          67.9/198.5 MB 850.3 kB/s eta 0:02:34\n",
      "     ------------                          68.0/198.5 MB 846.9 kB/s eta 0:02:35\n",
      "     ------------                          68.0/198.5 MB 846.9 kB/s eta 0:02:35\n",
      "     ------------                          68.0/198.5 MB 846.9 kB/s eta 0:02:35\n",
      "     ------------                          68.0/198.5 MB 846.9 kB/s eta 0:02:35\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 835.1 kB/s eta 0:02:37\n",
      "     ------------                          68.0/198.5 MB 756.9 kB/s eta 0:02:53\n",
      "     ------------                          68.0/198.5 MB 756.9 kB/s eta 0:02:53\n",
      "     ------------                          68.0/198.5 MB 756.9 kB/s eta 0:02:53\n",
      "     ------------                          68.0/198.5 MB 748.2 kB/s eta 0:02:55\n",
      "     ------------                          68.1/198.5 MB 747.4 kB/s eta 0:02:55\n",
      "     ------------                          68.1/198.5 MB 747.4 kB/s eta 0:02:55\n",
      "     ------------                          68.1/198.5 MB 747.4 kB/s eta 0:02:55\n",
      "     ------------                          68.1/198.5 MB 747.4 kB/s eta 0:02:55\n",
      "     ------------                          68.1/198.5 MB 738.1 kB/s eta 0:02:57\n",
      "     ------------                          68.1/198.5 MB 738.1 kB/s eta 0:02:57\n",
      "     ------------                          68.1/198.5 MB 738.1 kB/s eta 0:02:57\n",
      "     ------------                          68.2/198.5 MB 730.7 kB/s eta 0:02:59\n",
      "     ------------                          68.2/198.5 MB 730.7 kB/s eta 0:02:59\n",
      "     ------------                          68.2/198.5 MB 727.4 kB/s eta 0:03:00\n",
      "     ------------                          68.2/198.5 MB 725.0 kB/s eta 0:03:00\n",
      "     ------------                          68.2/198.5 MB 722.6 kB/s eta 0:03:01\n",
      "     ------------                          68.2/198.5 MB 721.0 kB/s eta 0:03:01\n",
      "     ------------                          68.2/198.5 MB 718.7 kB/s eta 0:03:02\n",
      "     ------------                          68.3/198.5 MB 717.1 kB/s eta 0:03:02\n",
      "     ------------                          68.3/198.5 MB 714.0 kB/s eta 0:03:03\n",
      "     ------------                          68.3/198.5 MB 713.2 kB/s eta 0:03:03\n",
      "     ------------                          68.3/198.5 MB 711.6 kB/s eta 0:03:03\n",
      "     ------------                          68.4/198.5 MB 709.3 kB/s eta 0:03:04\n",
      "     ------------                          68.4/198.5 MB 707.0 kB/s eta 0:03:05\n",
      "     ------------                          68.4/198.5 MB 707.0 kB/s eta 0:03:05\n",
      "     ------------                          68.4/198.5 MB 703.2 kB/s eta 0:03:05\n",
      "     ------------                          68.4/198.5 MB 703.2 kB/s eta 0:03:05\n",
      "     ------------                          68.4/198.5 MB 703.2 kB/s eta 0:03:05\n",
      "     ------------                          68.4/198.5 MB 698.8 kB/s eta 0:03:07\n",
      "     ------------                          68.5/198.5 MB 696.5 kB/s eta 0:03:07\n",
      "     ------------                          68.5/198.5 MB 694.3 kB/s eta 0:03:08\n",
      "     ------------                          68.5/198.5 MB 692.8 kB/s eta 0:03:08\n",
      "     ------------                          68.6/198.5 MB 690.6 kB/s eta 0:03:09\n",
      "     ------------                          68.6/198.5 MB 689.2 kB/s eta 0:03:09\n",
      "     ------------                          68.6/198.5 MB 686.3 kB/s eta 0:03:10\n",
      "     ------------                          68.6/198.5 MB 686.3 kB/s eta 0:03:10\n",
      "     ------------                          68.7/198.5 MB 684.1 kB/s eta 0:03:10\n",
      "     ------------                          68.7/198.5 MB 681.3 kB/s eta 0:03:11\n",
      "     ------------                          68.7/198.5 MB 679.9 kB/s eta 0:03:11\n",
      "     ------------                          68.8/198.5 MB 678.5 kB/s eta 0:03:12\n",
      "     ------------                          68.8/198.5 MB 677.0 kB/s eta 0:03:12\n",
      "     ------------                          68.8/198.5 MB 675.6 kB/s eta 0:03:12\n",
      "     ------------                          68.9/198.5 MB 672.8 kB/s eta 0:03:13\n",
      "     ------------                          68.9/198.5 MB 671.5 kB/s eta 0:03:14\n",
      "     ------------                          68.9/198.5 MB 670.1 kB/s eta 0:03:14\n",
      "     ------------                          68.9/198.5 MB 669.4 kB/s eta 0:03:14\n",
      "     ------------                          69.0/198.5 MB 667.4 kB/s eta 0:03:15\n",
      "     ------------                          69.0/198.5 MB 664.7 kB/s eta 0:03:15\n",
      "     ------------                          69.0/198.5 MB 664.0 kB/s eta 0:03:15\n",
      "     ------------                          69.0/198.5 MB 662.7 kB/s eta 0:03:16\n",
      "     ------------                          69.1/198.5 MB 662.7 kB/s eta 0:03:16\n",
      "     ------------                          69.1/198.5 MB 660.6 kB/s eta 0:03:16\n",
      "     ------------                          69.1/198.5 MB 659.3 kB/s eta 0:03:17\n",
      "     ------------                          69.2/198.5 MB 658.0 kB/s eta 0:03:17\n",
      "     ------------                          69.2/198.5 MB 658.0 kB/s eta 0:03:17\n",
      "     ------------                          69.2/198.5 MB 655.4 kB/s eta 0:03:18\n",
      "     ------------                          69.3/198.5 MB 654.7 kB/s eta 0:03:18\n",
      "     ------------                          69.3/198.5 MB 652.1 kB/s eta 0:03:19\n",
      "     ------------                          69.3/198.5 MB 651.4 kB/s eta 0:03:19\n",
      "     ------------                          69.4/198.5 MB 650.2 kB/s eta 0:03:19\n",
      "     ------------                          69.4/198.5 MB 648.9 kB/s eta 0:03:19\n",
      "     ------------                          69.4/198.5 MB 648.2 kB/s eta 0:03:20\n",
      "     ------------                          69.4/198.5 MB 645.7 kB/s eta 0:03:20\n",
      "     ------------                          69.4/198.5 MB 643.7 kB/s eta 0:03:21\n",
      "     ------------                          69.5/198.5 MB 643.1 kB/s eta 0:03:21\n",
      "     ------------                          69.5/198.5 MB 643.1 kB/s eta 0:03:21\n",
      "     ------------                          69.5/198.5 MB 640.0 kB/s eta 0:03:22\n",
      "     ------------                          69.5/198.5 MB 641.2 kB/s eta 0:03:22\n",
      "     ------------                          69.6/198.5 MB 638.7 kB/s eta 0:03:22\n",
      "     ------------                          69.6/198.5 MB 637.5 kB/s eta 0:03:23\n",
      "     ------------                          69.6/198.5 MB 636.9 kB/s eta 0:03:23\n",
      "     ------------                          69.6/198.5 MB 634.4 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 634.4 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 633.2 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 631.9 kB/s eta 0:03:24\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     ------------                          69.7/198.5 MB 536.6 kB/s eta 0:04:00\n",
      "     -------------                         69.8/198.5 MB 362.5 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 362.3 kB/s eta 0:05:56\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                         69.8/198.5 MB 352.0 kB/s eta 0:06:06\n",
      "     -------------                          69.8/198.5 MB 53.3 kB/s eta 0:40:15\n",
      "     -------------                          69.8/198.5 MB 54.0 kB/s eta 0:39:45\n",
      "     -------------                          69.8/198.5 MB 54.0 kB/s eta 0:39:45\n",
      "     -------------                          69.8/198.5 MB 54.0 kB/s eta 0:39:45\n",
      "     -------------                          69.8/198.5 MB 54.0 kB/s eta 0:39:45\n",
      "     -------------                          69.8/198.5 MB 54.0 kB/s eta 0:39:45\n",
      "     -------------                          69.8/198.5 MB 54.0 kB/s eta 0:39:45\n",
      "     -------------                          69.8/198.5 MB 54.0 kB/s eta 0:39:45\n",
      "     -------------                          69.8/198.5 MB 54.0 kB/s eta 0:39:45\n",
      "     -------------                          69.8/198.5 MB 54.0 kB/s eta 0:39:45\n",
      "     -------------                          69.8/198.5 MB 54.0 kB/s eta 0:39:45\n",
      "     -------------                          69.8/198.5 MB 54.0 kB/s eta 0:39:45\n",
      "     -------------                          69.8/198.5 MB 54.0 kB/s eta 0:39:45\n",
      "     -------------                          69.8/198.5 MB 46.4 kB/s eta 0:46:11\n",
      "     -------------                          69.8/198.5 MB 46.4 kB/s eta 0:46:11\n",
      "     -------------                          69.8/198.5 MB 46.4 kB/s eta 0:46:11\n",
      "     -------------                          69.8/198.5 MB 46.4 kB/s eta 0:46:11\n",
      "     -------------                          69.8/198.5 MB 46.4 kB/s eta 0:46:11\n",
      "     -------------                          69.8/198.5 MB 46.4 kB/s eta 0:46:11\n",
      "     -------------                          69.8/198.5 MB 46.4 kB/s eta 0:46:11\n",
      "     -------------                          69.8/198.5 MB 41.0 kB/s eta 0:52:22\n",
      "     -------------                          69.8/198.5 MB 41.0 kB/s eta 0:52:22\n",
      "     -------------                          69.9/198.5 MB 39.6 kB/s eta 0:54:10\n",
      "     -------------                          69.9/198.5 MB 39.6 kB/s eta 0:54:10\n",
      "     -------------                          69.9/198.5 MB 39.6 kB/s eta 0:54:10\n",
      "     -------------                          69.9/198.5 MB 37.5 kB/s eta 0:57:06\n",
      "     -------------                          69.9/198.5 MB 37.5 kB/s eta 0:57:06\n",
      "     -------------                          69.9/198.5 MB 35.5 kB/s eta 1:00:24\n",
      "     -------------                          69.9/198.5 MB 35.2 kB/s eta 1:00:58\n",
      "     -------------                          69.9/198.5 MB 35.5 kB/s eta 1:00:21\n",
      "     -------------                          69.9/198.5 MB 34.8 kB/s eta 1:01:33\n",
      "     -------------                          70.0/198.5 MB 35.2 kB/s eta 1:00:57\n",
      "     -------------                          70.0/198.5 MB 34.8 kB/s eta 1:01:32\n",
      "     -------------                          70.0/198.5 MB 34.5 kB/s eta 1:02:08\n",
      "     -------------                          70.0/198.5 MB 33.8 kB/s eta 1:03:20\n",
      "     -------------                          70.1/198.5 MB 33.8 kB/s eta 1:03:20\n",
      "     -------------                          70.1/198.5 MB 34.2 kB/s eta 1:02:39\n",
      "     -------------                          70.1/198.5 MB 34.5 kB/s eta 1:02:05\n",
      "     -------------                          70.1/198.5 MB 33.1 kB/s eta 1:04:38\n",
      "     -------------                          70.2/198.5 MB 33.5 kB/s eta 1:03:57\n",
      "     -------------                          70.2/198.5 MB 32.8 kB/s eta 1:05:14\n",
      "     -------------                          70.2/198.5 MB 32.8 kB/s eta 1:05:16\n",
      "     -------------                          70.2/198.5 MB 31.4 kB/s eta 1:08:00\n",
      "     -------------                          70.3/198.5 MB 32.8 kB/s eta 1:05:14\n",
      "     -------------                          70.3/198.5 MB 32.8 kB/s eta 1:05:11\n",
      "     -------------                          70.3/198.5 MB 32.8 kB/s eta 1:05:13\n",
      "     -------------                          70.3/198.5 MB 32.8 kB/s eta 1:05:12\n",
      "     -------------                          70.3/198.5 MB 32.1 kB/s eta 1:06:33\n",
      "     -------------                          70.4/198.5 MB 32.1 kB/s eta 1:06:30\n",
      "     -------------                          70.4/198.5 MB 32.8 kB/s eta 1:05:05\n",
      "     -------------                          70.4/198.5 MB 33.1 kB/s eta 1:04:29\n",
      "     -------------                          70.5/198.5 MB 33.5 kB/s eta 1:03:49\n",
      "     -------------                          70.5/198.5 MB 32.8 kB/s eta 1:05:01\n",
      "     -------------                          70.5/198.5 MB 33.8 kB/s eta 1:03:08\n",
      "     -------------                          70.5/198.5 MB 33.2 kB/s eta 1:04:19\n",
      "     -------------                          70.6/198.5 MB 34.5 kB/s eta 1:01:49\n",
      "     -------------                          70.6/198.5 MB 34.9 kB/s eta 1:01:10\n",
      "     -------------                          70.7/198.5 MB 35.5 kB/s eta 1:00:02\n",
      "     -------------                          70.7/198.5 MB 35.5 kB/s eta 1:00:01\n",
      "     -------------                          70.7/198.5 MB 35.2 kB/s eta 1:00:29\n",
      "     -------------                          70.8/198.5 MB 35.5 kB/s eta 0:59:57\n",
      "     -------------                          70.8/198.5 MB 39.2 kB/s eta 0:54:19\n",
      "     -------------                          70.8/198.5 MB 41.0 kB/s eta 0:51:54\n",
      "     -------------                          70.9/198.5 MB 42.0 kB/s eta 0:50:37\n",
      "     -------------                          70.9/198.5 MB 43.1 kB/s eta 0:49:22\n",
      "     -------------                          70.9/198.5 MB 44.9 kB/s eta 0:47:24\n",
      "     -------------                          71.0/198.5 MB 45.9 kB/s eta 0:46:19\n",
      "     -------------                          71.0/198.5 MB 47.7 kB/s eta 0:44:34\n",
      "     -------------                          71.1/198.5 MB 48.7 kB/s eta 0:43:38\n",
      "     -------------                          71.1/198.5 MB 49.8 kB/s eta 0:42:41\n",
      "     -------------                          71.1/198.5 MB 50.8 kB/s eta 0:41:50\n",
      "     -------------                          71.2/198.5 MB 52.2 kB/s eta 0:40:41\n",
      "     -------------                          71.2/198.5 MB 54.3 kB/s eta 0:39:04\n",
      "     -------------                          71.2/198.5 MB 54.3 kB/s eta 0:39:04\n",
      "     -------------                          71.3/198.5 MB 56.3 kB/s eta 0:37:40\n",
      "     -------------                          71.3/198.5 MB 58.0 kB/s eta 0:36:32\n",
      "     -------------                          71.4/198.5 MB 59.0 kB/s eta 0:35:54\n",
      "     -------------                          71.4/198.5 MB 61.5 kB/s eta 0:34:26\n",
      "     -------------                          71.5/198.5 MB 62.5 kB/s eta 0:33:52\n",
      "     -------------                          71.5/198.5 MB 64.2 kB/s eta 0:32:59\n",
      "     -------------                          71.5/198.5 MB 65.2 kB/s eta 0:32:29\n",
      "     -------------                          71.6/198.5 MB 66.9 kB/s eta 0:31:37\n",
      "     -------------                          71.6/198.5 MB 68.2 kB/s eta 0:31:00\n",
      "     -------------                          71.7/198.5 MB 69.6 kB/s eta 0:30:22\n",
      "     -------------                          71.7/198.5 MB 71.7 kB/s eta 0:29:30\n",
      "     -------------                          71.8/198.5 MB 73.3 kB/s eta 0:28:48\n",
      "     -------------                          71.8/198.5 MB 75.0 kB/s eta 0:28:09\n",
      "     -------------                          71.9/198.5 MB 76.4 kB/s eta 0:27:38\n",
      "     -------------                          71.9/198.5 MB 77.8 kB/s eta 0:27:08\n",
      "     -------------                          72.0/198.5 MB 79.7 kB/s eta 0:26:28\n",
      "     -------------                          72.0/198.5 MB 80.3 kB/s eta 0:26:15\n",
      "     -------------                          72.1/198.5 MB 82.3 kB/s eta 0:25:36\n",
      "     -------------                          72.1/198.5 MB 83.3 kB/s eta 0:25:18\n",
      "     -------------                          72.1/198.5 MB 84.6 kB/s eta 0:24:54\n",
      "     -------------                          72.2/198.5 MB 87.3 kB/s eta 0:24:07\n",
      "     -------------                          72.3/198.5 MB 88.2 kB/s eta 0:23:51\n",
      "     -------------                          72.3/198.5 MB 90.2 kB/s eta 0:23:19\n",
      "     -------------                          72.4/198.5 MB 92.5 kB/s eta 0:22:44\n",
      "     -------------                          72.4/198.5 MB 93.4 kB/s eta 0:22:30\n",
      "     -------------                          72.5/198.5 MB 96.1 kB/s eta 0:21:52\n",
      "     -------------                          72.6/198.5 MB 98.7 kB/s eta 0:21:16\n",
      "     -------------                          72.6/198.5 MB 99.3 kB/s eta 0:21:08\n",
      "     -------------                         72.7/198.5 MB 101.2 kB/s eta 0:20:44\n",
      "     -------------                         72.7/198.5 MB 103.2 kB/s eta 0:20:19\n",
      "     -------------                         72.8/198.5 MB 104.8 kB/s eta 0:20:00\n",
      "     -------------                         72.8/198.5 MB 107.1 kB/s eta 0:19:34\n",
      "     -------------                         72.9/198.5 MB 110.0 kB/s eta 0:19:02\n",
      "     -------------                         73.0/198.5 MB 110.9 kB/s eta 0:18:53\n",
      "     -------------                         73.1/198.5 MB 113.5 kB/s eta 0:18:26\n",
      "     -------------                         73.1/198.5 MB 115.4 kB/s eta 0:18:07\n",
      "     -------------                         73.2/198.5 MB 118.0 kB/s eta 0:17:43\n",
      "     -------------                         73.2/198.5 MB 118.8 kB/s eta 0:17:35\n",
      "     -------------                         73.3/198.5 MB 119.8 kB/s eta 0:17:26\n",
      "     -------------                         73.3/198.5 MB 121.9 kB/s eta 0:17:07\n",
      "     -------------                         73.4/198.5 MB 124.5 kB/s eta 0:16:46\n",
      "     -------------                         73.4/198.5 MB 125.3 kB/s eta 0:16:39\n",
      "     -------------                         73.5/198.5 MB 126.8 kB/s eta 0:16:26\n",
      "     -------------                         73.6/198.5 MB 129.6 kB/s eta 0:16:04\n",
      "     -------------                         73.7/198.5 MB 132.2 kB/s eta 0:15:45\n",
      "     -------------                         73.7/198.5 MB 133.7 kB/s eta 0:15:34\n",
      "     -------------                         73.8/198.5 MB 136.3 kB/s eta 0:15:16\n",
      "     -------------                         73.8/198.5 MB 137.2 kB/s eta 0:15:09\n",
      "     -------------                         73.9/198.5 MB 197.5 kB/s eta 0:10:31\n",
      "     -------------                         74.0/198.5 MB 201.5 kB/s eta 0:10:19\n",
      "     -------------                         74.0/198.5 MB 202.0 kB/s eta 0:10:17\n",
      "     -------------                         74.0/198.5 MB 203.2 kB/s eta 0:10:13\n",
      "     -------------                         74.1/198.5 MB 205.2 kB/s eta 0:10:07\n",
      "     -------------                         74.1/198.5 MB 206.5 kB/s eta 0:10:03\n",
      "     -------------                         74.2/198.5 MB 208.5 kB/s eta 0:09:57\n",
      "     -------------                         74.2/198.5 MB 208.5 kB/s eta 0:09:57\n",
      "     -------------                         74.2/198.5 MB 210.6 kB/s eta 0:09:51\n",
      "     -------------                         74.3/198.5 MB 211.7 kB/s eta 0:09:47\n",
      "     -------------                         74.3/198.5 MB 213.8 kB/s eta 0:09:41\n",
      "     -------------                         74.3/198.5 MB 214.6 kB/s eta 0:09:39\n",
      "     -------------                         74.4/198.5 MB 216.7 kB/s eta 0:09:33\n",
      "     -------------                         74.4/198.5 MB 218.6 kB/s eta 0:09:28\n",
      "     -------------                         74.5/198.5 MB 219.3 kB/s eta 0:09:26\n",
      "     -------------                         74.5/198.5 MB 220.4 kB/s eta 0:09:23\n",
      "     -------------                         74.5/198.5 MB 221.1 kB/s eta 0:09:21\n",
      "     -------------                         74.6/198.5 MB 223.2 kB/s eta 0:09:16\n",
      "     -------------                         74.6/198.5 MB 225.5 kB/s eta 0:09:10\n",
      "     -------------                         74.6/198.5 MB 226.2 kB/s eta 0:09:08\n",
      "     -------------                         74.7/198.5 MB 227.1 kB/s eta 0:09:06\n",
      "     -------------                         74.7/198.5 MB 229.0 kB/s eta 0:09:01\n",
      "     -------------                         74.8/198.5 MB 231.0 kB/s eta 0:08:56\n",
      "     -------------                         74.8/198.5 MB 233.5 kB/s eta 0:08:50\n",
      "     -------------                         74.9/198.5 MB 234.1 kB/s eta 0:08:49\n",
      "     -------------                         74.9/198.5 MB 236.0 kB/s eta 0:08:44\n",
      "     -------------                         75.0/198.5 MB 238.3 kB/s eta 0:08:39\n",
      "     -------------                         75.0/198.5 MB 239.7 kB/s eta 0:08:36\n",
      "     --------------                        75.1/198.5 MB 243.6 kB/s eta 0:08:27\n",
      "     --------------                        75.2/198.5 MB 245.6 kB/s eta 0:08:23\n",
      "     --------------                        75.2/198.5 MB 245.9 kB/s eta 0:08:22\n",
      "     --------------                        75.2/198.5 MB 245.9 kB/s eta 0:08:22\n",
      "     --------------                        75.4/198.5 MB 251.9 kB/s eta 0:08:09\n",
      "     --------------                        75.4/198.5 MB 254.8 kB/s eta 0:08:03\n",
      "     --------------                        75.5/198.5 MB 257.5 kB/s eta 0:07:58\n",
      "     --------------                        75.5/198.5 MB 258.5 kB/s eta 0:07:56\n",
      "     --------------                        75.6/198.5 MB 260.1 kB/s eta 0:07:53\n",
      "     --------------                        75.7/198.5 MB 262.1 kB/s eta 0:07:49\n",
      "     --------------                        75.7/198.5 MB 262.9 kB/s eta 0:07:48\n",
      "     --------------                        75.7/198.5 MB 264.8 kB/s eta 0:07:44\n",
      "     --------------                        75.8/198.5 MB 268.6 kB/s eta 0:07:37\n",
      "     --------------                        75.9/198.5 MB 269.5 kB/s eta 0:07:35\n",
      "     --------------                        75.9/198.5 MB 269.5 kB/s eta 0:07:35\n",
      "     --------------                        75.9/198.5 MB 269.5 kB/s eta 0:07:35\n",
      "     --------------                        76.0/198.5 MB 272.5 kB/s eta 0:07:30\n",
      "     --------------                        76.0/198.5 MB 274.7 kB/s eta 0:07:26\n",
      "     --------------                        76.1/198.5 MB 275.5 kB/s eta 0:07:25\n",
      "     --------------                        76.1/198.5 MB 278.2 kB/s eta 0:07:20\n",
      "     --------------                        76.2/198.5 MB 279.4 kB/s eta 0:07:18\n",
      "     --------------                        76.2/198.5 MB 280.2 kB/s eta 0:07:17\n",
      "     --------------                        76.3/198.5 MB 282.4 kB/s eta 0:07:13\n",
      "     --------------                        76.3/198.5 MB 283.2 kB/s eta 0:07:12\n",
      "     --------------                        76.4/198.5 MB 286.4 kB/s eta 0:07:07\n",
      "     --------------                        76.4/198.5 MB 286.9 kB/s eta 0:07:06\n",
      "     --------------                        76.5/198.5 MB 288.7 kB/s eta 0:07:03\n",
      "     --------------                        76.5/198.5 MB 291.9 kB/s eta 0:06:58\n",
      "     --------------                        76.6/198.5 MB 293.5 kB/s eta 0:06:56\n",
      "     --------------                        76.7/198.5 MB 296.1 kB/s eta 0:06:52\n",
      "     --------------                        76.7/198.5 MB 298.2 kB/s eta 0:06:49\n",
      "     --------------                        76.8/198.5 MB 301.3 kB/s eta 0:06:44\n",
      "     --------------                        76.8/198.5 MB 302.0 kB/s eta 0:06:43\n",
      "     --------------                        76.9/198.5 MB 304.4 kB/s eta 0:06:40\n",
      "     --------------                        77.0/198.5 MB 307.3 kB/s eta 0:06:36\n",
      "     --------------                        77.1/198.5 MB 310.1 kB/s eta 0:06:32\n",
      "     --------------                        77.1/198.5 MB 312.8 kB/s eta 0:06:29\n",
      "     --------------                        77.2/198.5 MB 312.8 kB/s eta 0:06:28\n",
      "     --------------                        77.2/198.5 MB 312.8 kB/s eta 0:06:28\n",
      "     --------------                        77.2/198.5 MB 312.8 kB/s eta 0:06:28\n",
      "     --------------                        77.2/198.5 MB 312.8 kB/s eta 0:06:28\n",
      "     --------------                        77.2/198.5 MB 312.8 kB/s eta 0:06:28\n",
      "     --------------                        77.2/198.5 MB 312.8 kB/s eta 0:06:28\n",
      "     --------------                        77.2/198.5 MB 312.8 kB/s eta 0:06:28\n",
      "     --------------                        77.2/198.5 MB 312.8 kB/s eta 0:06:28\n",
      "     --------------                        77.2/198.5 MB 312.8 kB/s eta 0:06:28\n",
      "     --------------                        77.2/198.5 MB 312.8 kB/s eta 0:06:28\n",
      "     --------------                        77.2/198.5 MB 312.8 kB/s eta 0:06:28\n",
      "     --------------                        77.9/198.5 MB 336.3 kB/s eta 0:05:59\n",
      "     --------------                        78.0/198.5 MB 338.9 kB/s eta 0:05:56\n",
      "     --------------                        78.1/198.5 MB 341.8 kB/s eta 0:05:53\n",
      "     --------------                        78.1/198.5 MB 343.6 kB/s eta 0:05:51\n",
      "     --------------                        78.2/198.5 MB 346.1 kB/s eta 0:05:48\n",
      "     --------------                        78.2/198.5 MB 346.7 kB/s eta 0:05:47\n",
      "     --------------                        78.3/198.5 MB 348.8 kB/s eta 0:05:45\n",
      "     --------------                        78.3/198.5 MB 349.2 kB/s eta 0:05:45\n",
      "     --------------                        78.4/198.5 MB 351.4 kB/s eta 0:05:42\n",
      "     --------------                        78.5/198.5 MB 354.3 kB/s eta 0:05:39\n",
      "     --------------                        78.5/198.5 MB 354.5 kB/s eta 0:05:39\n",
      "     --------------                        78.6/198.5 MB 357.9 kB/s eta 0:05:36\n",
      "     --------------                        78.7/198.5 MB 360.0 kB/s eta 0:05:33\n",
      "     --------------                        78.7/198.5 MB 361.9 kB/s eta 0:05:31\n",
      "     --------------                        78.8/198.5 MB 363.5 kB/s eta 0:05:30\n",
      "     --------------                        78.8/198.5 MB 363.5 kB/s eta 0:05:30\n",
      "     --------------                        78.8/198.5 MB 363.5 kB/s eta 0:05:30\n",
      "     --------------                        78.9/198.5 MB 364.5 kB/s eta 0:05:29\n",
      "     --------------                        78.9/198.5 MB 365.5 kB/s eta 0:05:28\n",
      "     --------------                        79.0/198.5 MB 367.1 kB/s eta 0:05:26\n",
      "     --------------                        79.0/198.5 MB 367.1 kB/s eta 0:05:26\n",
      "     --------------                        79.0/198.5 MB 367.1 kB/s eta 0:05:26\n",
      "     --------------                        79.0/198.5 MB 367.1 kB/s eta 0:05:26\n",
      "     --------------                        79.0/198.5 MB 365.4 kB/s eta 0:05:28\n",
      "     --------------                        79.1/198.5 MB 371.1 kB/s eta 0:05:22\n",
      "     --------------                        79.2/198.5 MB 374.3 kB/s eta 0:05:19\n",
      "     --------------                        79.3/198.5 MB 375.9 kB/s eta 0:05:18\n",
      "     --------------                        79.3/198.5 MB 376.6 kB/s eta 0:05:17\n",
      "     --------------                        79.4/198.5 MB 378.7 kB/s eta 0:05:15\n",
      "     --------------                        79.5/198.5 MB 380.0 kB/s eta 0:05:14\n",
      "     --------------                        79.5/198.5 MB 381.1 kB/s eta 0:05:13\n",
      "     --------------                        79.6/198.5 MB 383.6 kB/s eta 0:05:11\n",
      "     --------------                        79.6/198.5 MB 384.5 kB/s eta 0:05:10\n",
      "     --------------                        79.6/198.5 MB 385.5 kB/s eta 0:05:09\n",
      "     --------------                        79.7/198.5 MB 385.7 kB/s eta 0:05:09\n",
      "     --------------                        79.8/198.5 MB 388.2 kB/s eta 0:05:06\n",
      "     --------------                        79.8/198.5 MB 389.7 kB/s eta 0:05:05\n",
      "     --------------                        79.9/198.5 MB 392.0 kB/s eta 0:05:03\n",
      "     --------------                        80.0/198.5 MB 393.4 kB/s eta 0:05:02\n",
      "     --------------                        80.0/198.5 MB 943.4 kB/s eta 0:02:06\n",
      "     --------------                        80.0/198.5 MB 942.1 kB/s eta 0:02:06\n",
      "     ---------------                         80.1/198.5 MB 1.1 MB/s eta 0:01:52\n",
      "     ---------------                         80.1/198.5 MB 1.1 MB/s eta 0:01:52\n",
      "     ---------------                         80.2/198.5 MB 1.1 MB/s eta 0:01:51\n",
      "     ---------------                         80.3/198.5 MB 1.1 MB/s eta 0:01:50\n",
      "     ---------------                         80.3/198.5 MB 1.1 MB/s eta 0:01:49\n",
      "     ---------------                         80.3/198.5 MB 1.1 MB/s eta 0:01:50\n",
      "     ---------------                         80.4/198.5 MB 1.1 MB/s eta 0:01:48\n",
      "     ---------------                         80.5/198.5 MB 1.1 MB/s eta 0:01:47\n",
      "     ---------------                         80.5/198.5 MB 1.1 MB/s eta 0:01:47\n",
      "     ---------------                         80.6/198.5 MB 1.1 MB/s eta 0:01:46\n",
      "     ---------------                         80.6/198.5 MB 1.1 MB/s eta 0:01:45\n",
      "     ---------------                         80.7/198.5 MB 1.1 MB/s eta 0:01:44\n",
      "     ---------------                         80.8/198.5 MB 1.1 MB/s eta 0:01:44\n",
      "     ---------------                         80.8/198.5 MB 1.1 MB/s eta 0:01:43\n",
      "     ---------------                         80.9/198.5 MB 1.1 MB/s eta 0:01:43\n",
      "     ---------------                         80.9/198.5 MB 1.1 MB/s eta 0:01:43\n",
      "     ---------------                         81.0/198.5 MB 1.2 MB/s eta 0:01:42\n",
      "     ---------------                         81.0/198.5 MB 1.2 MB/s eta 0:01:42\n",
      "     ---------------                         81.0/198.5 MB 1.2 MB/s eta 0:01:43\n",
      "     ---------------                         81.0/198.5 MB 1.1 MB/s eta 0:01:43\n",
      "     ---------------                         81.1/198.5 MB 1.1 MB/s eta 0:01:43\n",
      "     ---------------                         81.1/198.5 MB 1.1 MB/s eta 0:01:43\n",
      "     ---------------                         81.1/198.5 MB 1.1 MB/s eta 0:01:43\n",
      "     ---------------                         81.1/198.5 MB 1.1 MB/s eta 0:01:43\n",
      "     ---------------                         81.1/198.5 MB 1.1 MB/s eta 0:01:43\n",
      "     ---------------                         81.1/198.5 MB 1.1 MB/s eta 0:01:43\n",
      "     ---------------                         81.2/198.5 MB 1.1 MB/s eta 0:01:44\n",
      "     ---------------                         81.4/198.5 MB 1.2 MB/s eta 0:01:42\n",
      "     ----------------                        81.5/198.5 MB 1.2 MB/s eta 0:01:40\n",
      "     ----------------                        81.6/198.5 MB 1.2 MB/s eta 0:01:40\n",
      "     ----------------                        81.6/198.5 MB 1.2 MB/s eta 0:01:40\n",
      "     ----------------                        81.7/198.5 MB 1.2 MB/s eta 0:01:40\n",
      "     ----------------                        81.7/198.5 MB 1.2 MB/s eta 0:01:40\n",
      "     ----------------                        81.8/198.5 MB 1.2 MB/s eta 0:01:39\n",
      "     ----------------                        81.9/198.5 MB 1.2 MB/s eta 0:01:38\n",
      "     ----------------                        82.0/198.5 MB 1.2 MB/s eta 0:01:39\n",
      "     ----------------                        82.0/198.5 MB 1.2 MB/s eta 0:01:38\n",
      "     ----------------                        82.1/198.5 MB 1.2 MB/s eta 0:01:38\n",
      "     ----------------                        82.2/198.5 MB 1.2 MB/s eta 0:01:38\n",
      "     ----------------                        82.2/198.5 MB 1.2 MB/s eta 0:01:38\n",
      "     ----------------                        82.3/198.5 MB 1.2 MB/s eta 0:01:38\n",
      "     ----------------                        82.4/198.5 MB 1.2 MB/s eta 0:01:37\n",
      "     ----------------                        82.5/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        82.6/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        82.7/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        82.8/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        82.9/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        83.0/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     ----------------                        83.1/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     ----------------                        83.2/198.5 MB 1.3 MB/s eta 0:01:32\n",
      "     ----------------                        83.2/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     ----------------                        83.2/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     ----------------                        83.4/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     ----------------                        83.4/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     ----------------                        83.4/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     ----------------                        83.4/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     ----------------                        83.5/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     ----------------                        83.5/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     ----------------                        83.5/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     ----------------                        83.5/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        83.5/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        83.6/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        83.7/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        83.8/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        83.8/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        83.8/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        83.8/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        83.9/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        83.9/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        84.0/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        84.0/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        84.1/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        84.2/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        84.3/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        84.3/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        84.3/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        84.4/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        84.4/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        84.5/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        84.6/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        84.7/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        84.7/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     ----------------                        84.7/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     ----------------                        84.8/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     ----------------                        84.8/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        84.8/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        84.9/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        84.9/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        84.9/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        84.9/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     ----------------                        84.9/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        85.0/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        85.0/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        85.0/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        85.0/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        85.1/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        85.2/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        85.3/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        85.3/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        85.3/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        85.3/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     ----------------                        85.4/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        85.4/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        85.4/198.5 MB 1.2 MB/s eta 0:01:37\n",
      "     ----------------                        85.5/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        85.6/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        85.6/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        85.7/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        85.7/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        85.8/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        85.8/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        85.9/198.5 MB 1.2 MB/s eta 0:01:37\n",
      "     ----------------                        85.9/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        86.0/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        86.0/198.5 MB 1.2 MB/s eta 0:01:37\n",
      "     ----------------                        86.1/198.5 MB 1.2 MB/s eta 0:01:37\n",
      "     ----------------                        86.2/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        86.2/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        86.2/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        86.3/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        86.4/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        86.4/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        86.4/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     ----------------                        86.5/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     -----------------                       86.6/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     -----------------                       86.6/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     -----------------                       86.6/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     -----------------                       86.7/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     -----------------                       86.7/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     -----------------                       86.7/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     -----------------                       86.8/198.5 MB 1.2 MB/s eta 0:01:37\n",
      "     -----------------                       86.8/198.5 MB 1.2 MB/s eta 0:01:37\n",
      "     -----------------                       86.9/198.5 MB 1.2 MB/s eta 0:01:37\n",
      "     -----------------                       86.9/198.5 MB 1.2 MB/s eta 0:01:37\n",
      "     -----------------                       86.9/198.5 MB 1.2 MB/s eta 0:01:37\n",
      "     -----------------                       87.1/198.5 MB 1.2 MB/s eta 0:01:37\n",
      "     -----------------                       87.1/198.5 MB 1.2 MB/s eta 0:01:37\n",
      "     -----------------                       87.2/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     -----------------                       87.3/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     -----------------                       87.4/198.5 MB 1.2 MB/s eta 0:01:31\n",
      "     -----------------                       87.5/198.5 MB 1.2 MB/s eta 0:01:31\n",
      "     -----------------                       87.6/198.5 MB 1.2 MB/s eta 0:01:31\n",
      "     -----------------                       87.6/198.5 MB 1.2 MB/s eta 0:01:32\n",
      "     -----------------                       87.7/198.5 MB 1.2 MB/s eta 0:01:32\n",
      "     -----------------                       87.7/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     -----------------                       87.8/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     -----------------                       87.8/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     -----------------                       87.9/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     -----------------                       87.9/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     -----------------                       87.9/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     -----------------                       88.0/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     -----------------                       88.1/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     -----------------                       88.2/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     -----------------                       88.2/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     -----------------                       88.3/198.5 MB 1.2 MB/s eta 0:01:36\n",
      "     -----------------                       88.5/198.5 MB 1.2 MB/s eta 0:01:35\n",
      "     -----------------                       88.6/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     -----------------                       88.7/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     -----------------                       88.8/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     -----------------                       88.8/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     -----------------                       88.8/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     -----------------                       88.9/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     -----------------                       89.0/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     -----------------                       89.0/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     -----------------                       89.0/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     -----------------                       89.0/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     -----------------                       89.1/198.5 MB 1.2 MB/s eta 0:01:34\n",
      "     -----------------                       89.2/198.5 MB 1.2 MB/s eta 0:01:32\n",
      "     -----------------                       89.3/198.5 MB 1.2 MB/s eta 0:01:32\n",
      "     -----------------                       89.3/198.5 MB 1.2 MB/s eta 0:01:32\n",
      "     -----------------                       89.4/198.5 MB 1.2 MB/s eta 0:01:32\n",
      "     -----------------                       89.5/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     -----------------                       89.5/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     -----------------                       89.5/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     -----------------                       89.7/198.5 MB 1.2 MB/s eta 0:01:32\n",
      "     -----------------                       89.7/198.5 MB 1.2 MB/s eta 0:01:32\n",
      "     -----------------                       89.7/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     -----------------                       89.7/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     -----------------                       89.8/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     -----------------                       89.8/198.5 MB 1.2 MB/s eta 0:01:33\n",
      "     -----------------                       89.9/198.5 MB 1.2 MB/s eta 0:01:32\n",
      "     -----------------                       90.0/198.5 MB 1.2 MB/s eta 0:01:32\n",
      "     -----------------                       90.1/198.5 MB 1.2 MB/s eta 0:01:32\n",
      "     -----------------                       90.1/198.5 MB 1.2 MB/s eta 0:01:32\n",
      "     -----------------                       90.3/198.5 MB 1.2 MB/s eta 0:01:31\n",
      "     -----------------                       90.4/198.5 MB 1.2 MB/s eta 0:01:30\n",
      "     -----------------                       90.4/198.5 MB 1.2 MB/s eta 0:01:30\n",
      "     -----------------                       90.5/198.5 MB 1.2 MB/s eta 0:01:30\n",
      "     -----------------                       90.6/198.5 MB 1.2 MB/s eta 0:01:29\n",
      "     -----------------                       90.7/198.5 MB 1.2 MB/s eta 0:01:28\n",
      "     -----------------                       90.8/198.5 MB 1.2 MB/s eta 0:01:28\n",
      "     -----------------                       90.8/198.5 MB 1.2 MB/s eta 0:01:29\n",
      "     -----------------                       90.9/198.5 MB 1.2 MB/s eta 0:01:29\n",
      "     -----------------                       90.9/198.5 MB 1.2 MB/s eta 0:01:29\n",
      "     -----------------                       90.9/198.5 MB 1.2 MB/s eta 0:01:29\n",
      "     -----------------                       91.0/198.5 MB 1.2 MB/s eta 0:01:29\n",
      "     -----------------                       91.0/198.5 MB 1.2 MB/s eta 0:01:29\n",
      "     -----------------                       91.1/198.5 MB 1.2 MB/s eta 0:01:30\n",
      "     -----------------                       91.2/198.5 MB 1.2 MB/s eta 0:01:29\n",
      "     -----------------                       91.3/198.5 MB 1.2 MB/s eta 0:01:28\n",
      "     -----------------                       91.4/198.5 MB 1.3 MB/s eta 0:01:25\n",
      "     -----------------                       91.5/198.5 MB 1.3 MB/s eta 0:01:24\n",
      "     -----------------                       91.5/198.5 MB 1.3 MB/s eta 0:01:25\n",
      "     -----------------                       91.5/198.5 MB 1.3 MB/s eta 0:01:25\n",
      "     -----------------                       91.6/198.5 MB 1.3 MB/s eta 0:01:26\n",
      "     ------------------                      91.6/198.5 MB 1.3 MB/s eta 0:01:26\n",
      "     ------------------                      91.7/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      91.7/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      91.8/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      91.9/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      92.0/198.5 MB 1.3 MB/s eta 0:01:25\n",
      "     ------------------                      92.1/198.5 MB 1.3 MB/s eta 0:01:25\n",
      "     ------------------                      92.2/198.5 MB 1.3 MB/s eta 0:01:25\n",
      "     ------------------                      92.2/198.5 MB 1.3 MB/s eta 0:01:25\n",
      "     ------------------                      92.2/198.5 MB 1.3 MB/s eta 0:01:25\n",
      "     ------------------                      92.3/198.5 MB 1.3 MB/s eta 0:01:25\n",
      "     ------------------                      92.4/198.5 MB 1.3 MB/s eta 0:01:25\n",
      "     ------------------                      92.4/198.5 MB 1.3 MB/s eta 0:01:25\n",
      "     ------------------                      92.5/198.5 MB 1.3 MB/s eta 0:01:25\n",
      "     ------------------                      92.7/198.5 MB 1.3 MB/s eta 0:01:24\n",
      "     ------------------                      92.7/198.5 MB 1.3 MB/s eta 0:01:24\n",
      "     ------------------                      92.7/198.5 MB 1.3 MB/s eta 0:01:24\n",
      "     ------------------                      92.7/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      92.9/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      93.2/198.5 MB 1.3 MB/s eta 0:01:24\n",
      "     ------------------                      93.3/198.5 MB 1.3 MB/s eta 0:01:24\n",
      "     ------------------                      93.3/198.5 MB 1.3 MB/s eta 0:01:24\n",
      "     ------------------                      93.3/198.5 MB 1.3 MB/s eta 0:01:24\n",
      "     ------------------                      93.4/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      93.4/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      93.4/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      93.4/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      93.5/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      93.5/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      93.5/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      93.6/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      93.7/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      93.8/198.5 MB 1.3 MB/s eta 0:01:24\n",
      "     ------------------                      93.8/198.5 MB 1.3 MB/s eta 0:01:23\n",
      "     ------------------                      93.8/198.5 MB 1.3 MB/s eta 0:01:23\n",
      "     ------------------                      93.8/198.5 MB 1.2 MB/s eta 0:01:24\n",
      "     ------------------                      93.8/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      93.8/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      93.8/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      93.9/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      94.0/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      94.0/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      94.1/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      94.1/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      94.1/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      94.1/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      94.2/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      94.2/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      94.3/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      94.4/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      94.4/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      94.4/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      94.5/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      94.5/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      94.6/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      94.6/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      94.6/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      94.8/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      94.8/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      94.9/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      95.0/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      95.1/198.5 MB 1.2 MB/s eta 0:01:24\n",
      "     ------------------                      95.2/198.5 MB 1.3 MB/s eta 0:01:21\n",
      "     ------------------                      95.3/198.5 MB 1.3 MB/s eta 0:01:20\n",
      "     ------------------                      95.4/198.5 MB 1.3 MB/s eta 0:01:20\n",
      "     ------------------                      95.4/198.5 MB 1.3 MB/s eta 0:01:20\n",
      "     ------------------                      95.5/198.5 MB 1.3 MB/s eta 0:01:20\n",
      "     ------------------                      95.5/198.5 MB 1.3 MB/s eta 0:01:20\n",
      "     ------------------                      95.5/198.5 MB 1.3 MB/s eta 0:01:20\n",
      "     ------------------                      95.5/198.5 MB 1.3 MB/s eta 0:01:20\n",
      "     ------------------                      95.5/198.5 MB 1.3 MB/s eta 0:01:21\n",
      "     ------------------                      95.5/198.5 MB 1.3 MB/s eta 0:01:21\n",
      "     ------------------                      95.5/198.5 MB 1.3 MB/s eta 0:01:21\n",
      "     ------------------                      95.6/198.5 MB 1.2 MB/s eta 0:01:23\n",
      "     ------------------                      95.6/198.5 MB 1.2 MB/s eta 0:01:23\n",
      "     ------------------                      95.6/198.5 MB 1.2 MB/s eta 0:01:23\n",
      "     ------------------                      95.6/198.5 MB 1.2 MB/s eta 0:01:23\n",
      "     ------------------                      95.6/198.5 MB 1.2 MB/s eta 0:01:24\n",
      "     ------------------                      95.6/198.5 MB 1.2 MB/s eta 0:01:24\n",
      "     ------------------                      95.6/198.5 MB 1.2 MB/s eta 0:01:24\n",
      "     ------------------                      95.6/198.5 MB 1.2 MB/s eta 0:01:24\n",
      "     ------------------                      95.6/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      95.7/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      95.7/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      95.7/198.5 MB 1.2 MB/s eta 0:01:25\n",
      "     ------------------                      95.7/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      95.7/198.5 MB 1.2 MB/s eta 0:01:26\n",
      "     ------------------                      95.7/198.5 MB 1.2 MB/s eta 0:01:27\n",
      "     ------------------                      95.7/198.5 MB 1.2 MB/s eta 0:01:27\n",
      "     ------------------                      95.7/198.5 MB 1.2 MB/s eta 0:01:27\n",
      "     ------------------                      95.8/198.5 MB 1.2 MB/s eta 0:01:28\n",
      "     ------------------                      95.8/198.5 MB 1.2 MB/s eta 0:01:28\n",
      "     ------------------                      95.8/198.5 MB 1.2 MB/s eta 0:01:28\n",
      "     ------------------                      95.8/198.5 MB 1.2 MB/s eta 0:01:29\n",
      "     ------------------                      95.9/198.5 MB 1.2 MB/s eta 0:01:29\n",
      "     ------------------                      95.9/198.5 MB 1.2 MB/s eta 0:01:29\n",
      "     ------------------                      95.9/198.5 MB 1.2 MB/s eta 0:01:30\n",
      "     ------------------                      95.9/198.5 MB 1.2 MB/s eta 0:01:30\n",
      "     ------------------                      95.9/198.5 MB 1.1 MB/s eta 0:01:30\n",
      "     ------------------                      95.9/198.5 MB 1.1 MB/s eta 0:01:30\n",
      "     ------------------                      96.0/198.5 MB 1.1 MB/s eta 0:01:31\n",
      "     ------------------                      96.0/198.5 MB 1.1 MB/s eta 0:01:31\n",
      "     ------------------                      96.0/198.5 MB 1.1 MB/s eta 0:01:31\n",
      "     ------------------                      96.0/198.5 MB 1.1 MB/s eta 0:01:31\n",
      "     ------------------                      96.0/198.5 MB 1.1 MB/s eta 0:01:31\n",
      "     ------------------                      96.0/198.5 MB 1.1 MB/s eta 0:01:32\n",
      "     ------------------                      96.1/198.5 MB 1.1 MB/s eta 0:01:32\n",
      "     ------------------                      96.1/198.5 MB 1.1 MB/s eta 0:01:32\n",
      "     ------------------                      96.1/198.5 MB 1.1 MB/s eta 0:01:33\n",
      "     ------------------                      96.1/198.5 MB 1.1 MB/s eta 0:01:33\n",
      "     ------------------                      96.1/198.5 MB 1.1 MB/s eta 0:01:33\n",
      "     ------------------                      96.2/198.5 MB 1.1 MB/s eta 0:01:33\n",
      "     ------------------                      96.2/198.5 MB 1.1 MB/s eta 0:01:33\n",
      "     ------------------                      96.2/198.5 MB 1.1 MB/s eta 0:01:33\n",
      "     ------------------                      96.2/198.5 MB 1.1 MB/s eta 0:01:34\n",
      "     ------------------                      96.2/198.5 MB 1.1 MB/s eta 0:01:34\n",
      "     ------------------                      96.2/198.5 MB 1.1 MB/s eta 0:01:34\n",
      "     ------------------                      96.3/198.5 MB 1.1 MB/s eta 0:01:35\n",
      "     ------------------                      96.3/198.5 MB 1.1 MB/s eta 0:01:35\n",
      "     ------------------                      96.3/198.5 MB 1.1 MB/s eta 0:01:35\n",
      "     ------------------                      96.3/198.5 MB 1.1 MB/s eta 0:01:36\n",
      "     ------------------                      96.4/198.5 MB 1.1 MB/s eta 0:01:36\n",
      "     ------------------                      96.4/198.5 MB 1.1 MB/s eta 0:01:36\n",
      "     ------------------                      96.4/198.5 MB 1.1 MB/s eta 0:01:36\n",
      "     ------------------                      96.4/198.5 MB 1.1 MB/s eta 0:01:37\n",
      "     ------------------                      96.5/198.5 MB 1.1 MB/s eta 0:01:37\n",
      "     ------------------                      96.5/198.5 MB 1.1 MB/s eta 0:01:37\n",
      "     ------------------                      96.5/198.5 MB 1.1 MB/s eta 0:01:37\n",
      "     ------------------                      96.5/198.5 MB 1.1 MB/s eta 0:01:37\n",
      "     ------------------                      96.6/198.5 MB 1.1 MB/s eta 0:01:37\n",
      "     ------------------                      96.6/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     ------------------                      96.6/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     ------------------                      96.6/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     ------------------                      96.7/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     -------------------                     96.7/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     -------------------                     96.7/198.5 MB 1.0 MB/s eta 0:01:39\n",
      "     -------------------                     96.7/198.5 MB 1.0 MB/s eta 0:01:39\n",
      "     -------------------                     96.8/198.5 MB 1.0 MB/s eta 0:01:39\n",
      "     -------------------                     96.8/198.5 MB 1.0 MB/s eta 0:01:40\n",
      "     -------------------                     96.8/198.5 MB 1.0 MB/s eta 0:01:40\n",
      "     -------------------                     96.9/198.5 MB 1.0 MB/s eta 0:01:39\n",
      "     -------------------                     97.0/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     -------------------                     97.0/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     -------------------                     97.0/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     -------------------                     97.1/198.5 MB 1.0 MB/s eta 0:01:39\n",
      "     -------------------                     97.1/198.5 MB 1.0 MB/s eta 0:01:39\n",
      "     -------------------                     97.2/198.5 MB 1.0 MB/s eta 0:01:39\n",
      "     -------------------                     97.2/198.5 MB 1.0 MB/s eta 0:01:39\n",
      "     -------------------                     97.2/198.5 MB 1.0 MB/s eta 0:01:39\n",
      "     -------------------                     97.2/198.5 MB 1.0 MB/s eta 0:01:39\n",
      "     -------------------                     97.2/198.5 MB 1.0 MB/s eta 0:01:39\n",
      "     -------------------                     97.4/198.5 MB 1.0 MB/s eta 0:01:39\n",
      "     -------------------                     97.5/198.5 MB 1.0 MB/s eta 0:01:40\n",
      "     -------------------                     97.5/198.5 MB 1.0 MB/s eta 0:01:40\n",
      "     -------------------                     97.6/198.5 MB 1.0 MB/s eta 0:01:39\n",
      "     -------------------                     97.6/198.5 MB 1.0 MB/s eta 0:01:40\n",
      "     -------------------                     97.6/198.5 MB 1.0 MB/s eta 0:01:40\n",
      "     -------------------                     97.7/198.5 MB 1.0 MB/s eta 0:01:41\n",
      "     -------------------                     97.7/198.5 MB 1.0 MB/s eta 0:01:41\n",
      "     -------------------                     97.8/198.5 MB 1.0 MB/s eta 0:01:41\n",
      "     -------------------                     97.9/198.5 MB 1.0 MB/s eta 0:01:40\n",
      "     -------------------                     98.0/198.5 MB 1.0 MB/s eta 0:01:40\n",
      "     -------------------                     98.0/198.5 MB 1.0 MB/s eta 0:01:41\n",
      "     ------------------                    98.0/198.5 MB 999.5 kB/s eta 0:01:41\n",
      "     -------------------                     98.0/198.5 MB 1.0 MB/s eta 0:01:41\n",
      "     -------------------                     98.1/198.5 MB 1.0 MB/s eta 0:01:41\n",
      "     ------------------                    98.1/198.5 MB 998.0 kB/s eta 0:01:41\n",
      "     -------------------                     98.2/198.5 MB 1.0 MB/s eta 0:01:40\n",
      "     -------------------                     98.2/198.5 MB 1.0 MB/s eta 0:01:40\n",
      "     ------------------                    98.2/198.5 MB 998.0 kB/s eta 0:01:41\n",
      "     ------------------                    98.3/198.5 MB 996.6 kB/s eta 0:01:41\n",
      "     ------------------                    98.3/198.5 MB 993.5 kB/s eta 0:01:41\n",
      "     ------------------                    98.4/198.5 MB 992.0 kB/s eta 0:01:41\n",
      "     ------------------                    98.5/198.5 MB 991.9 kB/s eta 0:01:41\n",
      "     ------------------                    98.6/198.5 MB 993.5 kB/s eta 0:01:41\n",
      "     ------------------                    98.7/198.5 MB 992.0 kB/s eta 0:01:41\n",
      "     ------------------                    98.7/198.5 MB 989.0 kB/s eta 0:01:41\n",
      "     ------------------                    98.8/198.5 MB 987.4 kB/s eta 0:01:41\n",
      "     ------------------                    98.8/198.5 MB 989.0 kB/s eta 0:01:41\n",
      "     ------------------                    98.8/198.5 MB 989.0 kB/s eta 0:01:41\n",
      "     ------------------                    98.9/198.5 MB 980.0 kB/s eta 0:01:42\n",
      "     ------------------                    99.0/198.5 MB 981.6 kB/s eta 0:01:42\n",
      "     ------------------                    99.1/198.5 MB 989.0 kB/s eta 0:01:41\n",
      "     ------------------                    99.1/198.5 MB 989.0 kB/s eta 0:01:41\n",
      "     ------------------                    99.2/198.5 MB 981.6 kB/s eta 0:01:42\n",
      "     ------------------                    99.2/198.5 MB 986.0 kB/s eta 0:01:41\n",
      "     ------------------                    99.2/198.5 MB 986.0 kB/s eta 0:01:41\n",
      "     ------------------                    99.2/198.5 MB 978.5 kB/s eta 0:01:42\n",
      "     ------------------                    99.3/198.5 MB 984.5 kB/s eta 0:01:41\n",
      "     ------------------                    99.4/198.5 MB 984.6 kB/s eta 0:01:41\n",
      "     ------------------                    99.5/198.5 MB 989.0 kB/s eta 0:01:41\n",
      "     ------------------                    99.6/198.5 MB 989.0 kB/s eta 0:01:41\n",
      "     ------------------                    99.7/198.5 MB 990.4 kB/s eta 0:01:40\n",
      "     ------------------                    99.8/198.5 MB 998.0 kB/s eta 0:01:39\n",
      "     ------------------                    99.9/198.5 MB 999.6 kB/s eta 0:01:39\n",
      "     -------------------                    100.0/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     -------------------                    100.2/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     -------------------                    100.2/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     -------------------                    100.4/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     -------------------                    100.4/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     -------------------                    100.5/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     -------------------                    100.6/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     -------------------                    100.6/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     -------------------                    100.6/198.5 MB 1.0 MB/s eta 0:01:38\n",
      "     ------------------                   100.7/198.5 MB 998.0 kB/s eta 0:01:39\n",
      "     ------------------                   100.8/198.5 MB 996.5 kB/s eta 0:01:39\n",
      "     ------------------                   100.8/198.5 MB 995.0 kB/s eta 0:01:39\n",
      "     ------------------                   100.8/198.5 MB 995.0 kB/s eta 0:01:39\n",
      "     ------------------                   100.8/198.5 MB 987.4 kB/s eta 0:01:39\n",
      "     ------------------                   100.9/198.5 MB 987.4 kB/s eta 0:01:39\n",
      "     ------------------                   100.9/198.5 MB 983.0 kB/s eta 0:01:40\n",
      "     ------------------                   101.0/198.5 MB 981.6 kB/s eta 0:01:40\n",
      "     ------------------                   101.1/198.5 MB 986.0 kB/s eta 0:01:39\n",
      "     ------------------                   101.2/198.5 MB 998.0 kB/s eta 0:01:38\n",
      "     ------------------                   101.3/198.5 MB 999.5 kB/s eta 0:01:38\n",
      "     ------------------                   101.3/198.5 MB 998.0 kB/s eta 0:01:38\n",
      "     ------------------                   101.3/198.5 MB 994.9 kB/s eta 0:01:38\n",
      "     ------------------                   101.4/198.5 MB 992.0 kB/s eta 0:01:38\n",
      "     ------------------                   101.5/198.5 MB 990.5 kB/s eta 0:01:38\n",
      "     ------------------                   101.5/198.5 MB 989.0 kB/s eta 0:01:39\n",
      "     ------------------                   101.6/198.5 MB 986.0 kB/s eta 0:01:39\n",
      "     ------------------                   101.7/198.5 MB 991.9 kB/s eta 0:01:38\n",
      "     ------------------                   101.7/198.5 MB 991.9 kB/s eta 0:01:38\n",
      "     ------------------                   101.7/198.5 MB 991.9 kB/s eta 0:01:38\n",
      "     ------------------                   101.8/198.5 MB 984.5 kB/s eta 0:01:39\n",
      "     ------------------                   101.8/198.5 MB 980.0 kB/s eta 0:01:39\n",
      "     ------------------                   101.8/198.5 MB 980.0 kB/s eta 0:01:39\n",
      "     ------------------                   101.8/198.5 MB 980.0 kB/s eta 0:01:39\n",
      "     ------------------                   101.9/198.5 MB 974.3 kB/s eta 0:01:40\n",
      "     ------------------                   102.0/198.5 MB 978.6 kB/s eta 0:01:39\n",
      "     ------------------                   102.1/198.5 MB 980.0 kB/s eta 0:01:39\n",
      "     ------------------                   102.1/198.5 MB 980.0 kB/s eta 0:01:39\n",
      "     ------------------                   102.3/198.5 MB 975.7 kB/s eta 0:01:39\n",
      "     ------------------                   102.4/198.5 MB 975.7 kB/s eta 0:01:39\n",
      "     ------------------                   102.5/198.5 MB 984.6 kB/s eta 0:01:38\n",
      "     ------------------                   102.6/198.5 MB 984.6 kB/s eta 0:01:38\n",
      "     ------------------                   102.7/198.5 MB 989.0 kB/s eta 0:01:37\n",
      "     ------------------                   102.8/198.5 MB 987.5 kB/s eta 0:01:37\n",
      "     ------------------                   102.8/198.5 MB 987.5 kB/s eta 0:01:37\n",
      "     ------------------                   102.8/198.5 MB 978.6 kB/s eta 0:01:38\n",
      "     ------------------                   102.8/198.5 MB 978.6 kB/s eta 0:01:38\n",
      "     ------------------                   102.9/198.5 MB 974.3 kB/s eta 0:01:39\n",
      "     ------------------                   102.9/198.5 MB 974.3 kB/s eta 0:01:39\n",
      "     ------------------                   102.9/198.5 MB 967.0 kB/s eta 0:01:39\n",
      "     ------------------                   102.9/198.5 MB 962.8 kB/s eta 0:01:40\n",
      "     ------------------                   103.0/198.5 MB 967.1 kB/s eta 0:01:39\n",
      "     ------------------                   103.0/198.5 MB 968.5 kB/s eta 0:01:39\n",
      "     ------------------                   103.2/198.5 MB 964.3 kB/s eta 0:01:39\n",
      "     ------------------                   103.3/198.5 MB 961.4 kB/s eta 0:01:40\n",
      "     ------------------                   103.3/198.5 MB 958.6 kB/s eta 0:01:40\n",
      "     ------------------                   103.3/198.5 MB 957.1 kB/s eta 0:01:40\n",
      "     ------------------                   103.6/198.5 MB 958.6 kB/s eta 0:01:40\n",
      "     ------------------                   103.7/198.5 MB 980.1 kB/s eta 0:01:37\n",
      "     ------------------                   103.8/198.5 MB 984.6 kB/s eta 0:01:37\n",
      "     ------------------                   103.9/198.5 MB 984.5 kB/s eta 0:01:37\n",
      "     ------------------                   103.9/198.5 MB 983.1 kB/s eta 0:01:37\n",
      "     ------------------                   103.9/198.5 MB 980.0 kB/s eta 0:01:37\n",
      "     ------------------                   103.9/198.5 MB 980.0 kB/s eta 0:01:37\n",
      "     ------------------                   103.9/198.5 MB 980.0 kB/s eta 0:01:37\n",
      "     ------------------                   103.9/198.5 MB 968.5 kB/s eta 0:01:38\n",
      "     ------------------                   103.9/198.5 MB 968.5 kB/s eta 0:01:38\n",
      "     ------------------                   104.0/198.5 MB 958.6 kB/s eta 0:01:39\n",
      "     ------------------                   104.0/198.5 MB 958.6 kB/s eta 0:01:39\n",
      "     ------------------                   104.0/198.5 MB 962.8 kB/s eta 0:01:39\n",
      "     ------------------                   104.0/198.5 MB 969.9 kB/s eta 0:01:38\n",
      "     ------------------                   104.1/198.5 MB 975.7 kB/s eta 0:01:37\n",
      "     ------------------                   104.2/198.5 MB 975.7 kB/s eta 0:01:37\n",
      "     ------------------                   104.2/198.5 MB 975.7 kB/s eta 0:01:37\n",
      "     ------------------                   104.2/198.5 MB 975.7 kB/s eta 0:01:37\n",
      "     ------------------                   104.2/198.5 MB 964.3 kB/s eta 0:01:38\n",
      "     ------------------                   104.2/198.5 MB 964.3 kB/s eta 0:01:38\n",
      "     ------------------                   104.3/198.5 MB 960.0 kB/s eta 0:01:39\n",
      "     ------------------                   104.4/198.5 MB 971.4 kB/s eta 0:01:37\n",
      "     ------------------                   104.5/198.5 MB 974.3 kB/s eta 0:01:37\n",
      "     ------------------                   104.5/198.5 MB 974.3 kB/s eta 0:01:37\n",
      "     ------------------                   104.5/198.5 MB 967.1 kB/s eta 0:01:38\n",
      "     ------------------                   104.5/198.5 MB 964.2 kB/s eta 0:01:38\n",
      "     ------------------                   104.5/198.5 MB 964.3 kB/s eta 0:01:38\n",
      "     ------------------                   104.6/198.5 MB 957.2 kB/s eta 0:01:39\n",
      "     ------------------                   104.7/198.5 MB 960.0 kB/s eta 0:01:38\n",
      "     -------------------                  104.8/198.5 MB 972.9 kB/s eta 0:01:37\n",
      "     -------------------                  104.9/198.5 MB 977.1 kB/s eta 0:01:36\n",
      "     -------------------                  104.9/198.5 MB 975.7 kB/s eta 0:01:36\n",
      "     -------------------                  105.0/198.5 MB 971.4 kB/s eta 0:01:37\n",
      "     -------------------                  105.0/198.5 MB 971.3 kB/s eta 0:01:37\n",
      "     -------------------                  105.0/198.5 MB 968.5 kB/s eta 0:01:37\n",
      "     -------------------                  105.1/198.5 MB 965.7 kB/s eta 0:01:37\n",
      "     -------------------                  105.1/198.5 MB 965.7 kB/s eta 0:01:37\n",
      "     -------------------                  105.2/198.5 MB 961.4 kB/s eta 0:01:38\n",
      "     -------------------                  105.2/198.5 MB 960.0 kB/s eta 0:01:38\n",
      "     -------------------                  105.3/198.5 MB 954.4 kB/s eta 0:01:38\n",
      "     -------------------                  105.3/198.5 MB 953.0 kB/s eta 0:01:38\n",
      "     -------------------                  105.3/198.5 MB 953.0 kB/s eta 0:01:38\n",
      "     -------------------                  105.3/198.5 MB 953.0 kB/s eta 0:01:38\n",
      "     -------------------                  105.3/198.5 MB 943.4 kB/s eta 0:01:39\n",
      "     -------------------                  105.4/198.5 MB 939.3 kB/s eta 0:01:40\n",
      "     -------------------                  105.5/198.5 MB 939.3 kB/s eta 0:01:40\n",
      "     -------------------                  105.7/198.5 MB 944.8 kB/s eta 0:01:39\n",
      "     -------------------                  105.7/198.5 MB 943.4 kB/s eta 0:01:39\n",
      "     -------------------                  105.7/198.5 MB 943.4 kB/s eta 0:01:39\n",
      "     -------------------                  105.8/198.5 MB 939.4 kB/s eta 0:01:39\n",
      "     -------------------                  105.8/198.5 MB 984.6 kB/s eta 0:01:35\n",
      "     --------------------                   105.9/198.5 MB 1.0 MB/s eta 0:01:33\n",
      "     --------------------                   106.0/198.5 MB 1.0 MB/s eta 0:01:30\n",
      "     --------------------                   106.2/198.5 MB 1.1 MB/s eta 0:01:27\n",
      "     --------------------                   106.3/198.5 MB 1.1 MB/s eta 0:01:25\n",
      "     --------------------                   106.4/198.5 MB 1.1 MB/s eta 0:01:23\n",
      "     --------------------                   106.5/198.5 MB 1.2 MB/s eta 0:01:20\n",
      "     --------------------                   106.6/198.5 MB 1.2 MB/s eta 0:01:19\n",
      "     --------------------                   106.6/198.5 MB 1.2 MB/s eta 0:01:19\n",
      "     --------------------                   106.6/198.5 MB 1.2 MB/s eta 0:01:19\n",
      "     --------------------                   106.8/198.5 MB 1.2 MB/s eta 0:01:18\n",
      "     --------------------                   107.0/198.5 MB 1.2 MB/s eta 0:01:14\n",
      "     --------------------                   107.1/198.5 MB 1.2 MB/s eta 0:01:14\n",
      "     --------------------                   107.2/198.5 MB 1.3 MB/s eta 0:01:13\n",
      "     --------------------                   107.2/198.5 MB 1.3 MB/s eta 0:01:13\n",
      "     --------------------                   107.2/198.5 MB 1.3 MB/s eta 0:01:13\n",
      "     --------------------                   107.2/198.5 MB 1.2 MB/s eta 0:01:14\n",
      "     --------------------                   107.5/198.5 MB 1.3 MB/s eta 0:01:12\n",
      "     --------------------                   107.6/198.5 MB 1.3 MB/s eta 0:01:11\n",
      "     --------------------                   107.7/198.5 MB 1.3 MB/s eta 0:01:11\n",
      "     --------------------                   107.8/198.5 MB 1.3 MB/s eta 0:01:09\n",
      "     --------------------                   108.0/198.5 MB 1.3 MB/s eta 0:01:09\n",
      "     --------------------                   108.1/198.5 MB 1.3 MB/s eta 0:01:09\n",
      "     --------------------                   108.1/198.5 MB 1.3 MB/s eta 0:01:09\n",
      "     --------------------                   108.3/198.5 MB 1.3 MB/s eta 0:01:08\n",
      "     --------------------                   108.3/198.5 MB 1.3 MB/s eta 0:01:08\n",
      "     --------------------                   108.5/198.5 MB 1.4 MB/s eta 0:01:06\n",
      "     --------------------                   108.5/198.5 MB 1.4 MB/s eta 0:01:06\n",
      "     --------------------                   108.6/198.5 MB 1.4 MB/s eta 0:01:06\n",
      "     --------------------                   108.6/198.5 MB 1.4 MB/s eta 0:01:06\n",
      "     --------------------                   108.7/198.5 MB 1.4 MB/s eta 0:01:06\n",
      "     --------------------                   108.7/198.5 MB 1.4 MB/s eta 0:01:06\n",
      "     --------------------                   108.8/198.5 MB 1.4 MB/s eta 0:01:06\n",
      "     --------------------                   108.9/198.5 MB 1.4 MB/s eta 0:01:06\n",
      "     --------------------                   108.9/198.5 MB 1.4 MB/s eta 0:01:06\n",
      "     --------------------                   109.0/198.5 MB 1.4 MB/s eta 0:01:06\n",
      "     --------------------                   109.1/198.5 MB 1.4 MB/s eta 0:01:05\n",
      "     --------------------                   109.2/198.5 MB 1.4 MB/s eta 0:01:05\n",
      "     --------------------                   109.3/198.5 MB 1.4 MB/s eta 0:01:05\n",
      "     --------------------                   109.4/198.5 MB 1.4 MB/s eta 0:01:04\n",
      "     --------------------                   109.5/198.5 MB 1.4 MB/s eta 0:01:03\n",
      "     --------------------                   109.6/198.5 MB 1.4 MB/s eta 0:01:03\n",
      "     ---------------------                  109.7/198.5 MB 1.4 MB/s eta 0:01:03\n",
      "     ---------------------                  109.8/198.5 MB 1.4 MB/s eta 0:01:03\n",
      "     ---------------------                  109.9/198.5 MB 1.4 MB/s eta 0:01:03\n",
      "     ---------------------                  110.0/198.5 MB 1.4 MB/s eta 0:01:03\n",
      "     ---------------------                  110.1/198.5 MB 1.4 MB/s eta 0:01:03\n",
      "     ---------------------                  110.2/198.5 MB 1.4 MB/s eta 0:01:03\n",
      "     ---------------------                  110.3/198.5 MB 1.4 MB/s eta 0:01:03\n",
      "     ---------------------                  110.4/198.5 MB 1.4 MB/s eta 0:01:03\n",
      "     ---------------------                  110.5/198.5 MB 1.4 MB/s eta 0:01:03\n",
      "     ---------------------                  110.6/198.5 MB 1.4 MB/s eta 0:01:03\n",
      "     ---------------------                  110.7/198.5 MB 1.4 MB/s eta 0:01:02\n",
      "     ---------------------                  110.7/198.5 MB 1.4 MB/s eta 0:01:02\n",
      "     ---------------------                  110.8/198.5 MB 1.4 MB/s eta 0:01:02\n",
      "     ---------------------                  110.9/198.5 MB 1.4 MB/s eta 0:01:02\n",
      "     ---------------------                  110.9/198.5 MB 1.4 MB/s eta 0:01:02\n",
      "     ---------------------                  111.0/198.5 MB 1.4 MB/s eta 0:01:01\n",
      "     ---------------------                  111.1/198.5 MB 1.4 MB/s eta 0:01:01\n",
      "     ---------------------                  111.2/198.5 MB 1.5 MB/s eta 0:01:00\n",
      "     ---------------------                  111.3/198.5 MB 1.5 MB/s eta 0:01:00\n",
      "     ---------------------                  111.3/198.5 MB 1.5 MB/s eta 0:01:00\n",
      "     ---------------------                  111.4/198.5 MB 1.5 MB/s eta 0:01:00\n",
      "     ---------------------                  111.6/198.5 MB 1.5 MB/s eta 0:00:59\n",
      "     ---------------------                  111.7/198.5 MB 1.5 MB/s eta 0:00:59\n",
      "     ---------------------                  111.8/198.5 MB 1.5 MB/s eta 0:00:59\n",
      "     ---------------------                  111.9/198.5 MB 1.5 MB/s eta 0:00:59\n",
      "     ---------------------                  112.0/198.5 MB 1.5 MB/s eta 0:00:58\n",
      "     ---------------------                  112.1/198.5 MB 1.5 MB/s eta 0:00:57\n",
      "     ---------------------                  112.2/198.5 MB 1.5 MB/s eta 0:00:56\n",
      "     ---------------------                  112.3/198.5 MB 1.6 MB/s eta 0:00:56\n",
      "     ---------------------                  112.4/198.5 MB 1.5 MB/s eta 0:00:56\n",
      "     ---------------------                  112.5/198.5 MB 1.5 MB/s eta 0:00:56\n",
      "     ---------------------                  112.6/198.5 MB 1.5 MB/s eta 0:00:56\n",
      "     ---------------------                  112.6/198.5 MB 1.5 MB/s eta 0:00:56\n",
      "     ---------------------                  112.8/198.5 MB 1.5 MB/s eta 0:00:56\n",
      "     ---------------------                  112.9/198.5 MB 1.5 MB/s eta 0:00:56\n",
      "     ---------------------                  113.0/198.5 MB 1.5 MB/s eta 0:00:56\n",
      "     ---------------------                  113.1/198.5 MB 1.6 MB/s eta 0:00:55\n",
      "     ---------------------                  113.2/198.5 MB 1.6 MB/s eta 0:00:54\n",
      "     ---------------------                  113.3/198.5 MB 1.6 MB/s eta 0:00:54\n",
      "     ---------------------                  113.3/198.5 MB 1.6 MB/s eta 0:00:54\n",
      "     ---------------------                  113.5/198.5 MB 1.6 MB/s eta 0:00:54\n",
      "     ---------------------                  113.5/198.5 MB 1.6 MB/s eta 0:00:53\n",
      "     ---------------------                  113.6/198.5 MB 1.6 MB/s eta 0:00:53\n",
      "     ---------------------                  113.7/198.5 MB 1.6 MB/s eta 0:00:53\n",
      "     ---------------------                  113.8/198.5 MB 1.6 MB/s eta 0:00:53\n",
      "     ---------------------                  113.9/198.5 MB 1.6 MB/s eta 0:00:54\n",
      "     ---------------------                  114.0/198.5 MB 1.6 MB/s eta 0:00:53\n",
      "     ---------------------                  114.1/198.5 MB 1.6 MB/s eta 0:00:54\n",
      "     ---------------------                  114.1/198.5 MB 1.6 MB/s eta 0:00:53\n",
      "     ---------------------                  114.2/198.5 MB 1.7 MB/s eta 0:00:50\n",
      "     ---------------------                  114.3/198.5 MB 1.7 MB/s eta 0:00:50\n",
      "     ---------------------                  114.4/198.5 MB 1.7 MB/s eta 0:00:50\n",
      "     ---------------------                  114.5/198.5 MB 1.7 MB/s eta 0:00:49\n",
      "     ---------------------                  114.6/198.5 MB 1.7 MB/s eta 0:00:49\n",
      "     ---------------------                  114.6/198.5 MB 1.7 MB/s eta 0:00:49\n",
      "     ---------------------                  114.7/198.5 MB 1.8 MB/s eta 0:00:47\n",
      "     ---------------------                  114.8/198.5 MB 1.8 MB/s eta 0:00:47\n",
      "     ---------------------                  114.8/198.5 MB 1.8 MB/s eta 0:00:47\n",
      "     ---------------------                  114.8/198.5 MB 1.8 MB/s eta 0:00:48\n",
      "     ----------------------                 115.0/198.5 MB 1.8 MB/s eta 0:00:47\n",
      "     ----------------------                 115.1/198.5 MB 1.8 MB/s eta 0:00:47\n",
      "     ----------------------                 115.2/198.5 MB 1.8 MB/s eta 0:00:46\n",
      "     ----------------------                 115.3/198.5 MB 1.9 MB/s eta 0:00:45\n",
      "     ----------------------                 115.4/198.5 MB 1.9 MB/s eta 0:00:45\n",
      "     ----------------------                 115.5/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 115.6/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 115.7/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 115.8/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 115.9/198.5 MB 1.9 MB/s eta 0:00:44\n",
      "     ----------------------                 116.0/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 116.1/198.5 MB 2.0 MB/s eta 0:00:43\n",
      "     ----------------------                 116.2/198.5 MB 2.0 MB/s eta 0:00:42\n",
      "     ----------------------                 116.3/198.5 MB 2.0 MB/s eta 0:00:43\n",
      "     ----------------------                 116.4/198.5 MB 2.0 MB/s eta 0:00:43\n",
      "     ----------------------                 116.4/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 116.5/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 116.6/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 116.6/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 116.7/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 116.8/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 116.9/198.5 MB 2.0 MB/s eta 0:00:42\n",
      "     ----------------------                 116.9/198.5 MB 1.9 MB/s eta 0:00:42\n",
      "     ----------------------                 117.0/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 117.1/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 117.1/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 117.2/198.5 MB 1.9 MB/s eta 0:00:44\n",
      "     ----------------------                 117.3/198.5 MB 1.9 MB/s eta 0:00:44\n",
      "     ----------------------                 117.3/198.5 MB 1.9 MB/s eta 0:00:44\n",
      "     ----------------------                 117.4/198.5 MB 1.9 MB/s eta 0:00:44\n",
      "     ----------------------                 117.4/198.5 MB 1.9 MB/s eta 0:00:44\n",
      "     ----------------------                 117.5/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 117.5/198.5 MB 1.9 MB/s eta 0:00:43\n",
      "     ----------------------                 117.6/198.5 MB 1.9 MB/s eta 0:00:44\n",
      "     ----------------------                 117.6/198.5 MB 1.9 MB/s eta 0:00:44\n",
      "     ----------------------                 117.6/198.5 MB 1.8 MB/s eta 0:00:44\n",
      "     ----------------------                 117.7/198.5 MB 1.8 MB/s eta 0:00:45\n",
      "     ----------------------                 117.7/198.5 MB 1.8 MB/s eta 0:00:45\n",
      "     ----------------------                 117.7/198.5 MB 1.8 MB/s eta 0:00:45\n",
      "     ----------------------                 117.8/198.5 MB 1.8 MB/s eta 0:00:46\n",
      "     ----------------------                 117.8/198.5 MB 1.8 MB/s eta 0:00:46\n",
      "     ----------------------                 117.9/198.5 MB 1.8 MB/s eta 0:00:46\n",
      "     ----------------------                 118.0/198.5 MB 1.8 MB/s eta 0:00:46\n",
      "     ----------------------                 118.0/198.5 MB 1.8 MB/s eta 0:00:46\n",
      "     ----------------------                 118.1/198.5 MB 1.8 MB/s eta 0:00:46\n",
      "     ----------------------                 118.2/198.5 MB 1.8 MB/s eta 0:00:46\n",
      "     ----------------------                 118.2/198.5 MB 1.8 MB/s eta 0:00:46\n",
      "     ----------------------                 118.3/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     ----------------------                 118.4/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     ----------------------                 118.4/198.5 MB 1.8 MB/s eta 0:00:46\n",
      "     ----------------------                 118.5/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     ----------------------                 118.6/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     ----------------------                 118.7/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     ----------------------                 118.7/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     ----------------------                 118.8/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     ----------------------                 118.9/198.5 MB 1.8 MB/s eta 0:00:46\n",
      "     ----------------------                 119.0/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     ----------------------                 119.0/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     ----------------------                 119.1/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     ----------------------                 119.1/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     ----------------------                 119.1/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     ----------------------                 119.1/198.5 MB 1.7 MB/s eta 0:00:47\n",
      "     ----------------------                 119.2/198.5 MB 1.7 MB/s eta 0:00:47\n",
      "     ----------------------                 119.3/198.5 MB 1.7 MB/s eta 0:00:47\n",
      "     ----------------------                 119.3/198.5 MB 1.7 MB/s eta 0:00:47\n",
      "     ----------------------                 119.4/198.5 MB 1.7 MB/s eta 0:00:47\n",
      "     ----------------------                 119.4/198.5 MB 1.7 MB/s eta 0:00:47\n",
      "     ----------------------                 119.5/198.5 MB 1.7 MB/s eta 0:00:48\n",
      "     ----------------------                 119.5/198.5 MB 1.7 MB/s eta 0:00:48\n",
      "     ----------------------                 119.5/198.5 MB 1.7 MB/s eta 0:00:48\n",
      "     ----------------------                 119.6/198.5 MB 1.7 MB/s eta 0:00:48\n",
      "     ----------------------                 119.7/198.5 MB 1.7 MB/s eta 0:00:48\n",
      "     ----------------------                 119.8/198.5 MB 1.7 MB/s eta 0:00:48\n",
      "     ----------------------                 119.9/198.5 MB 1.7 MB/s eta 0:00:48\n",
      "     ----------------------                 120.0/198.5 MB 1.6 MB/s eta 0:00:48\n",
      "     ----------------------                 120.1/198.5 MB 1.7 MB/s eta 0:00:48\n",
      "     -----------------------                120.2/198.5 MB 1.7 MB/s eta 0:00:48\n",
      "     -----------------------                120.3/198.5 MB 1.7 MB/s eta 0:00:48\n",
      "     -----------------------                120.4/198.5 MB 1.7 MB/s eta 0:00:48\n",
      "     -----------------------                120.5/198.5 MB 1.6 MB/s eta 0:00:48\n",
      "     -----------------------                120.6/198.5 MB 1.7 MB/s eta 0:00:48\n",
      "     -----------------------                120.6/198.5 MB 1.6 MB/s eta 0:00:48\n",
      "     -----------------------                120.7/198.5 MB 1.6 MB/s eta 0:00:48\n",
      "     -----------------------                120.8/198.5 MB 1.6 MB/s eta 0:00:48\n",
      "     -----------------------                121.0/198.5 MB 1.7 MB/s eta 0:00:47\n",
      "     -----------------------                121.1/198.5 MB 1.7 MB/s eta 0:00:47\n",
      "     -----------------------                121.2/198.5 MB 1.7 MB/s eta 0:00:47\n",
      "     -----------------------                121.3/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     -----------------------                121.4/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     -----------------------                121.5/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     -----------------------                121.6/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     -----------------------                121.7/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     -----------------------                121.8/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     -----------------------                122.0/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     -----------------------                122.1/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     -----------------------                122.2/198.5 MB 1.7 MB/s eta 0:00:45\n",
      "     -----------------------                122.3/198.5 MB 1.7 MB/s eta 0:00:45\n",
      "     -----------------------                122.4/198.5 MB 1.7 MB/s eta 0:00:45\n",
      "     -----------------------                122.4/198.5 MB 1.7 MB/s eta 0:00:45\n",
      "     -----------------------                122.4/198.5 MB 1.7 MB/s eta 0:00:45\n",
      "     -----------------------                122.5/198.5 MB 1.7 MB/s eta 0:00:46\n",
      "     -----------------------                122.8/198.5 MB 1.7 MB/s eta 0:00:45\n",
      "     -----------------------                122.9/198.5 MB 1.7 MB/s eta 0:00:44\n",
      "     -----------------------                123.0/198.5 MB 1.7 MB/s eta 0:00:44\n",
      "     -----------------------                123.1/198.5 MB 1.7 MB/s eta 0:00:44\n",
      "     -----------------------                123.2/198.5 MB 1.7 MB/s eta 0:00:44\n",
      "     -----------------------                123.3/198.5 MB 1.7 MB/s eta 0:00:44\n",
      "     -----------------------                123.4/198.5 MB 1.7 MB/s eta 0:00:44\n",
      "     -----------------------                123.5/198.5 MB 1.7 MB/s eta 0:00:44\n",
      "     -----------------------                123.6/198.5 MB 1.7 MB/s eta 0:00:44\n",
      "     -----------------------                123.7/198.5 MB 1.7 MB/s eta 0:00:44\n",
      "     -----------------------                123.8/198.5 MB 1.7 MB/s eta 0:00:44\n",
      "     -----------------------                123.9/198.5 MB 1.7 MB/s eta 0:00:44\n",
      "     -----------------------                124.0/198.5 MB 1.7 MB/s eta 0:00:44\n",
      "     -----------------------                124.1/198.5 MB 1.7 MB/s eta 0:00:44\n",
      "     -----------------------                124.2/198.5 MB 1.7 MB/s eta 0:00:43\n",
      "     -----------------------                124.3/198.5 MB 1.7 MB/s eta 0:00:43\n",
      "     -----------------------                124.4/198.5 MB 1.7 MB/s eta 0:00:43\n",
      "     -----------------------                124.5/198.5 MB 1.7 MB/s eta 0:00:43\n",
      "     -----------------------                124.6/198.5 MB 1.7 MB/s eta 0:00:43\n",
      "     -----------------------                124.7/198.5 MB 1.8 MB/s eta 0:00:43\n",
      "     -----------------------                124.8/198.5 MB 1.8 MB/s eta 0:00:43\n",
      "     -----------------------                124.9/198.5 MB 1.8 MB/s eta 0:00:43\n",
      "     -----------------------                125.0/198.5 MB 1.8 MB/s eta 0:00:42\n",
      "     -----------------------                125.1/198.5 MB 1.8 MB/s eta 0:00:42\n",
      "     -----------------------                125.2/198.5 MB 1.8 MB/s eta 0:00:42\n",
      "     -----------------------                125.2/198.5 MB 1.8 MB/s eta 0:00:42\n",
      "     -----------------------                125.4/198.5 MB 1.8 MB/s eta 0:00:42\n",
      "     ------------------------               125.4/198.5 MB 1.8 MB/s eta 0:00:42\n",
      "     ------------------------               125.6/198.5 MB 1.8 MB/s eta 0:00:42\n",
      "     ------------------------               125.7/198.5 MB 1.8 MB/s eta 0:00:42\n",
      "     ------------------------               125.7/198.5 MB 1.8 MB/s eta 0:00:42\n",
      "     ------------------------               125.8/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               125.9/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               126.0/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               126.0/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               126.2/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               126.3/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               126.4/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               126.4/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               126.5/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               126.6/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               126.8/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               126.8/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               126.9/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               127.0/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               127.1/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               127.1/198.5 MB 1.8 MB/s eta 0:00:41\n",
      "     ------------------------               127.3/198.5 MB 1.8 MB/s eta 0:00:40\n",
      "     ------------------------               127.4/198.5 MB 1.8 MB/s eta 0:00:40\n",
      "     ------------------------               127.5/198.5 MB 1.8 MB/s eta 0:00:40\n",
      "     ------------------------               127.6/198.5 MB 1.8 MB/s eta 0:00:40\n",
      "     ------------------------               127.7/198.5 MB 1.8 MB/s eta 0:00:39\n",
      "     ------------------------               127.8/198.5 MB 1.8 MB/s eta 0:00:39\n",
      "     ------------------------               127.8/198.5 MB 1.9 MB/s eta 0:00:38\n",
      "     ------------------------               127.8/198.5 MB 1.9 MB/s eta 0:00:38\n",
      "     ------------------------               127.8/198.5 MB 1.9 MB/s eta 0:00:39\n",
      "     ------------------------               127.9/198.5 MB 1.9 MB/s eta 0:00:38\n",
      "     ------------------------               128.1/198.5 MB 1.9 MB/s eta 0:00:38\n",
      "     ------------------------               128.3/198.5 MB 1.9 MB/s eta 0:00:37\n",
      "     ------------------------               128.5/198.5 MB 2.0 MB/s eta 0:00:36\n",
      "     ------------------------               128.6/198.5 MB 2.0 MB/s eta 0:00:36\n",
      "     ------------------------               128.6/198.5 MB 2.0 MB/s eta 0:00:36\n",
      "     ------------------------               128.7/198.5 MB 2.0 MB/s eta 0:00:36\n",
      "     ------------------------               128.8/198.5 MB 2.0 MB/s eta 0:00:36\n",
      "     ------------------------               128.9/198.5 MB 2.0 MB/s eta 0:00:36\n",
      "     ------------------------               129.0/198.5 MB 2.0 MB/s eta 0:00:35\n",
      "     ------------------------               129.1/198.5 MB 2.0 MB/s eta 0:00:35\n",
      "     ------------------------               129.3/198.5 MB 2.0 MB/s eta 0:00:35\n",
      "     ------------------------               129.4/198.5 MB 2.0 MB/s eta 0:00:34\n",
      "     ------------------------               129.5/198.5 MB 2.1 MB/s eta 0:00:34\n",
      "     ------------------------               129.6/198.5 MB 2.1 MB/s eta 0:00:33\n",
      "     ------------------------               129.7/198.5 MB 2.1 MB/s eta 0:00:33\n",
      "     ------------------------               129.8/198.5 MB 2.1 MB/s eta 0:00:33\n",
      "     ------------------------               129.9/198.5 MB 2.1 MB/s eta 0:00:32\n",
      "     ------------------------               130.0/198.5 MB 2.2 MB/s eta 0:00:32\n",
      "     ------------------------               130.1/198.5 MB 2.1 MB/s eta 0:00:32\n",
      "     ------------------------               130.2/198.5 MB 2.2 MB/s eta 0:00:32\n",
      "     ------------------------               130.3/198.5 MB 2.2 MB/s eta 0:00:32\n",
      "     ------------------------               130.4/198.5 MB 2.2 MB/s eta 0:00:32\n",
      "     ------------------------               130.5/198.5 MB 2.2 MB/s eta 0:00:32\n",
      "     -------------------------              130.6/198.5 MB 2.2 MB/s eta 0:00:32\n",
      "     -------------------------              130.7/198.5 MB 2.2 MB/s eta 0:00:32\n",
      "     -------------------------              130.8/198.5 MB 2.2 MB/s eta 0:00:32\n",
      "     -------------------------              131.0/198.5 MB 2.2 MB/s eta 0:00:32\n",
      "     -------------------------              131.0/198.5 MB 2.2 MB/s eta 0:00:32\n",
      "     -------------------------              131.1/198.5 MB 2.2 MB/s eta 0:00:32\n",
      "     -------------------------              131.3/198.5 MB 2.2 MB/s eta 0:00:32\n",
      "     -------------------------              131.4/198.5 MB 2.2 MB/s eta 0:00:32\n",
      "     -------------------------              131.5/198.5 MB 2.2 MB/s eta 0:00:32\n",
      "     -------------------------              131.6/198.5 MB 2.2 MB/s eta 0:00:32\n",
      "     -------------------------              131.7/198.5 MB 2.2 MB/s eta 0:00:31\n",
      "     -------------------------              131.8/198.5 MB 2.2 MB/s eta 0:00:31\n",
      "     -------------------------              131.9/198.5 MB 2.1 MB/s eta 0:00:32\n",
      "     -------------------------              131.9/198.5 MB 2.1 MB/s eta 0:00:32\n",
      "     -------------------------              132.1/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              132.2/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              132.3/198.5 MB 2.2 MB/s eta 0:00:31\n",
      "     -------------------------              132.3/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              132.3/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              132.6/198.5 MB 2.1 MB/s eta 0:00:32\n",
      "     -------------------------              132.7/198.5 MB 2.2 MB/s eta 0:00:31\n",
      "     -------------------------              132.8/198.5 MB 2.2 MB/s eta 0:00:31\n",
      "     -------------------------              132.9/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              133.0/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              133.2/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              133.3/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              133.4/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              133.5/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              133.6/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              133.8/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              133.8/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              133.9/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              134.0/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              134.1/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              134.2/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              134.2/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              134.2/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              134.3/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              134.6/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              134.7/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              134.8/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     -------------------------              134.9/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              135.0/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              135.1/198.5 MB 2.1 MB/s eta 0:00:31\n",
      "     -------------------------              135.2/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     -------------------------              135.3/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     -------------------------              135.4/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     -------------------------              135.4/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     -------------------------              135.5/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     -------------------------              135.6/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     -------------------------              135.8/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     --------------------------             135.9/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     --------------------------             136.0/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     --------------------------             136.1/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     --------------------------             136.1/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     --------------------------             136.2/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     --------------------------             136.3/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     --------------------------             136.4/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     --------------------------             136.5/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     --------------------------             136.6/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     --------------------------             136.7/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     --------------------------             136.8/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     --------------------------             136.9/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     --------------------------             137.0/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     --------------------------             137.1/198.5 MB 2.1 MB/s eta 0:00:30\n",
      "     --------------------------             137.2/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             137.3/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             137.4/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             137.5/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             137.6/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             137.6/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             137.8/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             137.9/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             137.9/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             138.0/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             138.1/198.5 MB 2.2 MB/s eta 0:00:29\n",
      "     --------------------------             138.3/198.5 MB 2.2 MB/s eta 0:00:28\n",
      "     --------------------------             138.4/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             138.5/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             138.6/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             138.7/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             138.7/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             138.8/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             138.8/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             139.0/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             139.1/198.5 MB 2.1 MB/s eta 0:00:29\n",
      "     --------------------------             139.2/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.4/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.4/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.6/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.6/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.6/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     --------------------------             139.8/198.5 MB 2.1 MB/s eta 0:00:28\n",
      "     ---------------------------            143.6/198.5 MB 2.0 MB/s eta 0:00:27\n",
      "     ---------------------------            144.0/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            144.0/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            144.0/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            144.1/198.5 MB 2.1 MB/s eta 0:00:27\n",
      "     ---------------------------            144.3/198.5 MB 2.1 MB/s eta 0:00:27\n",
      "     ---------------------------            144.4/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            144.4/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            144.5/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            144.7/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            144.7/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            144.8/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            144.9/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            145.0/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            145.1/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            145.2/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            145.3/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            145.4/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            145.5/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            145.6/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            145.7/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            145.8/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            145.9/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ---------------------------            146.0/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            146.1/198.5 MB 2.1 MB/s eta 0:00:26\n",
      "     ---------------------------            146.2/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           146.3/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           146.4/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           146.5/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           146.6/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           146.7/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           146.8/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           146.9/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           147.0/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           147.0/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           147.1/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           147.1/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           147.2/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           147.4/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           147.6/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           147.6/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           147.7/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           147.8/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           147.9/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           148.0/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           148.1/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           148.2/198.5 MB 2.1 MB/s eta 0:00:24\n",
      "     ----------------------------           148.3/198.5 MB 2.1 MB/s eta 0:00:24\n",
      "     ----------------------------           148.4/198.5 MB 2.1 MB/s eta 0:00:24\n",
      "     ----------------------------           148.5/198.5 MB 2.1 MB/s eta 0:00:24\n",
      "     ----------------------------           148.6/198.5 MB 2.1 MB/s eta 0:00:24\n",
      "     ----------------------------           148.6/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           148.6/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           148.7/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           148.8/198.5 MB 2.1 MB/s eta 0:00:25\n",
      "     ----------------------------           148.8/198.5 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------------           148.9/198.5 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------------           148.9/198.5 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------------           148.9/198.5 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------------           148.9/198.5 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------------           149.0/198.5 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------------           149.0/198.5 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------------           149.0/198.5 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------------           149.2/198.5 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------------           149.4/198.5 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------------           149.5/198.5 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------------           149.6/198.5 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------------           149.7/198.5 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------------           149.9/198.5 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------------           150.0/198.5 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------------           150.1/198.5 MB 3.1 MB/s eta 0:00:16\n",
      "     ----------------------------           150.2/198.5 MB 3.1 MB/s eta 0:00:16\n",
      "     ----------------------------           150.3/198.5 MB 3.1 MB/s eta 0:00:16\n",
      "     ----------------------------           150.3/198.5 MB 3.1 MB/s eta 0:00:16\n",
      "     ----------------------------           150.3/198.5 MB 3.1 MB/s eta 0:00:16\n",
      "     ----------------------------           150.7/198.5 MB 2.9 MB/s eta 0:00:17\n",
      "     ----------------------------           150.8/198.5 MB 2.9 MB/s eta 0:00:17\n",
      "     ----------------------------           150.9/198.5 MB 2.9 MB/s eta 0:00:17\n",
      "     ----------------------------           151.0/198.5 MB 2.8 MB/s eta 0:00:17\n",
      "     ----------------------------           151.1/198.5 MB 2.8 MB/s eta 0:00:18\n",
      "     ----------------------------           151.2/198.5 MB 2.8 MB/s eta 0:00:18\n",
      "     ----------------------------           151.2/198.5 MB 2.7 MB/s eta 0:00:18\n",
      "     ----------------------------           151.2/198.5 MB 2.7 MB/s eta 0:00:18\n",
      "     ----------------------------           151.3/198.5 MB 2.7 MB/s eta 0:00:18\n",
      "     ----------------------------           151.4/198.5 MB 2.6 MB/s eta 0:00:18\n",
      "     ----------------------------           151.5/198.5 MB 2.6 MB/s eta 0:00:19\n",
      "     -----------------------------          151.7/198.5 MB 2.5 MB/s eta 0:00:19\n",
      "     -----------------------------          151.8/198.5 MB 2.5 MB/s eta 0:00:19\n",
      "     -----------------------------          151.9/198.5 MB 2.5 MB/s eta 0:00:19\n",
      "     -----------------------------          152.1/198.5 MB 2.5 MB/s eta 0:00:19\n",
      "     -----------------------------          152.1/198.5 MB 2.4 MB/s eta 0:00:19\n",
      "     -----------------------------          152.2/198.5 MB 2.4 MB/s eta 0:00:20\n",
      "     -----------------------------          152.3/198.5 MB 2.4 MB/s eta 0:00:20\n",
      "     -----------------------------          152.4/198.5 MB 2.4 MB/s eta 0:00:20\n",
      "     -----------------------------          152.5/198.5 MB 2.3 MB/s eta 0:00:20\n",
      "     -----------------------------          152.6/198.5 MB 2.3 MB/s eta 0:00:20\n",
      "     -----------------------------          152.7/198.5 MB 2.3 MB/s eta 0:00:20\n",
      "     -----------------------------          152.7/198.5 MB 2.3 MB/s eta 0:00:21\n",
      "     -----------------------------          152.8/198.5 MB 2.2 MB/s eta 0:00:21\n",
      "     -----------------------------          152.9/198.5 MB 2.2 MB/s eta 0:00:21\n",
      "     -----------------------------          153.0/198.5 MB 2.2 MB/s eta 0:00:21\n",
      "     -----------------------------          153.1/198.5 MB 2.2 MB/s eta 0:00:21\n",
      "     -----------------------------          153.2/198.5 MB 2.2 MB/s eta 0:00:21\n",
      "     -----------------------------          153.2/198.5 MB 2.2 MB/s eta 0:00:21\n",
      "     -----------------------------          153.2/198.5 MB 2.2 MB/s eta 0:00:21\n",
      "     -----------------------------          153.5/198.5 MB 2.1 MB/s eta 0:00:22\n",
      "     -----------------------------          153.6/198.5 MB 2.1 MB/s eta 0:00:22\n",
      "     -----------------------------          153.7/198.5 MB 2.1 MB/s eta 0:00:22\n",
      "     -----------------------------          153.8/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          153.8/198.5 MB 2.0 MB/s eta 0:00:23\n",
      "     -----------------------------          153.9/198.5 MB 2.0 MB/s eta 0:00:23\n",
      "     -----------------------------          154.0/198.5 MB 2.0 MB/s eta 0:00:23\n",
      "     -----------------------------          154.1/198.5 MB 2.0 MB/s eta 0:00:23\n",
      "     -----------------------------          154.3/198.5 MB 2.0 MB/s eta 0:00:23\n",
      "     -----------------------------          154.3/198.5 MB 2.0 MB/s eta 0:00:23\n",
      "     -----------------------------          154.4/198.5 MB 2.0 MB/s eta 0:00:23\n",
      "     -----------------------------          154.5/198.5 MB 2.0 MB/s eta 0:00:23\n",
      "     -----------------------------          154.6/198.5 MB 2.0 MB/s eta 0:00:23\n",
      "     -----------------------------          154.7/198.5 MB 2.0 MB/s eta 0:00:23\n",
      "     -----------------------------          154.8/198.5 MB 2.0 MB/s eta 0:00:23\n",
      "     -----------------------------          154.9/198.5 MB 2.0 MB/s eta 0:00:23\n",
      "     -----------------------------          155.0/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.1/198.5 MB 2.0 MB/s eta 0:00:23\n",
      "     -----------------------------          155.2/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.2/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.3/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.4/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.5/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.6/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.7/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.8/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          155.9/198.5 MB 2.0 MB/s eta 0:00:22\n",
      "     -----------------------------          156.7/198.5 MB 1.5 MB/s eta 0:00:29\n",
      "     ------------------------------         156.8/198.5 MB 1.5 MB/s eta 0:00:29\n",
      "     ------------------------------         156.9/198.5 MB 1.5 MB/s eta 0:00:29\n",
      "     ------------------------------         157.0/198.5 MB 1.5 MB/s eta 0:00:29\n",
      "     ------------------------------         157.8/198.5 MB 1.5 MB/s eta 0:00:27\n",
      "     ------------------------------         160.2/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         160.2/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         160.4/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         160.4/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         160.5/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         160.6/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         160.7/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         160.8/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         160.9/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         161.0/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         161.1/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         161.2/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         161.3/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         161.4/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         161.4/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         161.4/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         161.4/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         161.7/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         161.8/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     ------------------------------         161.9/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     -------------------------------        162.0/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     -------------------------------        162.0/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     -------------------------------        162.1/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     -------------------------------        162.2/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     -------------------------------        162.3/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     -------------------------------        162.4/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     -------------------------------        162.5/198.5 MB 1.9 MB/s eta 0:00:19\n",
      "     -------------------------------        162.6/198.5 MB 1.9 MB/s eta 0:00:19\n",
      "     -------------------------------        162.6/198.5 MB 1.9 MB/s eta 0:00:19\n",
      "     -------------------------------        162.8/198.5 MB 1.9 MB/s eta 0:00:20\n",
      "     -------------------------------        162.9/198.5 MB 1.9 MB/s eta 0:00:19\n",
      "     -------------------------------        163.0/198.5 MB 1.9 MB/s eta 0:00:19\n",
      "     -------------------------------        163.1/198.5 MB 1.9 MB/s eta 0:00:19\n",
      "     -------------------------------        163.2/198.5 MB 1.9 MB/s eta 0:00:19\n",
      "     -------------------------------        163.3/198.5 MB 1.9 MB/s eta 0:00:19\n",
      "     -------------------------------        163.4/198.5 MB 1.9 MB/s eta 0:00:19\n",
      "     -------------------------------        163.5/198.5 MB 1.9 MB/s eta 0:00:19\n",
      "     -------------------------------        163.6/198.5 MB 1.9 MB/s eta 0:00:19\n",
      "     -------------------------------        163.7/198.5 MB 1.9 MB/s eta 0:00:19\n",
      "     -------------------------------        163.8/198.5 MB 1.9 MB/s eta 0:00:19\n",
      "     -------------------------------        163.9/198.5 MB 1.9 MB/s eta 0:00:18\n",
      "     -------------------------------        164.0/198.5 MB 1.9 MB/s eta 0:00:19\n",
      "     -------------------------------        164.1/198.5 MB 1.9 MB/s eta 0:00:19\n",
      "     -------------------------------        164.2/198.5 MB 1.9 MB/s eta 0:00:18\n",
      "     -------------------------------        164.3/198.5 MB 1.9 MB/s eta 0:00:18\n",
      "     -------------------------------        164.4/198.5 MB 1.9 MB/s eta 0:00:18\n",
      "     -------------------------------        164.5/198.5 MB 1.9 MB/s eta 0:00:18\n",
      "     -------------------------------        164.5/198.5 MB 1.9 MB/s eta 0:00:18\n",
      "     -------------------------------        164.7/198.5 MB 1.9 MB/s eta 0:00:18\n",
      "     -------------------------------        164.8/198.5 MB 1.9 MB/s eta 0:00:18\n",
      "     -------------------------------        164.9/198.5 MB 1.9 MB/s eta 0:00:18\n",
      "     -------------------------------        165.0/198.5 MB 1.9 MB/s eta 0:00:18\n",
      "     -------------------------------        165.1/198.5 MB 1.9 MB/s eta 0:00:18\n",
      "     -------------------------------        165.2/198.5 MB 1.9 MB/s eta 0:00:18\n",
      "     -------------------------------        165.3/198.5 MB 1.9 MB/s eta 0:00:18\n",
      "     -------------------------------        165.4/198.5 MB 1.9 MB/s eta 0:00:17\n",
      "     -------------------------------        165.5/198.5 MB 2.0 MB/s eta 0:00:17\n",
      "     -------------------------------        165.6/198.5 MB 1.9 MB/s eta 0:00:17\n",
      "     -------------------------------        165.7/198.5 MB 1.9 MB/s eta 0:00:17\n",
      "     -------------------------------        165.8/198.5 MB 1.9 MB/s eta 0:00:17\n",
      "     -------------------------------        165.9/198.5 MB 2.0 MB/s eta 0:00:17\n",
      "     -------------------------------        166.0/198.5 MB 1.9 MB/s eta 0:00:17\n",
      "     -------------------------------        166.1/198.5 MB 3.3 MB/s eta 0:00:10\n",
      "     -------------------------------        166.2/198.5 MB 3.3 MB/s eta 0:00:10\n",
      "     -------------------------------        166.3/198.5 MB 3.2 MB/s eta 0:00:11\n",
      "     -------------------------------        166.4/198.5 MB 3.2 MB/s eta 0:00:11\n",
      "     -------------------------------        166.5/198.5 MB 3.1 MB/s eta 0:00:11\n",
      "     -------------------------------        166.5/198.5 MB 3.1 MB/s eta 0:00:11\n",
      "     -------------------------------        166.7/198.5 MB 3.0 MB/s eta 0:00:11\n",
      "     -------------------------------        166.7/198.5 MB 3.0 MB/s eta 0:00:11\n",
      "     -------------------------------        166.8/198.5 MB 3.0 MB/s eta 0:00:11\n",
      "     -------------------------------        167.0/198.5 MB 2.9 MB/s eta 0:00:11\n",
      "     -------------------------------        167.1/198.5 MB 3.0 MB/s eta 0:00:11\n",
      "     --------------------------------       167.2/198.5 MB 3.0 MB/s eta 0:00:11\n",
      "     --------------------------------       167.3/198.5 MB 3.0 MB/s eta 0:00:11\n",
      "     --------------------------------       167.3/198.5 MB 2.9 MB/s eta 0:00:11\n",
      "     --------------------------------       167.4/198.5 MB 2.9 MB/s eta 0:00:11\n",
      "     --------------------------------       167.5/198.5 MB 2.9 MB/s eta 0:00:11\n",
      "     --------------------------------       167.6/198.5 MB 2.8 MB/s eta 0:00:11\n",
      "     --------------------------------       167.7/198.5 MB 2.8 MB/s eta 0:00:12\n",
      "     --------------------------------       167.8/198.5 MB 2.8 MB/s eta 0:00:12\n",
      "     --------------------------------       167.9/198.5 MB 2.7 MB/s eta 0:00:12\n",
      "     --------------------------------       168.0/198.5 MB 2.7 MB/s eta 0:00:12\n",
      "     --------------------------------       168.1/198.5 MB 2.7 MB/s eta 0:00:12\n",
      "     --------------------------------       168.2/198.5 MB 2.6 MB/s eta 0:00:12\n",
      "     --------------------------------       168.3/198.5 MB 2.6 MB/s eta 0:00:12\n",
      "     --------------------------------       168.4/198.5 MB 2.6 MB/s eta 0:00:12\n",
      "     --------------------------------       168.5/198.5 MB 2.5 MB/s eta 0:00:12\n",
      "     --------------------------------       168.6/198.5 MB 2.5 MB/s eta 0:00:12\n",
      "     --------------------------------       168.7/198.5 MB 2.5 MB/s eta 0:00:12\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:12\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       168.8/198.5 MB 2.5 MB/s eta 0:00:13\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     --------------------------------       171.4/198.5 MB 1.9 MB/s eta 0:00:15\n",
      "     ---------------------------------      172.7/198.5 MB 1.8 MB/s eta 0:00:15\n",
      "     ---------------------------------      174.7/198.5 MB 2.2 MB/s eta 0:00:11\n",
      "     ---------------------------------      174.8/198.5 MB 2.2 MB/s eta 0:00:11\n",
      "     ---------------------------------      174.9/198.5 MB 2.2 MB/s eta 0:00:11\n",
      "     ---------------------------------      175.0/198.5 MB 2.2 MB/s eta 0:00:11\n",
      "     ---------------------------------      175.2/198.5 MB 2.2 MB/s eta 0:00:11\n",
      "     ---------------------------------      175.3/198.5 MB 2.2 MB/s eta 0:00:11\n",
      "     ---------------------------------      175.4/198.5 MB 2.2 MB/s eta 0:00:11\n",
      "     ---------------------------------      175.5/198.5 MB 2.2 MB/s eta 0:00:11\n",
      "     ---------------------------------      175.6/198.5 MB 2.2 MB/s eta 0:00:11\n",
      "     ---------------------------------      175.6/198.5 MB 2.1 MB/s eta 0:00:11\n",
      "     ---------------------------------      175.6/198.5 MB 2.1 MB/s eta 0:00:11\n",
      "     ---------------------------------      175.7/198.5 MB 2.1 MB/s eta 0:00:11\n",
      "     ---------------------------------      175.9/198.5 MB 2.1 MB/s eta 0:00:11\n",
      "     ---------------------------------      176.0/198.5 MB 2.2 MB/s eta 0:00:11\n",
      "     ---------------------------------      176.0/198.5 MB 2.1 MB/s eta 0:00:11\n",
      "     ---------------------------------      176.2/198.5 MB 2.1 MB/s eta 0:00:11\n",
      "     ---------------------------------      176.3/198.5 MB 2.1 MB/s eta 0:00:11\n",
      "     ---------------------------------      176.4/198.5 MB 2.1 MB/s eta 0:00:11\n",
      "     ---------------------------------      176.5/198.5 MB 2.1 MB/s eta 0:00:11\n",
      "     ---------------------------------      176.6/198.5 MB 2.1 MB/s eta 0:00:11\n",
      "     ---------------------------------      176.7/198.5 MB 2.2 MB/s eta 0:00:11\n",
      "     ---------------------------------      176.8/198.5 MB 2.2 MB/s eta 0:00:11\n",
      "     ---------------------------------      176.9/198.5 MB 2.1 MB/s eta 0:00:11\n",
      "     ---------------------------------      177.0/198.5 MB 2.2 MB/s eta 0:00:11\n",
      "     ---------------------------------      177.0/198.5 MB 2.2 MB/s eta 0:00:10\n",
      "     ---------------------------------      177.1/198.5 MB 2.1 MB/s eta 0:00:10\n",
      "     ---------------------------------      177.2/198.5 MB 2.1 MB/s eta 0:00:10\n",
      "     ---------------------------------      177.3/198.5 MB 2.1 MB/s eta 0:00:10\n",
      "     ---------------------------------      177.5/198.5 MB 2.1 MB/s eta 0:00:10\n",
      "     ---------------------------------      177.6/198.5 MB 2.2 MB/s eta 0:00:10\n",
      "     ----------------------------------     177.6/198.5 MB 2.1 MB/s eta 0:00:10\n",
      "     ----------------------------------     177.8/198.5 MB 2.1 MB/s eta 0:00:10\n",
      "     ----------------------------------     177.8/198.5 MB 2.1 MB/s eta 0:00:10\n",
      "     ----------------------------------     178.0/198.5 MB 2.1 MB/s eta 0:00:10\n",
      "     ----------------------------------     178.0/198.5 MB 2.1 MB/s eta 0:00:10\n",
      "     ----------------------------------     178.2/198.5 MB 2.2 MB/s eta 0:00:10\n",
      "     ----------------------------------     178.2/198.5 MB 2.2 MB/s eta 0:00:10\n",
      "     ----------------------------------     178.4/198.5 MB 2.2 MB/s eta 0:00:10\n",
      "     ----------------------------------     178.5/198.5 MB 2.2 MB/s eta 0:00:10\n",
      "     ----------------------------------     178.6/198.5 MB 2.2 MB/s eta 0:00:10\n",
      "     ----------------------------------     178.7/198.5 MB 2.2 MB/s eta 0:00:10\n",
      "     ----------------------------------     178.8/198.5 MB 2.2 MB/s eta 0:00:10\n",
      "     ----------------------------------     178.9/198.5 MB 2.2 MB/s eta 0:00:10\n",
      "     ----------------------------------     179.0/198.5 MB 2.2 MB/s eta 0:00:09\n",
      "     ----------------------------------     179.0/198.5 MB 2.1 MB/s eta 0:00:10\n",
      "     ----------------------------------     179.2/198.5 MB 3.4 MB/s eta 0:00:06\n",
      "     ----------------------------------     179.3/198.5 MB 3.4 MB/s eta 0:00:06\n",
      "     ----------------------------------     179.4/198.5 MB 3.3 MB/s eta 0:00:06\n",
      "     ----------------------------------     179.5/198.5 MB 3.3 MB/s eta 0:00:06\n",
      "     ----------------------------------     179.6/198.5 MB 3.3 MB/s eta 0:00:06\n",
      "     ----------------------------------     179.7/198.5 MB 3.2 MB/s eta 0:00:06\n",
      "     ----------------------------------     179.8/198.5 MB 3.2 MB/s eta 0:00:06\n",
      "     ----------------------------------     179.9/198.5 MB 3.1 MB/s eta 0:00:06\n",
      "     ----------------------------------     180.0/198.5 MB 3.1 MB/s eta 0:00:06\n",
      "     ----------------------------------     180.1/198.5 MB 3.0 MB/s eta 0:00:07\n",
      "     ----------------------------------     180.2/198.5 MB 3.0 MB/s eta 0:00:07\n",
      "     ----------------------------------     180.3/198.5 MB 3.0 MB/s eta 0:00:07\n",
      "     ----------------------------------     180.4/198.5 MB 2.9 MB/s eta 0:00:07\n",
      "     ----------------------------------     180.6/198.5 MB 2.9 MB/s eta 0:00:07\n",
      "     ----------------------------------     180.7/198.5 MB 2.8 MB/s eta 0:00:07\n",
      "     ----------------------------------     180.8/198.5 MB 2.8 MB/s eta 0:00:07\n",
      "     ----------------------------------     180.9/198.5 MB 2.8 MB/s eta 0:00:07\n",
      "     ----------------------------------     181.0/198.5 MB 2.7 MB/s eta 0:00:07\n",
      "     ----------------------------------     181.2/198.5 MB 2.7 MB/s eta 0:00:07\n",
      "     ----------------------------------     181.3/198.5 MB 2.7 MB/s eta 0:00:07\n",
      "     ----------------------------------     181.3/198.5 MB 2.7 MB/s eta 0:00:07\n",
      "     ----------------------------------     181.3/198.5 MB 2.7 MB/s eta 0:00:07\n",
      "     ----------------------------------     181.3/198.5 MB 2.6 MB/s eta 0:00:07\n",
      "     ----------------------------------     181.4/198.5 MB 2.6 MB/s eta 0:00:07\n",
      "     ----------------------------------     181.7/198.5 MB 3.1 MB/s eta 0:00:06\n",
      "     ----------------------------------     181.8/198.5 MB 3.1 MB/s eta 0:00:06\n",
      "     ----------------------------------     182.0/198.5 MB 3.1 MB/s eta 0:00:06\n",
      "     ----------------------------------     182.1/198.5 MB 3.0 MB/s eta 0:00:06\n",
      "     ----------------------------------     182.1/198.5 MB 3.0 MB/s eta 0:00:06\n",
      "     ----------------------------------     182.3/198.5 MB 3.0 MB/s eta 0:00:06\n",
      "     ----------------------------------     182.3/198.5 MB 2.9 MB/s eta 0:00:06\n",
      "     ----------------------------------     182.3/198.5 MB 2.9 MB/s eta 0:00:06\n",
      "     ----------------------------------     182.6/198.5 MB 2.8 MB/s eta 0:00:06\n",
      "     ----------------------------------     182.7/198.5 MB 2.8 MB/s eta 0:00:06\n",
      "     ----------------------------------     182.8/198.5 MB 2.8 MB/s eta 0:00:06\n",
      "     -----------------------------------    182.9/198.5 MB 2.8 MB/s eta 0:00:06\n",
      "     -----------------------------------    183.0/198.5 MB 2.7 MB/s eta 0:00:06\n",
      "     -----------------------------------    183.1/198.5 MB 2.7 MB/s eta 0:00:06\n",
      "     -----------------------------------    183.2/198.5 MB 2.7 MB/s eta 0:00:06\n",
      "     -----------------------------------    183.3/198.5 MB 2.6 MB/s eta 0:00:06\n",
      "     -----------------------------------    183.4/198.5 MB 2.6 MB/s eta 0:00:06\n",
      "     -----------------------------------    183.5/198.5 MB 2.6 MB/s eta 0:00:06\n",
      "     -----------------------------------    183.6/198.5 MB 2.5 MB/s eta 0:00:06\n",
      "     -----------------------------------    183.7/198.5 MB 2.5 MB/s eta 0:00:06\n",
      "     -----------------------------------    183.9/198.5 MB 2.5 MB/s eta 0:00:06\n",
      "     -----------------------------------    184.0/198.5 MB 2.5 MB/s eta 0:00:06\n",
      "     -----------------------------------    184.1/198.5 MB 2.4 MB/s eta 0:00:06\n",
      "     -----------------------------------    184.2/198.5 MB 2.4 MB/s eta 0:00:06\n",
      "     -----------------------------------    184.3/198.5 MB 2.4 MB/s eta 0:00:06\n",
      "     -----------------------------------    184.4/198.5 MB 2.3 MB/s eta 0:00:07\n",
      "     -----------------------------------    184.5/198.5 MB 2.3 MB/s eta 0:00:07\n",
      "     -----------------------------------    184.6/198.5 MB 2.3 MB/s eta 0:00:07\n",
      "     -----------------------------------    184.7/198.5 MB 2.3 MB/s eta 0:00:07\n",
      "     -----------------------------------    184.8/198.5 MB 2.2 MB/s eta 0:00:07\n",
      "     -----------------------------------    184.9/198.5 MB 2.2 MB/s eta 0:00:07\n",
      "     -----------------------------------    185.1/198.5 MB 2.2 MB/s eta 0:00:06\n",
      "     -----------------------------------    185.2/198.5 MB 2.2 MB/s eta 0:00:06\n",
      "     -----------------------------------    185.3/198.5 MB 2.2 MB/s eta 0:00:06\n",
      "     -----------------------------------    185.4/198.5 MB 2.2 MB/s eta 0:00:06\n",
      "     -----------------------------------    185.5/198.5 MB 2.2 MB/s eta 0:00:06\n",
      "     -----------------------------------    185.6/198.5 MB 2.2 MB/s eta 0:00:06\n",
      "     -----------------------------------    185.7/198.5 MB 2.2 MB/s eta 0:00:06\n",
      "     -----------------------------------    185.8/198.5 MB 2.2 MB/s eta 0:00:06\n",
      "     -----------------------------------    185.8/198.5 MB 2.3 MB/s eta 0:00:06\n",
      "     -----------------------------------    186.0/198.5 MB 2.3 MB/s eta 0:00:06\n",
      "     -----------------------------------    186.1/198.5 MB 2.3 MB/s eta 0:00:06\n",
      "     -----------------------------------    186.1/198.5 MB 2.3 MB/s eta 0:00:06\n",
      "     -----------------------------------    186.3/198.5 MB 2.3 MB/s eta 0:00:06\n",
      "     -----------------------------------    186.4/198.5 MB 2.3 MB/s eta 0:00:06\n",
      "     -----------------------------------    186.5/198.5 MB 2.3 MB/s eta 0:00:06\n",
      "     -----------------------------------    186.6/198.5 MB 2.3 MB/s eta 0:00:06\n",
      "     -----------------------------------    186.7/198.5 MB 2.3 MB/s eta 0:00:06\n",
      "     -----------------------------------    186.8/198.5 MB 2.3 MB/s eta 0:00:06\n",
      "     -----------------------------------    186.9/198.5 MB 2.3 MB/s eta 0:00:06\n",
      "     -----------------------------------    187.0/198.5 MB 2.3 MB/s eta 0:00:06\n",
      "     -----------------------------------    187.1/198.5 MB 2.3 MB/s eta 0:00:06\n",
      "     -----------------------------------    187.2/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     -----------------------------------    187.3/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     -----------------------------------    187.3/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     -----------------------------------    187.5/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     -----------------------------------    187.5/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     -----------------------------------    187.6/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     -----------------------------------    187.8/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     -----------------------------------    187.8/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     -----------------------------------    187.9/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     ------------------------------------   188.1/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     ------------------------------------   188.1/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     ------------------------------------   188.2/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     ------------------------------------   188.3/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     ------------------------------------   188.3/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     ------------------------------------   188.4/198.5 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------------   188.6/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     ------------------------------------   188.7/198.5 MB 2.3 MB/s eta 0:00:05\n",
      "     ------------------------------------   188.7/198.5 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------------   188.8/198.5 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------------   188.9/198.5 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------------   189.0/198.5 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------------   189.1/198.5 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------------   189.2/198.5 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------------   189.2/198.5 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------------   189.4/198.5 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------------   189.5/198.5 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------------------------------   189.6/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   189.7/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   189.8/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   189.9/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   190.0/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   190.1/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   190.2/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   190.3/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   190.4/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   190.5/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   190.6/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   190.7/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   190.8/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   190.9/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   190.9/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   191.0/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   191.1/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   191.2/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   191.3/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   191.5/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   191.5/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   191.7/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   191.7/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   191.8/198.5 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------   192.0/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   192.0/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   192.1/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   192.3/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   192.4/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   192.4/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   192.6/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   192.7/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   192.8/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   192.9/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   193.0/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   193.1/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   193.2/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     -------------------------------------  193.3/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     -------------------------------------  193.3/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     -------------------------------------  193.3/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     -------------------------------------  193.3/198.5 MB 2.1 MB/s eta 0:00:03\n",
      "     -------------------------------------  193.6/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     -------------------------------------  193.8/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     -------------------------------------  193.9/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     -------------------------------------  194.0/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     -------------------------------------  194.1/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     -------------------------------------  194.2/198.5 MB 2.2 MB/s eta 0:00:03\n",
      "     -------------------------------------  194.2/198.5 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------------  194.3/198.5 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------------  194.4/198.5 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------------  194.4/198.5 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------------  194.4/198.5 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------------  194.6/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  194.7/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  194.8/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  194.9/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  195.0/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  195.2/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  195.2/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  195.3/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  195.4/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  195.6/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  195.7/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  195.7/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  195.8/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  195.9/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  196.0/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  196.0/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  196.1/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  196.2/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  196.2/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  196.2/198.5 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------  196.3/198.5 MB 2.0 MB/s eta 0:00:02\n",
      "     -------------------------------------  196.3/198.5 MB 2.0 MB/s eta 0:00:02\n",
      "     -------------------------------------  196.4/198.5 MB 2.0 MB/s eta 0:00:02\n",
      "     -------------------------------------  196.4/198.5 MB 2.0 MB/s eta 0:00:02\n",
      "     -------------------------------------  196.5/198.5 MB 2.0 MB/s eta 0:00:02\n",
      "     -------------------------------------  196.5/198.5 MB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------------  196.6/198.5 MB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------------  196.6/198.5 MB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------------  196.7/198.5 MB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------------  196.8/198.5 MB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------------  196.8/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  196.9/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  196.9/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.0/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.1/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.1/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.2/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.3/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.4/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.4/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.5/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.6/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.6/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.7/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.7/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.7/198.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.8/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.8/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  197.9/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.0/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.1/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.1/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.2/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.3/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.4/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  198.5/198.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- 198.5/198.5 MB 1.5 MB/s eta 0:00:00\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "                                              0.0/5.7 MB ? eta -:--:--\n",
      "                                              0.0/5.7 MB 2.0 MB/s eta 0:00:03\n",
      "                                              0.1/5.7 MB 1.7 MB/s eta 0:00:04\n",
      "     -                                        0.2/5.7 MB 1.7 MB/s eta 0:00:04\n",
      "     --                                       0.3/5.7 MB 1.7 MB/s eta 0:00:04\n",
      "     --                                       0.4/5.7 MB 1.8 MB/s eta 0:00:04\n",
      "     ---                                      0.5/5.7 MB 1.7 MB/s eta 0:00:04\n",
      "     ---                                      0.5/5.7 MB 1.7 MB/s eta 0:00:04\n",
      "     ----                                     0.6/5.7 MB 1.6 MB/s eta 0:00:04\n",
      "     ----                                     0.6/5.7 MB 1.6 MB/s eta 0:00:04\n",
      "     ----                                     0.7/5.7 MB 1.5 MB/s eta 0:00:04\n",
      "     -----                                    0.8/5.7 MB 1.6 MB/s eta 0:00:04\n",
      "     ------                                   0.9/5.7 MB 1.6 MB/s eta 0:00:03\n",
      "     -------                                  1.0/5.7 MB 1.6 MB/s eta 0:00:03\n",
      "     -------                                  1.1/5.7 MB 1.7 MB/s eta 0:00:03\n",
      "     --------                                 1.2/5.7 MB 1.7 MB/s eta 0:00:03\n",
      "     --------                                 1.2/5.7 MB 1.6 MB/s eta 0:00:03\n",
      "     --------                                 1.3/5.7 MB 1.6 MB/s eta 0:00:03\n",
      "     ---------                                1.4/5.7 MB 1.6 MB/s eta 0:00:03\n",
      "     ----------                               1.5/5.7 MB 1.6 MB/s eta 0:00:03\n",
      "     ----------                               1.5/5.7 MB 1.6 MB/s eta 0:00:03\n",
      "     -----------                              1.6/5.7 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------                             1.7/5.7 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------                             1.7/5.7 MB 1.7 MB/s eta 0:00:03\n",
      "     -------------                            1.9/5.7 MB 1.7 MB/s eta 0:00:03\n",
      "     -------------                            2.0/5.7 MB 1.7 MB/s eta 0:00:03\n",
      "     --------------                           2.1/5.7 MB 1.7 MB/s eta 0:00:03\n",
      "     ---------------                          2.2/5.7 MB 1.7 MB/s eta 0:00:03\n",
      "     ----------------                         2.3/5.7 MB 1.8 MB/s eta 0:00:02\n",
      "     -----------------                        2.5/5.7 MB 1.8 MB/s eta 0:00:02\n",
      "     -----------------                        2.5/5.7 MB 1.8 MB/s eta 0:00:02\n",
      "     -----------------                        2.6/5.7 MB 1.8 MB/s eta 0:00:02\n",
      "     ------------------                       2.7/5.7 MB 1.8 MB/s eta 0:00:02\n",
      "     ------------------                       2.7/5.7 MB 1.8 MB/s eta 0:00:02\n",
      "     --------------------                     2.9/5.7 MB 1.8 MB/s eta 0:00:02\n",
      "     --------------------                     3.0/5.7 MB 1.8 MB/s eta 0:00:02\n",
      "     ---------------------                    3.1/5.7 MB 1.8 MB/s eta 0:00:02\n",
      "     ----------------------                   3.2/5.7 MB 1.9 MB/s eta 0:00:02\n",
      "     -----------------------                  3.3/5.7 MB 1.9 MB/s eta 0:00:02\n",
      "     -----------------------                  3.4/5.7 MB 1.9 MB/s eta 0:00:02\n",
      "     ------------------------                 3.5/5.7 MB 1.9 MB/s eta 0:00:02\n",
      "     ------------------------                 3.6/5.7 MB 1.9 MB/s eta 0:00:02\n",
      "     ------------------------                 3.6/5.7 MB 1.8 MB/s eta 0:00:02\n",
      "     ------------------------                 3.6/5.7 MB 1.8 MB/s eta 0:00:02\n",
      "     ------------------------                 3.6/5.7 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------                 3.6/5.7 MB 1.7 MB/s eta 0:00:02\n",
      "     --------------------------               3.8/5.7 MB 1.8 MB/s eta 0:00:02\n",
      "     ---------------------------              3.9/5.7 MB 1.8 MB/s eta 0:00:02\n",
      "     ----------------------------             4.1/5.7 MB 1.8 MB/s eta 0:00:01\n",
      "     ----------------------------             4.1/5.7 MB 1.8 MB/s eta 0:00:01\n",
      "     -----------------------------            4.2/5.7 MB 1.8 MB/s eta 0:00:01\n",
      "     ------------------------------           4.4/5.7 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------          4.5/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------          4.6/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     --------------------------------         4.6/5.7 MB 1.8 MB/s eta 0:00:01\n",
      "     ---------------------------------        4.8/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------        4.8/5.7 MB 1.8 MB/s eta 0:00:01\n",
      "     ----------------------------------       4.9/5.7 MB 1.8 MB/s eta 0:00:01\n",
      "     -----------------------------------      5.0/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     -----------------------------------      5.1/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ------------------------------------     5.3/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ------------------------------------     5.3/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------    5.4/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     --------------------------------------   5.5/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.7/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.7/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.7/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.7/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.7/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.7/5.7 MB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: networkx in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch) (3.1.2)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "                                              0.0/170.9 kB ? eta -:--:--\n",
      "     ---------                               41.0/170.9 kB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------        143.4/170.9 kB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------------   163.8/170.9 kB 2.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 170.9/170.9 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "                                              0.0/536.2 kB ? eta -:--:--\n",
      "     ----                                    61.4/536.2 kB 1.7 MB/s eta 0:00:01\n",
      "     -------------                          194.6/536.2 kB 2.4 MB/s eta 0:00:01\n",
      "     ---------------------                  307.2/536.2 kB 2.4 MB/s eta 0:00:01\n",
      "     -----------------------------          419.8/536.2 kB 2.2 MB/s eta 0:00:01\n",
      "     -----------------------------------    501.8/536.2 kB 2.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 536.2/536.2 kB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, fsspec, filelock, torch\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.0\n",
      "    Uninstalling typing_extensions-4.7.0:\n",
      "      Successfully uninstalled typing_extensions-4.7.0\n",
      "Successfully installed filelock-3.13.1 fsspec-2024.2.0 mpmath-1.3.0 sympy-1.12 torch-2.2.0 typing-extensions-4.9.0\n",
      "Collecting torchvision"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading torchvision-0.17.0-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "                                              0.0/1.2 MB ? eta -:--:--\n",
      "     -                                        0.0/1.2 MB 640.0 kB/s eta 0:00:02\n",
      "     -                                        0.0/1.2 MB 640.0 kB/s eta 0:00:02\n",
      "     -                                        0.0/1.2 MB 217.9 kB/s eta 0:00:06\n",
      "     --                                       0.1/1.2 MB 416.7 kB/s eta 0:00:03\n",
      "     ---                                      0.1/1.2 MB 504.4 kB/s eta 0:00:03\n",
      "     ----                                     0.1/1.2 MB 472.1 kB/s eta 0:00:03\n",
      "     ----                                     0.1/1.2 MB 472.1 kB/s eta 0:00:03\n",
      "     -----                                    0.2/1.2 MB 436.9 kB/s eta 0:00:03\n",
      "     --------                                 0.2/1.2 MB 602.4 kB/s eta 0:00:02\n",
      "     --------                                 0.2/1.2 MB 602.4 kB/s eta 0:00:02\n",
      "     --------                                 0.2/1.2 MB 602.4 kB/s eta 0:00:02\n",
      "     --------                                 0.2/1.2 MB 602.4 kB/s eta 0:00:02\n",
      "     --------                                 0.2/1.2 MB 602.4 kB/s eta 0:00:02\n",
      "     --------                                 0.2/1.2 MB 602.4 kB/s eta 0:00:02\n",
      "     --------                                 0.2/1.2 MB 602.4 kB/s eta 0:00:02\n",
      "     ------------                             0.4/1.2 MB 487.6 kB/s eta 0:00:02\n",
      "     ------------                             0.4/1.2 MB 487.6 kB/s eta 0:00:02\n",
      "     ------------                             0.4/1.2 MB 487.6 kB/s eta 0:00:02\n",
      "     -------------                            0.4/1.2 MB 440.6 kB/s eta 0:00:02\n",
      "     ---------------                          0.5/1.2 MB 469.4 kB/s eta 0:00:02\n",
      "     -----------------                        0.5/1.2 MB 499.0 kB/s eta 0:00:02\n",
      "     ------------------                       0.6/1.2 MB 525.9 kB/s eta 0:00:02\n",
      "     ---------------------                    0.6/1.2 MB 569.9 kB/s eta 0:00:01\n",
      "     -----------------------                  0.7/1.2 MB 609.8 kB/s eta 0:00:01\n",
      "     -------------------------                0.7/1.2 MB 629.1 kB/s eta 0:00:01\n",
      "     ---------------------------              0.8/1.2 MB 655.2 kB/s eta 0:00:01\n",
      "     -----------------------------            0.9/1.2 MB 679.9 kB/s eta 0:00:01\n",
      "     -------------------------------          0.9/1.2 MB 702.7 kB/s eta 0:00:01\n",
      "     ----------------------------------       1.0/1.2 MB 730.4 kB/s eta 0:00:01\n",
      "     ------------------------------------     1.1/1.2 MB 765.6 kB/s eta 0:00:01\n",
      "     --------------------------------------   1.1/1.2 MB 783.3 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.2/1.2 MB 770.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torchvision) (1.25.0)\n",
      "Requirement already satisfied: requests in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.2.0 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torchvision) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: filelock in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch==2.2.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch==2.2.0->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch==2.2.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch==2.2.0->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch==2.2.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch==2.2.0->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from requests->torchvision) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from jinja2->torch==2.2.0->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from sympy->torch==2.2.0->torchvision) (1.3.0)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.17.0\n",
      "Collecting torchaudio"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading torchaudio-2.2.0-cp39-cp39-win_amd64.whl (2.4 MB)\n",
      "                                              0.0/2.4 MB ? eta -:--:--\n",
      "                                              0.0/2.4 MB ? eta -:--:--\n",
      "                                              0.0/2.4 MB 330.3 kB/s eta 0:00:08\n",
      "                                              0.0/2.4 MB 330.3 kB/s eta 0:00:08\n",
      "     -                                        0.1/2.4 MB 416.7 kB/s eta 0:00:06\n",
      "     -                                        0.1/2.4 MB 469.7 kB/s eta 0:00:05\n",
      "     --                                       0.1/2.4 MB 502.3 kB/s eta 0:00:05\n",
      "     ---                                      0.2/2.4 MB 590.8 kB/s eta 0:00:04\n",
      "     ----                                     0.2/2.4 MB 656.0 kB/s eta 0:00:04\n",
      "     ----                                     0.3/2.4 MB 655.8 kB/s eta 0:00:04\n",
      "     -----                                    0.3/2.4 MB 679.5 kB/s eta 0:00:04\n",
      "     ------                                   0.4/2.4 MB 735.7 kB/s eta 0:00:03\n",
      "     -------                                  0.5/2.4 MB 842.4 kB/s eta 0:00:03\n",
      "     ---------                                0.6/2.4 MB 949.7 kB/s eta 0:00:02\n",
      "     -----------                              0.7/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------                            0.8/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------                           0.9/2.4 MB 1.2 MB/s eta 0:00:02\n",
      "     ----------------                         1.0/2.4 MB 1.2 MB/s eta 0:00:02\n",
      "     ------------------                       1.1/2.4 MB 1.3 MB/s eta 0:00:02\n",
      "     -------------------                      1.1/2.4 MB 1.3 MB/s eta 0:00:01\n",
      "     --------------------                     1.2/2.4 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------                    1.3/2.4 MB 1.3 MB/s eta 0:00:01\n",
      "     ----------------------                   1.4/2.4 MB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------                 1.5/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "     --------------------------               1.6/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------              1.6/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "     ----------------------------             1.7/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "     ----------------------------             1.7/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "     -----------------------------            1.7/2.4 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------        2.0/2.4 MB 1.5 MB/s eta 0:00:01\n",
      "     -----------------------------------      2.1/2.4 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------    2.2/2.4 MB 1.5 MB/s eta 0:00:01\n",
      "     --------------------------------------   2.3/2.4 MB 1.5 MB/s eta 0:00:01\n",
      "     --------------------------------------   2.3/2.4 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.4/2.4 MB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch==2.2.0 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torchaudio) (2.2.0)\n",
      "Requirement already satisfied: filelock in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch==2.2.0->torchaudio) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch==2.2.0->torchaudio) (4.9.0)\n",
      "Requirement already satisfied: sympy in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch==2.2.0->torchaudio) (1.12)\n",
      "Requirement already satisfied: networkx in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch==2.2.0->torchaudio) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch==2.2.0->torchaudio) (3.1.2)\n",
      "Requirement already satisfied: fsspec in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch==2.2.0->torchaudio) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from jinja2->torch==2.2.0->torchaudio) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from sympy->torch==2.2.0->torchaudio) (1.3.0)\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.2.0\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
      "                                              0.0/1.0 MB ? eta -:--:--\n",
      "                                              0.0/1.0 MB ? eta -:--:--\n",
      "     -                                        0.0/1.0 MB 660.6 kB/s eta 0:00:02\n",
      "     -                                        0.0/1.0 MB 660.6 kB/s eta 0:00:02\n",
      "     --                                       0.1/1.0 MB 328.2 kB/s eta 0:00:03\n",
      "     ----                                     0.1/1.0 MB 504.4 kB/s eta 0:00:02\n",
      "     ----                                     0.1/1.0 MB 450.6 kB/s eta 0:00:03\n",
      "     ------                                   0.2/1.0 MB 551.6 kB/s eta 0:00:02\n",
      "     ---------                                0.2/1.0 MB 684.7 kB/s eta 0:00:02\n",
      "     ---------                                0.2/1.0 MB 684.7 kB/s eta 0:00:02\n",
      "     -----------                              0.3/1.0 MB 610.3 kB/s eta 0:00:02\n",
      "     -------------                            0.4/1.0 MB 696.3 kB/s eta 0:00:01\n",
      "     --------------                           0.4/1.0 MB 694.6 kB/s eta 0:00:01\n",
      "     ---------------                          0.4/1.0 MB 674.2 kB/s eta 0:00:01\n",
      "     -----------------                        0.5/1.0 MB 704.5 kB/s eta 0:00:01\n",
      "     ----------------------                   0.6/1.0 MB 834.7 kB/s eta 0:00:01\n",
      "     -------------------------                0.7/1.0 MB 897.2 kB/s eta 0:00:01\n",
      "     ----------------------------             0.7/1.0 MB 944.0 kB/s eta 0:00:01\n",
      "     --------------------------------         0.8/1.0 MB 1.0 MB/s eta 0:00:01\n",
      "     ------------------------------------     1.0/1.0 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.0/1.0 MB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch-geometric) (4.65.0)\n",
      "Requirement already satisfied: numpy in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch-geometric) (1.25.0)\n",
      "Requirement already satisfied: scipy in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch-geometric) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch-geometric) (3.1.0)\n",
      "Requirement already satisfied: scikit-learn in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch-geometric) (1.3.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from torch-geometric) (5.9.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from jinja2->torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from requests->torch-geometric) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from requests->torch-geometric) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from requests->torch-geometric) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from requests->torch-geometric) (2023.5.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from scikit-learn->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
      "Requirement already satisfied: colorama in e:\\university\\m.sc\\terms\\term2\\applied machine learning\\project\\codes\\1\\venv\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Installing collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Imports**"
   ],
   "metadata": {
    "id": "XFYdSgrG4ljq",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_ek1yIhBzwi2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.datasets import CitationFull\n",
    "from torch_geometric.datasets import CoraFull\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from torch_geometric.transforms import ToSparseTensor\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import MLP\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.nn.functional import softmax\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from itertools import permutations\n",
    "from itertools import product\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import GATv2Conv"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Download Datasets**"
   ],
   "metadata": {
    "id": "zMH_HKa545qh",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Download the dataset --> citeseer\n",
    "dataset_cite = Planetoid(root='./cite', name='CiteSeer')\n",
    "\n",
    "cite_classes = dataset_cite.num_classes\n",
    "cite_features = dataset_cite.num_features\n",
    "\n",
    "# Get information about the dataset\n",
    "print(f'Dataset: {dataset_cite}')\n",
    "print(f'Number of graphs: {len(dataset_cite)}')\n",
    "print(f'Number of features: {dataset_cite.num_features}')\n",
    "print(f'Number of classes: {dataset_cite.num_classes}')\n",
    "print('---------------------------------')\n",
    "\n",
    "# Print the number of nodes and edges\n",
    "print('Graph:')\n",
    "print(f'Number of nodes: {dataset_cite[0].num_nodes}')\n",
    "print(f'Number of edges: {dataset_cite[0].num_edges}')\n",
    "print(f'Number of node features: {dataset_cite[0].num_node_features}')\n",
    "print(f'Number of edge features: {dataset_cite[0].num_edge_features}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASH3HOUYxKYj",
    "outputId": "13e9d8ff-cfe4-4d2d-bf91-94a2256f1bf9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CiteSeer()\n",
      "Number of graphs: 1\n",
      "Number of features: 3703\n",
      "Number of classes: 6\n",
      "---------------------------------\n",
      "Graph:\n",
      "Number of nodes: 3327\n",
      "Number of edges: 9104\n",
      "Number of node features: 3703\n",
      "Number of edge features: 0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Download the dataset --> corafull\n",
    "dataset_corafull = CitationFull(root='./cora', name='cora')\n",
    "\n",
    "cora_classes = dataset_corafull.num_classes\n",
    "cora_features = dataset_corafull.num_features\n",
    "\n",
    "# Get information about the dataset\n",
    "print(f'Dataset: {dataset_corafull}')\n",
    "print(f'Number of graphs: {len(dataset_corafull)}')\n",
    "print(f'Number of features: {dataset_corafull.num_features}')\n",
    "print(f'Number of classes: {dataset_corafull.num_classes}')\n",
    "print('---------------------------------')\n",
    "\n",
    "# Print the number of nodes and edges\n",
    "print('Graph:')\n",
    "print(f'Number of nodes: {dataset_corafull[0].num_nodes}')\n",
    "print(f'Number of edges: {dataset_corafull[0].num_edges}')\n",
    "print(f'Number of node features: {dataset_corafull[0].num_node_features}')\n",
    "print(f'Number of edge features: {dataset_corafull[0].num_edge_features}')"
   ],
   "metadata": {
    "id": "nnpijpje8HNg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5a176362-2a00-4e79-d31e-d61a392c7812",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/abojchevski/graph2gauss/raw/master/data/cora.npz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CoraFull()\n",
      "Number of graphs: 1\n",
      "Number of features: 8710\n",
      "Number of classes: 70\n",
      "---------------------------------\n",
      "Graph:\n",
      "Number of nodes: 19793\n",
      "Number of edges: 126842\n",
      "Number of node features: 8710\n",
      "Number of edge features: 0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Train and Test and Validation Split**"
   ],
   "metadata": {
    "id": "cSv-GMFs5RCy",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "train_ratio, val_ratio, test_ratio = 0.7, 0.1, 0.2"
   ],
   "metadata": {
    "id": "VQK4jS9u9n8j",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate the number of all nodes\n",
    "nodes = dataset_cite[0].num_nodes\n",
    "\n",
    "# Shuffle the indices to create a random split\n",
    "indices = torch.randperm(nodes)\n",
    "\n",
    "# Calculate size of each split\n",
    "num_train = int(train_ratio * nodes)\n",
    "num_val = int(val_ratio * nodes)\n",
    "num_test = nodes - num_train - num_val\n",
    "\n",
    "# Create a mask for each split\n",
    "train_mask_cite = torch.zeros(nodes, dtype=torch.bool)\n",
    "val_mask_cite = torch.zeros(nodes, dtype=torch.bool)\n",
    "test_mask_cite = torch.zeros(nodes, dtype=torch.bool)\n",
    "\n",
    "# Convert the mask indices into true for split selection\n",
    "train_mask_cite[indices[: num_train]]=True\n",
    "val_mask_cite[indices[num_train : num_train+num_val]]=True\n",
    "test_mask_cite[indices[num_train+num_val :]]=True\n",
    "\n",
    "# Apply the calculated masks into the dataset\n",
    "dataset_cite[0].train_mask = train_mask_cite\n",
    "dataset_cite[0].val_mask = val_mask_cite\n",
    "dataset_cite[0].test_mask = test_mask_cite"
   ],
   "metadata": {
    "id": "v1E_8fzLLS_T",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'CiteSeer: \\n{dataset_cite[0]}')\n",
    "print(f'-------------------------------')\n",
    "\n",
    "# Print the size of each split\n",
    "print(\"Splited dataset:\")\n",
    "print(f\"Training set size: {num_train}\")\n",
    "print(f\"Validation set size: {num_val}\")\n",
    "print(f\"Test set size: {num_test}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROREFCRRD6H2",
    "outputId": "2fb8b671-3dfd-4410-ae67-c2e4f0538458",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CiteSeer: \n",
      "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])\n",
      "-------------------------------\n",
      "Splited dataset:\n",
      "Training set size: 2328\n",
      "Validation set size: 332\n",
      "Test set size: 667\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate the number of all nodes\n",
    "nodes = dataset_corafull[0].num_nodes\n",
    "\n",
    "# Shuffle the indices to create a random split\n",
    "indices = torch.randperm(nodes)\n",
    "\n",
    "# Calculate size of each split\n",
    "num_train = int(train_ratio * nodes)\n",
    "num_val = int(val_ratio * nodes)\n",
    "num_test = nodes - num_train - num_val\n",
    "\n",
    "# Create a mask for each split\n",
    "train_mask_cora = torch.zeros(nodes, dtype=torch.bool)\n",
    "val_mask_cora = torch.zeros(nodes, dtype=torch.bool)\n",
    "test_mask_cora = torch.zeros(nodes, dtype=torch.bool)\n",
    "\n",
    "# Convert the mask indices into true for split selection\n",
    "train_mask_cora[indices[: num_train]]=True\n",
    "val_mask_cora[indices[num_train : num_train+num_val]]=True\n",
    "test_mask_cora[indices[num_train+num_val :]]=True\n",
    "\n",
    "dataset_cora = dataset_corafull[0]\n",
    "\n",
    "# Apply the calculated masks into the dataset\n",
    "dataset_cora.train_mask = train_mask_cora\n",
    "dataset_cora.val_mask = val_mask_cora\n",
    "dataset_cora.test_mask = test_mask_cora\n",
    "\n",
    "\n",
    "dataset_cora.num_classes = dataset_corafull.num_classes\n",
    "dataset_cora.cora_features = dataset_corafull.num_features"
   ],
   "metadata": {
    "id": "AXoqlRWSLgpQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'CoraFull: \\n{dataset_cora}')\n",
    "print(f'-------------------------------')\n",
    "\n",
    "# Print the size of each split\n",
    "print(\"Splited dataset:\")\n",
    "print(f\"Training set size: {num_train}\")\n",
    "print(f\"Validation set size: {num_val}\")\n",
    "print(f\"Test set size: {num_test}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Px6mjNUI4LN",
    "outputId": "49346b79-79fe-4acf-b862-03094624af06",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoraFull: \n",
      "Data(x=[19793, 8710], edge_index=[2, 126842], y=[19793], train_mask=[19793], val_mask=[19793], test_mask=[19793], num_classes=70, cora_features=8710)\n",
      "-------------------------------\n",
      "Splited dataset:\n",
      "Training set size: 13855\n",
      "Validation set size: 1979\n",
      "Test set size: 3959\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **MLP Model**"
   ],
   "metadata": {
    "id": "Ffug_y2zIzDX",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the MLP model with two hidden layers\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.activation1 = nn.ReLU()\n",
    "\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.activation2 = nn.ReLU()\n",
    "\n",
    "        self.layer3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.layer2(self.dropout2(x))\n",
    "        x = self.activation2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "id": "Vwa9eXgnGle-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cite\n",
    "print('Dataset: CiteSeer')\n",
    "\n",
    "# Define training parameters\n",
    "layers_size = [(16, 8), (16, 16), (32, 16), (64, 32), (128,64), (64,128), (128,128)]\n",
    "epochs = 60\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Training Loop\n",
    "for layer_size in layers_size:\n",
    "\n",
    "    # Define model\n",
    "    model = MLPClassifier(dataset.num_features, layer_size[0], layer_size[1], dataset.num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Model with hidden size({layer_size[0]}, {layer_size[1]}):\\n\")\n",
    "    print(f\"...Training Start...\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(dataset.x)\n",
    "        loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Printing Every 10 epochs\n",
    "        if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "          print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(dataset.x)\n",
    "        _, predicted = logits.max(dim=1)\n",
    "        correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "        acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "    print(f\"...Training End...\")\n",
    "    print(f\"\\nValidation accuracy= {acc}\")\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Updateing best model\n",
    "    if best_model is None:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8EMdRsW9bTcK",
    "outputId": "d11112f5-5b9b-4ac6-94a1-4cc532a08c7e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CiteSeer\n",
      "Model with hidden size(16, 8):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.2148072719573975\n",
      "Epoch 20: loss=0.24308308959007263\n",
      "Epoch 30: loss=0.07072277367115021\n",
      "Epoch 40: loss=0.01816033013164997\n",
      "Epoch 50: loss=0.021470388397574425\n",
      "Epoch 60: loss=0.011633479967713356\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.47\n",
      "------------------------------------------\n",
      "Model with hidden size(16, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.9017589688301086\n",
      "Epoch 20: loss=0.07326389104127884\n",
      "Epoch 30: loss=0.014145812951028347\n",
      "Epoch 40: loss=0.007731970865279436\n",
      "Epoch 50: loss=0.00045787263661623\n",
      "Epoch 60: loss=0.0003872957022394985\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.454\n",
      "------------------------------------------\n",
      "Model with hidden size(32, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.6149654984474182\n",
      "Epoch 20: loss=0.005582745652645826\n",
      "Epoch 30: loss=0.001538103329949081\n",
      "Epoch 40: loss=2.195017077610828e-05\n",
      "Epoch 50: loss=2.1586574803222902e-05\n",
      "Epoch 60: loss=0.0001311586966039613\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.466\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.08312055468559265\n",
      "Epoch 20: loss=2.3953180061653256e-05\n",
      "Epoch 30: loss=6.155270511953859e-06\n",
      "Epoch 40: loss=6.329693405859871e-06\n",
      "Epoch 50: loss=2.8808896601617562e-08\n",
      "Epoch 60: loss=3.079569310671104e-08\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.482\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.0014607437187805772\n",
      "Epoch 20: loss=2.28341141337296e-05\n",
      "Epoch 30: loss=4.3710041808253663e-08\n",
      "Epoch 40: loss=9.934106870446158e-10\n",
      "Epoch 50: loss=2.9802320611338473e-09\n",
      "Epoch 60: loss=5.066383579332978e-08\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.4\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.0012508381623774767\n",
      "Epoch 20: loss=2.3841791119139089e-07\n",
      "Epoch 30: loss=3.2289526643580757e-06\n",
      "Epoch 40: loss=9.934106870446158e-10\n",
      "Epoch 50: loss=3.645737649549119e-07\n",
      "Epoch 60: loss=0.0\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.426\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.6513589546084404e-06\n",
      "Epoch 20: loss=0.0\n",
      "Epoch 30: loss=0.0\n",
      "Epoch 40: loss=0.0\n",
      "Epoch 50: loss=0.0\n",
      "Epoch 60: loss=0.0\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.354\n",
      "------------------------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset.x)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Best model with hidden size({best_hid1}, {best_hid2}): Test accuracy= {acc}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1dPWNwDr785",
    "outputId": "8451be3d-ed76-4dbd-d143-028b0dbc6aa0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model with hidden size(64, 32): Test accuracy= 0.484\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cora\n",
    "print('Dataset: CoraFull')\n",
    "\n",
    "# Define training parameters\n",
    "layers_size = [(16, 8), (16, 16), (32, 16), (64, 32), (128,64), (64,128), (128,128)]\n",
    "epochs = 60\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Training Loop\n",
    "for layer_size in layers_size:\n",
    "\n",
    "    # Define model\n",
    "    model = MLPClassifier(dataset.num_features, layer_size[0], layer_size[1], dataset.num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Model with hidden size({layer_size[0]}, {layer_size[1]}):\\n\")\n",
    "    print(f\"...Training Start...\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(dataset.x)\n",
    "        loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Printing Every 10 epochs\n",
    "        if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "          print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(dataset.x)\n",
    "        _, predicted = logits.max(dim=1)\n",
    "        correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "        acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "    print(f\"...Training End...\")\n",
    "    print(f\"\\nValidation accuracy= {acc}\")\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Updateing best model\n",
    "    if best_model is None:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4SXbq-3SffC",
    "outputId": "2a72cda8-6ffc-4847-f14d-33b28e70d73d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CoraFull\n",
      "Model with hidden size(16, 8):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.848348379135132\n",
      "Epoch 20: loss=3.1608328819274902\n",
      "Epoch 30: loss=2.4668819904327393\n",
      "Epoch 40: loss=1.857304334640503\n",
      "Epoch 50: loss=1.3678799867630005\n",
      "Epoch 60: loss=1.008188009262085\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.39464375947448205\n",
      "------------------------------------------\n",
      "Model with hidden size(16, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.5326948165893555\n",
      "Epoch 20: loss=2.5992181301116943\n",
      "Epoch 30: loss=1.7426469326019287\n",
      "Epoch 40: loss=1.144034504890442\n",
      "Epoch 50: loss=0.7814622521400452\n",
      "Epoch 60: loss=0.5568185448646545\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.45982819605861547\n",
      "------------------------------------------\n",
      "Model with hidden size(32, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.4129738807678223\n",
      "Epoch 20: loss=2.091388463973999\n",
      "Epoch 30: loss=1.0735961198806763\n",
      "Epoch 40: loss=0.5360394716262817\n",
      "Epoch 50: loss=0.2804892361164093\n",
      "Epoch 60: loss=0.17760765552520752\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.4926730672056594\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.7638473510742188\n",
      "Epoch 20: loss=1.0306566953659058\n",
      "Epoch 30: loss=0.33494728803634644\n",
      "Epoch 40: loss=0.12321244925260544\n",
      "Epoch 50: loss=0.06694495677947998\n",
      "Epoch 60: loss=0.04408492147922516\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.5391611925214755\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.1319000720977783\n",
      "Epoch 20: loss=0.4275720715522766\n",
      "Epoch 30: loss=0.08996173739433289\n",
      "Epoch 40: loss=0.03679006174206734\n",
      "Epoch 50: loss=0.02245771512389183\n",
      "Epoch 60: loss=0.014180907979607582\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.5694795351187468\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.181133508682251\n",
      "Epoch 20: loss=0.5440213680267334\n",
      "Epoch 30: loss=0.13761019706726074\n",
      "Epoch 40: loss=0.05572129040956497\n",
      "Epoch 50: loss=0.034087251871824265\n",
      "Epoch 60: loss=0.02450546622276306\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.5659423951490652\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.7179852724075317\n",
      "Epoch 20: loss=0.2935958504676819\n",
      "Epoch 30: loss=0.06739538162946701\n",
      "Epoch 40: loss=0.029662614688277245\n",
      "Epoch 50: loss=0.01687823049724102\n",
      "Epoch 60: loss=0.013030913658440113\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.5583628094997474\n",
      "------------------------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset.x)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Best model with hidden size({best_hid1}, {best_hid2}): Test accuracy= {acc}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8l2vAWOxB-4",
    "outputId": "c980e3fb-6a2a-4fa5-ab92-754ca49c5daf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model with hidden size(128, 64): Test accuracy= 0.5549381156857792\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **GCN**"
   ],
   "metadata": {
    "id": "t6-4RJoJvOt1",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **GCNOneLayer**"
   ],
   "metadata": {
    "id": "_PL810rqpkER",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the one-layer GCN model\n",
    "class GCNOneLayer(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(GCNOneLayer, self).__init__()\n",
    "        self.conv1 = GCNConv(input_size, output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # Graph convolution\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "metadata": {
    "id": "xU2ObWmk7wqM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cite\n",
    "print('Dataset: CiteSeer')\n",
    "\n",
    "# Define training parameters\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Define model\n",
    "model = GCNOneLayer(dataset.num_features, dataset.num_classes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"...Training Start...\")\n",
    "\n",
    "# Training\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(dataset)\n",
    "    loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Printing Every 10 epochs\n",
    "    if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "      print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "    acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "print(f\"...Training End...\")\n",
    "print(f\"\\nValidation accuracy= {acc}\")\n",
    "\n",
    "# Updateing best model\n",
    "if best_model is None:\n",
    "  best_model = model\n",
    "  best_acc = acc\n",
    "  best_hid = layer_size\n",
    "\n",
    "if acc > best_acc:\n",
    "  best_model = model\n",
    "  best_acc = acc\n",
    "  best_hid = layer_size\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Test accuracy= {acc}\")"
   ],
   "metadata": {
    "id": "H8a0fV6M9UG4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cbb91ae5-d743-4e78-b930-3b325999aa61",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CiteSeer\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.4646530151367188\n",
      "Epoch 20: loss=1.2447566986083984\n",
      "Epoch 30: loss=1.09996497631073\n",
      "Epoch 40: loss=1.2056366205215454\n",
      "Epoch 50: loss=1.004309058189392\n",
      "Epoch 60: loss=1.211988091468811\n",
      "Epoch 70: loss=0.8842710256576538\n",
      "Epoch 80: loss=1.092057704925537\n",
      "Epoch 90: loss=1.19599449634552\n",
      "Epoch 100: loss=1.1956760883331299\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.632\n",
      "Test accuracy= 0.642\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cora\n",
    "print('Dataset: CoraFull')\n",
    "\n",
    "# Define training parameters\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Define model\n",
    "model = GCNOneLayer(dataset.num_features, dataset.num_classes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"...Training Start...\")\n",
    "\n",
    "# Training\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(dataset)\n",
    "    loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Printing Every 10 epochs\n",
    "    if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "      print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "    acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "print(f\"...Training End...\")\n",
    "print(f\"\\nValidation accuracy= {acc}\")\n",
    "\n",
    "# Updateing best model\n",
    "if best_model is None:\n",
    "  best_model = model\n",
    "  best_acc = acc\n",
    "  best_hid = layer_size\n",
    "\n",
    "if acc > best_acc:\n",
    "  best_model = model\n",
    "  best_acc = acc\n",
    "  best_hid = layer_size\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Test accuracy= {acc}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UNmxyGtsoXPw",
    "outputId": "ef5ae16d-9b6c-4e85-c7e1-f2d32fec80ea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CoraFull\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.0957624912261963\n",
      "Epoch 20: loss=2.7036778926849365\n",
      "Epoch 30: loss=2.562960624694824\n",
      "Epoch 40: loss=2.4296939373016357\n",
      "Epoch 50: loss=2.370854616165161\n",
      "Epoch 60: loss=2.3782007694244385\n",
      "Epoch 70: loss=2.3455708026885986\n",
      "Epoch 80: loss=2.277073383331299\n",
      "Epoch 90: loss=2.3044869899749756\n",
      "Epoch 100: loss=2.298126697540283\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6690247599797877\n",
      "Test accuracy= 0.6723920181864107\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **GCNTwoLayer**"
   ],
   "metadata": {
    "id": "dT8aHcTIpNRK",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the two-layer GCN model\n",
    "class GCNTwoLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GCNTwoLayer, self).__init__()\n",
    "        self.conv1 = GCNConv(input_size, hidden_size)\n",
    "        self.conv2 = GCNConv(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # First graph convolution\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # Second graph convolution\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "metadata": {
    "id": "KCCAOYxqFtmX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cite\n",
    "print('Dataset: CiteSeer')\n",
    "\n",
    "# Define training parameters\n",
    "layers_size = [8,16,32,64,128]\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Training Loop\n",
    "for layer_size in layers_size:\n",
    "\n",
    "    # Define model\n",
    "    model = GCNTwoLayer(dataset.num_features, layer_size, dataset.num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Model with hidden size({layer_size}):\\n\")\n",
    "    print(f\"...Training Start...\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(dataset)\n",
    "        loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Printing Every 10 epochs\n",
    "        if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "          print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(dataset)\n",
    "        _, predicted = logits.max(dim=1)\n",
    "        correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "        acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "    print(f\"...Training End...\")\n",
    "    print(f\"\\nValidation accuracy= {acc}\")\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Updateing best model\n",
    "    if best_model is None:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid = layer_size\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid = layer_size"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6u39meIFtpP",
    "outputId": "c255ffe4-f066-462b-fd26-57c5292649cb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CiteSeer\n",
      "Model with hidden size(8):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.5549399852752686\n",
      "Epoch 20: loss=1.312578797340393\n",
      "Epoch 30: loss=1.2914199829101562\n",
      "Epoch 40: loss=1.3019603490829468\n",
      "Epoch 50: loss=1.2445485591888428\n",
      "Epoch 60: loss=1.2801926136016846\n",
      "Epoch 70: loss=1.0802642107009888\n",
      "Epoch 80: loss=1.0982940196990967\n",
      "Epoch 90: loss=1.2315618991851807\n",
      "Epoch 100: loss=1.2666003704071045\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.534\n",
      "------------------------------------------\n",
      "Model with hidden size(16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.3551170825958252\n",
      "Epoch 20: loss=0.9645804762840271\n",
      "Epoch 30: loss=0.80122309923172\n",
      "Epoch 40: loss=1.1027569770812988\n",
      "Epoch 50: loss=1.0815502405166626\n",
      "Epoch 60: loss=1.1656967401504517\n",
      "Epoch 70: loss=0.9475343227386475\n",
      "Epoch 80: loss=0.948855459690094\n",
      "Epoch 90: loss=0.8423164486885071\n",
      "Epoch 100: loss=1.0675699710845947\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.62\n",
      "------------------------------------------\n",
      "Model with hidden size(32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.3436757326126099\n",
      "Epoch 20: loss=1.2615323066711426\n",
      "Epoch 30: loss=0.9191911220550537\n",
      "Epoch 40: loss=1.0407387018203735\n",
      "Epoch 50: loss=0.9002601504325867\n",
      "Epoch 60: loss=0.9893273711204529\n",
      "Epoch 70: loss=0.871480405330658\n",
      "Epoch 80: loss=0.7734642624855042\n",
      "Epoch 90: loss=0.8039149045944214\n",
      "Epoch 100: loss=0.8477910161018372\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.632\n",
      "------------------------------------------\n",
      "Model with hidden size(64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.2859491109848022\n",
      "Epoch 20: loss=1.0361711978912354\n",
      "Epoch 30: loss=1.0556423664093018\n",
      "Epoch 40: loss=0.8942305445671082\n",
      "Epoch 50: loss=0.8739064335823059\n",
      "Epoch 60: loss=0.8849794864654541\n",
      "Epoch 70: loss=0.8985053896903992\n",
      "Epoch 80: loss=0.9447324275970459\n",
      "Epoch 90: loss=0.8081015348434448\n",
      "Epoch 100: loss=0.9714489579200745\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.632\n",
      "------------------------------------------\n",
      "Model with hidden size(128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.215924859046936\n",
      "Epoch 20: loss=1.0969796180725098\n",
      "Epoch 30: loss=0.9830597639083862\n",
      "Epoch 40: loss=1.0035243034362793\n",
      "Epoch 50: loss=1.0077931880950928\n",
      "Epoch 60: loss=1.0379599332809448\n",
      "Epoch 70: loss=1.1807585954666138\n",
      "Epoch 80: loss=1.0157607793807983\n",
      "Epoch 90: loss=1.1005899906158447\n",
      "Epoch 100: loss=0.9297525882720947\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.502\n",
      "------------------------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Best model with hidden size({best_hid}): Test accuracy= {acc}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6oSu50Ek9kLE",
    "outputId": "fc53a3f2-2112-46bd-a08f-1bd97f1b0853",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model with hidden size(32): Test accuracy= 0.629\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cora\n",
    "print('Dataset: CoraFull')\n",
    "\n",
    "# Define training parameters\n",
    "layers_size = [8,16,32,64,128]\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Training Loop\n",
    "for layer_size in layers_size:\n",
    "\n",
    "    # Define model\n",
    "    model = GCNTwoLayer(dataset.num_features, layer_size, dataset.num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Model with hidden size({layer_size}):\\n\")\n",
    "    print(f\"...Training Start...\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(dataset)\n",
    "        loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Printing Every 10 epochs\n",
    "        if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "          print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(dataset)\n",
    "        _, predicted = logits.max(dim=1)\n",
    "        correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "        acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "    print(f\"...Training End...\")\n",
    "    print(f\"\\nValidation accuracy= {acc}\")\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Updateing best model\n",
    "    if best_model is None:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid = layer_size\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid = layer_size"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xSpIwgrmRIV",
    "outputId": "31ee5789-021d-4b20-9514-49e5b2a3e6bb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CoraFull\n",
      "Model with hidden size(8):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.074256420135498\n",
      "Epoch 20: loss=3.83715558052063\n",
      "Epoch 30: loss=3.697192907333374\n",
      "Epoch 40: loss=3.596369743347168\n",
      "Epoch 50: loss=3.5249979496002197\n",
      "Epoch 60: loss=3.438077211380005\n",
      "Epoch 70: loss=3.4119555950164795\n",
      "Epoch 80: loss=3.4046425819396973\n",
      "Epoch 90: loss=3.388505220413208\n",
      "Epoch 100: loss=3.3363022804260254\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.5755432036382011\n",
      "------------------------------------------\n",
      "Model with hidden size(16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.818264961242676\n",
      "Epoch 20: loss=3.4943578243255615\n",
      "Epoch 30: loss=3.3044064044952393\n",
      "Epoch 40: loss=3.177940845489502\n",
      "Epoch 50: loss=3.1104774475097656\n",
      "Epoch 60: loss=3.043520450592041\n",
      "Epoch 70: loss=2.9811851978302\n",
      "Epoch 80: loss=2.9442453384399414\n",
      "Epoch 90: loss=2.8934435844421387\n",
      "Epoch 100: loss=2.8633744716644287\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6664982314300152\n",
      "------------------------------------------\n",
      "Model with hidden size(32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.610060691833496\n",
      "Epoch 20: loss=3.1942732334136963\n",
      "Epoch 30: loss=3.030555486679077\n",
      "Epoch 40: loss=2.9242069721221924\n",
      "Epoch 50: loss=2.831047773361206\n",
      "Epoch 60: loss=2.7922539710998535\n",
      "Epoch 70: loss=2.7445528507232666\n",
      "Epoch 80: loss=2.7129921913146973\n",
      "Epoch 90: loss=2.6948115825653076\n",
      "Epoch 100: loss=2.6843793392181396\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.675088428499242\n",
      "------------------------------------------\n",
      "Model with hidden size(64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.2142701148986816\n",
      "Epoch 20: loss=2.9067206382751465\n",
      "Epoch 30: loss=2.794729471206665\n",
      "Epoch 40: loss=2.694014072418213\n",
      "Epoch 50: loss=2.644482374191284\n",
      "Epoch 60: loss=2.572453022003174\n",
      "Epoch 70: loss=2.5600860118865967\n",
      "Epoch 80: loss=2.542065382003784\n",
      "Epoch 90: loss=2.5338761806488037\n",
      "Epoch 100: loss=2.5001425743103027\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6801414855987873\n",
      "------------------------------------------\n",
      "Model with hidden size(128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.0678014755249023\n",
      "Epoch 20: loss=2.8377490043640137\n",
      "Epoch 30: loss=2.690615653991699\n",
      "Epoch 40: loss=2.644113063812256\n",
      "Epoch 50: loss=2.582242965698242\n",
      "Epoch 60: loss=2.5286319255828857\n",
      "Epoch 70: loss=2.525824785232544\n",
      "Epoch 80: loss=2.463526725769043\n",
      "Epoch 90: loss=2.4632537364959717\n",
      "Epoch 100: loss=2.477450370788574\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6609398686205155\n",
      "------------------------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Best model with hidden size({best_hid}): Test accuracy= {acc}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FHLxT5nrmUhx",
    "outputId": "3f33c7e4-411a-41c1-bc3d-ae22f21f465f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model with hidden size(64): Test accuracy= 0.6900732508209144\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **GCNThreeLayer**"
   ],
   "metadata": {
    "id": "-EhSLsB6p1mY",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the three-layer GCN model\n",
    "class GCNThreeLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(GCNThreeLayer, self).__init__()\n",
    "        self.conv1 = GCNConv(input_size, hidden_size1)\n",
    "        self.conv2 = GCNConv(hidden_size1, hidden_size2)\n",
    "        self.conv3 = GCNConv(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # First graph convolution\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # Second graph convolution\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # Third graph convolution\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "metadata": {
    "id": "lz22qAJFlk-o",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Desired numbers\n",
    "numbers = [128, 64, 32, 16]\n",
    "\n",
    "# Generate all possible combinations of 3 numbers without repetition\n",
    "combinations_list = [(a, b) for a in numbers for b in numbers]\n",
    "\n",
    "# Filter combinations based on the condition\n",
    "filtered_list = []\n",
    "\n",
    "# Iterate through combinations and add to filtered_list only if it satisfies the condition\n",
    "for combination in combinations_list:\n",
    "    if combination[0] >= combination[1]:\n",
    "        filtered_list.append(combination)\n",
    "\n",
    "# Print the resulting list\n",
    "print(filtered_list)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e43sCarzsaW8",
    "outputId": "1e06a8e6-eac5-453d-aca1-431e219334ca",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(128, 128), (128, 64), (128, 32), (128, 16), (64, 64), (64, 32), (64, 16), (32, 32), (32, 16), (16, 16)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cora\n",
    "print('Dataset: CoraFull')\n",
    "\n",
    "# Define training parameters\n",
    "layers_size =filtered_list\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Training Loop\n",
    "for layer_size in layers_size:\n",
    "\n",
    "    # Define model\n",
    "    model = GCNThreeLayer(dataset.num_features, layer_size[0], layer_size[1], dataset.num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Model with hidden size({layer_size[0]}, {layer_size[1]}):\\n\")\n",
    "    print(f\"...Training Start...\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(dataset)\n",
    "        loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Printing Every 10 epochs\n",
    "        if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "          print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(dataset)\n",
    "        _, predicted = logits.max(dim=1)\n",
    "        correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "        acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "    print(f\"...Training End...\")\n",
    "    print(f\"\\nValidation accuracy= {acc}\")\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Updateing best model\n",
    "    if best_model is None:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRL52E-Kn2oI",
    "outputId": "5065c88a-9871-4c3b-ce5d-f0ebf3617d63",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CoraFull\n",
      "Model with hidden size(128, 128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.543853998184204\n",
      "Epoch 20: loss=3.2718899250030518\n",
      "Epoch 30: loss=3.1218061447143555\n",
      "Epoch 40: loss=3.0559699535369873\n",
      "Epoch 50: loss=3.0270118713378906\n",
      "Epoch 60: loss=2.9804909229278564\n",
      "Epoch 70: loss=2.971116542816162\n",
      "Epoch 80: loss=2.9742701053619385\n",
      "Epoch 90: loss=2.9289028644561768\n",
      "Epoch 100: loss=2.9206366539001465\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.562910560889338\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.395399808883667\n",
      "Epoch 20: loss=3.0633139610290527\n",
      "Epoch 30: loss=2.97442626953125\n",
      "Epoch 40: loss=2.8976869583129883\n",
      "Epoch 50: loss=2.8286190032958984\n",
      "Epoch 60: loss=2.816157579421997\n",
      "Epoch 70: loss=2.782951593399048\n",
      "Epoch 80: loss=2.7598178386688232\n",
      "Epoch 90: loss=2.7347259521484375\n",
      "Epoch 100: loss=2.7793264389038086\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6437594744820616\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.661546230316162\n",
      "Epoch 20: loss=3.2441465854644775\n",
      "Epoch 30: loss=3.0765247344970703\n",
      "Epoch 40: loss=2.9740188121795654\n",
      "Epoch 50: loss=2.913529396057129\n",
      "Epoch 60: loss=2.8925461769104004\n",
      "Epoch 70: loss=2.8461368083953857\n",
      "Epoch 80: loss=2.8184080123901367\n",
      "Epoch 90: loss=2.7982497215270996\n",
      "Epoch 100: loss=2.749276638031006\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6483072258716523\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.794020891189575\n",
      "Epoch 20: loss=3.4707276821136475\n",
      "Epoch 30: loss=3.2909035682678223\n",
      "Epoch 40: loss=3.198237419128418\n",
      "Epoch 50: loss=3.1169984340667725\n",
      "Epoch 60: loss=3.0628929138183594\n",
      "Epoch 70: loss=3.0166664123535156\n",
      "Epoch 80: loss=2.9656577110290527\n",
      "Epoch 90: loss=2.931466817855835\n",
      "Epoch 100: loss=2.9334964752197266\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.663466397170288\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.554518938064575\n",
      "Epoch 20: loss=3.176955223083496\n",
      "Epoch 30: loss=3.0465481281280518\n",
      "Epoch 40: loss=2.9530200958251953\n",
      "Epoch 50: loss=2.904470920562744\n",
      "Epoch 60: loss=2.880654811859131\n",
      "Epoch 70: loss=2.8593220710754395\n",
      "Epoch 80: loss=2.8485052585601807\n",
      "Epoch 90: loss=2.822657346725464\n",
      "Epoch 100: loss=2.7969260215759277\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6235472460838808\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.591693878173828\n",
      "Epoch 20: loss=3.26061749458313\n",
      "Epoch 30: loss=3.1168975830078125\n",
      "Epoch 40: loss=3.0465023517608643\n",
      "Epoch 50: loss=2.991572141647339\n",
      "Epoch 60: loss=2.937502145767212\n",
      "Epoch 70: loss=2.8960211277008057\n",
      "Epoch 80: loss=2.8702359199523926\n",
      "Epoch 90: loss=2.826627254486084\n",
      "Epoch 100: loss=2.8192572593688965\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6543708943911066\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.8222031593322754\n",
      "Epoch 20: loss=3.5328097343444824\n",
      "Epoch 30: loss=3.334948778152466\n",
      "Epoch 40: loss=3.2400708198547363\n",
      "Epoch 50: loss=3.1595048904418945\n",
      "Epoch 60: loss=3.099956512451172\n",
      "Epoch 70: loss=3.0577476024627686\n",
      "Epoch 80: loss=3.0414977073669434\n",
      "Epoch 90: loss=2.9841690063476562\n",
      "Epoch 100: loss=2.9983720779418945\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6543708943911066\n",
      "------------------------------------------\n",
      "Model with hidden size(32, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.8437130451202393\n",
      "Epoch 20: loss=3.4886410236358643\n",
      "Epoch 30: loss=3.284217596054077\n",
      "Epoch 40: loss=3.1943910121917725\n",
      "Epoch 50: loss=3.135279417037964\n",
      "Epoch 60: loss=3.0846147537231445\n",
      "Epoch 70: loss=3.048469305038452\n",
      "Epoch 80: loss=3.004960775375366\n",
      "Epoch 90: loss=3.009018659591675\n",
      "Epoch 100: loss=3.0034055709838867\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6114199090449722\n",
      "------------------------------------------\n",
      "Model with hidden size(32, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.936039924621582\n",
      "Epoch 20: loss=3.6431565284729004\n",
      "Epoch 30: loss=3.4574697017669678\n",
      "Epoch 40: loss=3.341063976287842\n",
      "Epoch 50: loss=3.26916241645813\n",
      "Epoch 60: loss=3.2354695796966553\n",
      "Epoch 70: loss=3.195936918258667\n",
      "Epoch 80: loss=3.1722939014434814\n",
      "Epoch 90: loss=3.141892910003662\n",
      "Epoch 100: loss=3.113420009613037\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.607377463365336\n",
      "------------------------------------------\n",
      "Model with hidden size(16, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.9616034030914307\n",
      "Epoch 20: loss=3.6952357292175293\n",
      "Epoch 30: loss=3.5111451148986816\n",
      "Epoch 40: loss=3.378929376602173\n",
      "Epoch 50: loss=3.2739083766937256\n",
      "Epoch 60: loss=3.2552857398986816\n",
      "Epoch 70: loss=3.228994846343994\n",
      "Epoch 80: loss=3.16469144821167\n",
      "Epoch 90: loss=3.1661770343780518\n",
      "Epoch 100: loss=3.0963010787963867\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6690247599797877\n",
      "------------------------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Best model with hidden size({best_hid1},{best_hid2}): Test accuracy= {acc}\")"
   ],
   "metadata": {
    "id": "Q7B-etaB8j7P",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "daf94185-c1d4-4bf2-99d2-8f637a46d3ce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model with hidden size(16,16): Test accuracy= 0.6569840868906289\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cite\n",
    "print('Dataset: CiteSeer')\n",
    "\n",
    "# Define training parameters\n",
    "layers_size =filtered_list\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Training Loop\n",
    "for layer_size in layers_size:\n",
    "\n",
    "    # Define model\n",
    "    model = GCNThreeLayer(dataset.num_features, layer_size[0], layer_size[1], dataset.num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Model with hidden size({layer_size[0]}, {layer_size[1]}):\\n\")\n",
    "    print(f\"...Training Start...\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(dataset)\n",
    "        loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Printing Every 10 epochs\n",
    "        if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "          print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(dataset)\n",
    "        _, predicted = logits.max(dim=1)\n",
    "        correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "        acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "    print(f\"...Training End...\")\n",
    "    print(f\"\\nValidation accuracy= {acc}\")\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Updateing best model\n",
    "    if best_model is None:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jaLTSBGjuhe0",
    "outputId": "6feaf2ce-7040-4d23-ac1e-788913fae126",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CiteSeer\n",
      "Model with hidden size(128, 128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.3910200595855713\n",
      "Epoch 20: loss=1.2612040042877197\n",
      "Epoch 30: loss=1.3214702606201172\n",
      "Epoch 40: loss=1.2408978939056396\n",
      "Epoch 50: loss=1.0626251697540283\n",
      "Epoch 60: loss=1.1729278564453125\n",
      "Epoch 70: loss=1.184701681137085\n",
      "Epoch 80: loss=1.1647896766662598\n",
      "Epoch 90: loss=1.2247505187988281\n",
      "Epoch 100: loss=1.2139573097229004\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.378\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.3572739362716675\n",
      "Epoch 20: loss=1.0728156566619873\n",
      "Epoch 30: loss=0.9264621734619141\n",
      "Epoch 40: loss=1.1109809875488281\n",
      "Epoch 50: loss=0.9719001650810242\n",
      "Epoch 60: loss=1.0348759889602661\n",
      "Epoch 70: loss=0.8189926743507385\n",
      "Epoch 80: loss=0.9888937473297119\n",
      "Epoch 90: loss=0.9323304295539856\n",
      "Epoch 100: loss=0.8558350801467896\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.644\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.2294155359268188\n",
      "Epoch 20: loss=1.0876179933547974\n",
      "Epoch 30: loss=1.1394351720809937\n",
      "Epoch 40: loss=0.955386221408844\n",
      "Epoch 50: loss=1.052350401878357\n",
      "Epoch 60: loss=0.9594286680221558\n",
      "Epoch 70: loss=1.169865369796753\n",
      "Epoch 80: loss=0.9065971374511719\n",
      "Epoch 90: loss=0.9111832976341248\n",
      "Epoch 100: loss=1.0318044424057007\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.64\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.315914511680603\n",
      "Epoch 20: loss=1.1664639711380005\n",
      "Epoch 30: loss=1.0976231098175049\n",
      "Epoch 40: loss=1.0873757600784302\n",
      "Epoch 50: loss=1.025773525238037\n",
      "Epoch 60: loss=0.9994888305664062\n",
      "Epoch 70: loss=1.1895973682403564\n",
      "Epoch 80: loss=0.9836046695709229\n",
      "Epoch 90: loss=1.0892833471298218\n",
      "Epoch 100: loss=0.9967050552368164\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.644\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.0945113897323608\n",
      "Epoch 20: loss=0.8489285707473755\n",
      "Epoch 30: loss=0.9912359714508057\n",
      "Epoch 40: loss=1.0064327716827393\n",
      "Epoch 50: loss=0.9654456973075867\n",
      "Epoch 60: loss=0.8753748536109924\n",
      "Epoch 70: loss=0.8875820636749268\n",
      "Epoch 80: loss=0.9985488653182983\n",
      "Epoch 90: loss=0.861965537071228\n",
      "Epoch 100: loss=0.8232195973396301\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.646\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.1078755855560303\n",
      "Epoch 20: loss=0.994625449180603\n",
      "Epoch 30: loss=0.9744243025779724\n",
      "Epoch 40: loss=1.0557888746261597\n",
      "Epoch 50: loss=1.0570875406265259\n",
      "Epoch 60: loss=0.7362459897994995\n",
      "Epoch 70: loss=0.963024377822876\n",
      "Epoch 80: loss=0.8910211324691772\n",
      "Epoch 90: loss=0.8732328414916992\n",
      "Epoch 100: loss=0.8505133390426636\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.642\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.41971755027771\n",
      "Epoch 20: loss=1.283805012702942\n",
      "Epoch 30: loss=1.1131659746170044\n",
      "Epoch 40: loss=1.3377623558044434\n",
      "Epoch 50: loss=1.1627486944198608\n",
      "Epoch 60: loss=1.214455485343933\n",
      "Epoch 70: loss=1.1165947914123535\n",
      "Epoch 80: loss=1.1217767000198364\n",
      "Epoch 90: loss=1.1223269701004028\n",
      "Epoch 100: loss=1.0270678997039795\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.496\n",
      "------------------------------------------\n",
      "Model with hidden size(32, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.4287126064300537\n",
      "Epoch 20: loss=1.1864559650421143\n",
      "Epoch 30: loss=0.9220161437988281\n",
      "Epoch 40: loss=0.998830258846283\n",
      "Epoch 50: loss=0.9999683499336243\n",
      "Epoch 60: loss=0.8601712584495544\n",
      "Epoch 70: loss=1.0219773054122925\n",
      "Epoch 80: loss=0.9790850281715393\n",
      "Epoch 90: loss=0.9479435086250305\n",
      "Epoch 100: loss=0.9608529210090637\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.648\n",
      "------------------------------------------\n",
      "Model with hidden size(32, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.3998807668685913\n",
      "Epoch 20: loss=1.308556318283081\n",
      "Epoch 30: loss=1.1610114574432373\n",
      "Epoch 40: loss=0.9576444029808044\n",
      "Epoch 50: loss=0.924426794052124\n",
      "Epoch 60: loss=1.1782554388046265\n",
      "Epoch 70: loss=0.9081340432167053\n",
      "Epoch 80: loss=0.9283388257026672\n",
      "Epoch 90: loss=0.9687942266464233\n",
      "Epoch 100: loss=1.0241698026657104\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.646\n",
      "------------------------------------------\n",
      "Model with hidden size(16, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.634682297706604\n",
      "Epoch 20: loss=1.3806501626968384\n",
      "Epoch 30: loss=1.3015714883804321\n",
      "Epoch 40: loss=1.191970944404602\n",
      "Epoch 50: loss=1.1391043663024902\n",
      "Epoch 60: loss=1.029244065284729\n",
      "Epoch 70: loss=1.0447643995285034\n",
      "Epoch 80: loss=1.0263909101486206\n",
      "Epoch 90: loss=0.9660536050796509\n",
      "Epoch 100: loss=0.977610170841217\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.652\n",
      "------------------------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Best model with hidden size({best_hid1},{best_hid2}): Test accuracy= {acc}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAtcywbiuhri",
    "outputId": "0ecf0868-af95-4ac5-faf5-d4e9e5845b43",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model with hidden size(16,16): Test accuracy= 0.631\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **GAT**"
   ],
   "metadata": {
    "id": "p_B26FcE3Nfo",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **GATOneLayer**"
   ],
   "metadata": {
    "id": "vwMDkW1d965l",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the one-layer GAT model\n",
    "class GATOneLayer(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_heads=1):\n",
    "        super(GATOneLayer, self).__init__()\n",
    "        self.conv1 = GATConv(input_size, output_size, heads=num_heads, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # Graph attention layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)  # Use ELU activation for GAT\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "metadata": {
    "id": "yuob9qKW-Dpm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cite\n",
    "print('Dataset: CiteSeer')\n",
    "\n",
    "# Define training parameters\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Define model\n",
    "model = GATOneLayer(dataset.num_features, dataset.num_classes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"...Training Start...\")\n",
    "\n",
    "# Training\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(dataset)\n",
    "    loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Printing Every 10 epochs\n",
    "    if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "      print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "    acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "print(f\"...Training End...\")\n",
    "print(f\"\\nValidation accuracy= {acc}\")\n",
    "\n",
    "# Updateing best model\n",
    "if best_model is None:\n",
    "  best_model = model\n",
    "  best_acc = acc\n",
    "  best_hid = layer_size\n",
    "\n",
    "if acc > best_acc:\n",
    "  best_model = model\n",
    "  best_acc = acc\n",
    "  best_hid = layer_size\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Test accuracy= {acc}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hNeE2fU2-JV1",
    "outputId": "620a74de-8307-4230-8b80-9bf6ed7dc257",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CiteSeer\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.287513017654419\n",
      "Epoch 20: loss=1.0465415716171265\n",
      "Epoch 30: loss=1.015625\n",
      "Epoch 40: loss=1.0997295379638672\n",
      "Epoch 50: loss=1.1209286451339722\n",
      "Epoch 60: loss=1.0280290842056274\n",
      "Epoch 70: loss=0.9495161175727844\n",
      "Epoch 80: loss=0.957697331905365\n",
      "Epoch 90: loss=0.9753391742706299\n",
      "Epoch 100: loss=0.9474474787712097\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.638\n",
      "Test accuracy= 0.633\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "num_heads = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Train and evaluate GAT with variable attention heads\n",
    "best_accuracy = 0.0\n",
    "best_num_heads = None\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "for num_head in num_heads:\n",
    "\n",
    "  # Define model\n",
    "  model = GATOneLayer(dataset.num_features, dataset.num_classes, num_heads=num_head)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  print(f\"Attention-heads: {num_head}\")\n",
    "  print(f\"...Training Start...\")\n",
    "\n",
    "  # Training\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset)\n",
    "      loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Printing Every 10 epochs\n",
    "      if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "        print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "  # Evaluation\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      logits = model(dataset)\n",
    "      _, predicted = logits.max(dim=1)\n",
    "      correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "      acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "  print(f\"...Training End...\")\n",
    "  print(f\"\\nValidation accuracy= {acc}\")\n",
    "  print(\"------------------------------------------\")\n",
    "\n",
    "  # Updateing best model\n",
    "  if best_model is None:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "  if acc > best_acc:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f'Best GATOneLayer with Variable Attention Heads({best_num_heads}) Test Accuracy : {acc}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-_XWMbEKmI6",
    "outputId": "9197a77d-b901-4206-c48a-e5c1dbdfd66e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention-heads: 1\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.2572972774505615\n",
      "Epoch 20: loss=0.9720839262008667\n",
      "Epoch 30: loss=0.9903488755226135\n",
      "Epoch 40: loss=0.8928050398826599\n",
      "Epoch 50: loss=0.8323952555656433\n",
      "Epoch 60: loss=0.9574065804481506\n",
      "Epoch 70: loss=0.903209924697876\n",
      "Epoch 80: loss=1.0071645975112915\n",
      "Epoch 90: loss=0.9445964694023132\n",
      "Epoch 100: loss=0.934622049331665\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.636\n",
      "------------------------------------------\n",
      "Attention-heads: 2\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.5760244131088257\n",
      "Epoch 20: loss=1.589318871498108\n",
      "Epoch 30: loss=1.4864444732666016\n",
      "Epoch 40: loss=1.2087541818618774\n",
      "Epoch 50: loss=1.27741539478302\n",
      "Epoch 60: loss=1.2302677631378174\n",
      "Epoch 70: loss=1.0791707038879395\n",
      "Epoch 80: loss=1.1882551908493042\n",
      "Epoch 90: loss=1.304964542388916\n",
      "Epoch 100: loss=1.433945894241333\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.634\n",
      "------------------------------------------\n",
      "Attention-heads: 3\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.7847422361373901\n",
      "Epoch 20: loss=1.761250376701355\n",
      "Epoch 30: loss=1.7599526643753052\n",
      "Epoch 40: loss=1.4634437561035156\n",
      "Epoch 50: loss=1.3639298677444458\n",
      "Epoch 60: loss=1.4110163450241089\n",
      "Epoch 70: loss=1.5497171878814697\n",
      "Epoch 80: loss=1.6568691730499268\n",
      "Epoch 90: loss=1.4221230745315552\n",
      "Epoch 100: loss=1.5538047552108765\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.622\n",
      "------------------------------------------\n",
      "Attention-heads: 4\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.0912997722625732\n",
      "Epoch 20: loss=2.1835007667541504\n",
      "Epoch 30: loss=1.7535510063171387\n",
      "Epoch 40: loss=1.9175130128860474\n",
      "Epoch 50: loss=1.6018702983856201\n",
      "Epoch 60: loss=1.5016155242919922\n",
      "Epoch 70: loss=1.7506678104400635\n",
      "Epoch 80: loss=1.6818721294403076\n",
      "Epoch 90: loss=1.5405030250549316\n",
      "Epoch 100: loss=1.6872721910476685\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.632\n",
      "------------------------------------------\n",
      "Attention-heads: 5\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.2987773418426514\n",
      "Epoch 20: loss=2.2542147636413574\n",
      "Epoch 30: loss=1.8147691488265991\n",
      "Epoch 40: loss=2.0810463428497314\n",
      "Epoch 50: loss=1.8066201210021973\n",
      "Epoch 60: loss=1.6485859155654907\n",
      "Epoch 70: loss=1.8734605312347412\n",
      "Epoch 80: loss=1.7710115909576416\n",
      "Epoch 90: loss=2.092768669128418\n",
      "Epoch 100: loss=1.619337797164917\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.636\n",
      "------------------------------------------\n",
      "Attention-heads: 6\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.228332757949829\n",
      "Epoch 20: loss=2.2958319187164307\n",
      "Epoch 30: loss=1.957491397857666\n",
      "Epoch 40: loss=1.7705634832382202\n",
      "Epoch 50: loss=1.8419578075408936\n",
      "Epoch 60: loss=1.9374809265136719\n",
      "Epoch 70: loss=1.768054723739624\n",
      "Epoch 80: loss=1.8384021520614624\n",
      "Epoch 90: loss=1.8950690031051636\n",
      "Epoch 100: loss=1.705077052116394\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.628\n",
      "------------------------------------------\n",
      "Attention-heads: 7\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.620591163635254\n",
      "Epoch 20: loss=2.1097769737243652\n",
      "Epoch 30: loss=2.189530611038208\n",
      "Epoch 40: loss=1.8798478841781616\n",
      "Epoch 50: loss=1.7454235553741455\n",
      "Epoch 60: loss=2.0832254886627197\n",
      "Epoch 70: loss=2.095325231552124\n",
      "Epoch 80: loss=2.1159164905548096\n",
      "Epoch 90: loss=1.9770808219909668\n",
      "Epoch 100: loss=1.8732880353927612\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.658\n",
      "------------------------------------------\n",
      "Attention-heads: 8\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.53436279296875\n",
      "Epoch 20: loss=2.1361327171325684\n",
      "Epoch 30: loss=2.258270502090454\n",
      "Epoch 40: loss=2.487954616546631\n",
      "Epoch 50: loss=2.1356730461120605\n",
      "Epoch 60: loss=2.122957468032837\n",
      "Epoch 70: loss=1.9690319299697876\n",
      "Epoch 80: loss=2.0554559230804443\n",
      "Epoch 90: loss=2.0468361377716064\n",
      "Epoch 100: loss=2.198920965194702\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.644\n",
      "------------------------------------------\n",
      "Attention-heads: 9\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.7122690677642822\n",
      "Epoch 20: loss=2.1773436069488525\n",
      "Epoch 30: loss=1.9868050813674927\n",
      "Epoch 40: loss=2.387871265411377\n",
      "Epoch 50: loss=1.9686744213104248\n",
      "Epoch 60: loss=1.923196792602539\n",
      "Epoch 70: loss=2.0213499069213867\n",
      "Epoch 80: loss=2.116649866104126\n",
      "Epoch 90: loss=2.151315450668335\n",
      "Epoch 100: loss=2.1496975421905518\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.632\n",
      "------------------------------------------\n",
      "Attention-heads: 10\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.849269151687622\n",
      "Epoch 20: loss=2.853870153427124\n",
      "Epoch 30: loss=2.3569223880767822\n",
      "Epoch 40: loss=2.184979200363159\n",
      "Epoch 50: loss=2.284329891204834\n",
      "Epoch 60: loss=2.094802141189575\n",
      "Epoch 70: loss=2.6094300746917725\n",
      "Epoch 80: loss=2.0038349628448486\n",
      "Epoch 90: loss=2.2892098426818848\n",
      "Epoch 100: loss=2.224621057510376\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.63\n",
      "------------------------------------------\n",
      "Best GATOneLayer with Variable Attention Heads(7) Test Accuracy : 0.637\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cora\n",
    "print('Dataset: CoraFull')\n",
    "\n",
    "# Define training parameters\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Define model\n",
    "model = GATOneLayer(dataset.num_features, dataset.num_classes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"...Training Start...\")\n",
    "\n",
    "# Training\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(dataset)\n",
    "    loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Printing Every 10 epochs\n",
    "    if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "      print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "    acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "print(f\"...Training End...\")\n",
    "print(f\"\\nValidation accuracy= {acc}\")\n",
    "\n",
    "# Updateing best model\n",
    "if best_model is None:\n",
    "  best_model = model\n",
    "  best_acc = acc\n",
    "  best_hid = layer_size\n",
    "\n",
    "if acc > best_acc:\n",
    "  best_model = model\n",
    "  best_acc = acc\n",
    "  best_hid = layer_size\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Test accuracy= {acc}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeP4uwfXA-GR",
    "outputId": "833b22b1-5667-49ff-bcf9-10b22249eab4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CoraFull\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.0050101280212402\n",
      "Epoch 20: loss=2.7719249725341797\n",
      "Epoch 30: loss=2.697040319442749\n",
      "Epoch 40: loss=2.6064095497131348\n",
      "Epoch 50: loss=2.5704777240753174\n",
      "Epoch 60: loss=2.5177576541900635\n",
      "Epoch 70: loss=2.527592182159424\n",
      "Epoch 80: loss=2.4969727993011475\n",
      "Epoch 90: loss=2.4947524070739746\n",
      "Epoch 100: loss=2.5098652839660645\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7018696311268318\n",
      "Test accuracy= 0.6994190452134378\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "num_heads = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Train and evaluate GAT with variable attention heads\n",
    "best_accuracy = 0.0\n",
    "best_num_heads = None\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "for num_head in num_heads:\n",
    "\n",
    "  # Define model\n",
    "  model = GATOneLayer(dataset.num_features, dataset.num_classes, num_heads=num_head)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  print(f\"Attention-heads: {num_head}\")\n",
    "  print(f\"...Training Start...\")\n",
    "\n",
    "  # Training\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset)\n",
    "      loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Printing Every 10 epochs\n",
    "      if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "        print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "  # Evaluation\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      logits = model(dataset)\n",
    "      _, predicted = logits.max(dim=1)\n",
    "      correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "      acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "  print(f\"...Training End...\")\n",
    "  print(f\"\\nValidation accuracy= {acc}\")\n",
    "  print(\"------------------------------------------\")\n",
    "\n",
    "  # Updateing best model\n",
    "  if best_model is None:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "  if acc > best_acc:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f'Best GATOneLayer with Variable Attention Heads({best_num_heads}) Test Accuracy : {acc}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xipCnKYqQfev",
    "outputId": "d44a8671-ef0d-4a61-e781-7b443f3226d5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention-heads: 1\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.0082855224609375\n",
      "Epoch 20: loss=2.7817721366882324\n",
      "Epoch 30: loss=2.672673225402832\n",
      "Epoch 40: loss=2.603245735168457\n",
      "Epoch 50: loss=2.576751947402954\n",
      "Epoch 60: loss=2.539975166320801\n",
      "Epoch 70: loss=2.5401976108551025\n",
      "Epoch 80: loss=2.509657382965088\n",
      "Epoch 90: loss=2.4693796634674072\n",
      "Epoch 100: loss=2.48476243019104\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6922688226376958\n",
      "------------------------------------------\n",
      "Attention-heads: 2\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.4880592823028564\n",
      "Epoch 20: loss=3.191213369369507\n",
      "Epoch 30: loss=3.0668141841888428\n",
      "Epoch 40: loss=3.008028745651245\n",
      "Epoch 50: loss=2.9755754470825195\n",
      "Epoch 60: loss=2.906764268875122\n",
      "Epoch 70: loss=2.899134635925293\n",
      "Epoch 80: loss=2.8656363487243652\n",
      "Epoch 90: loss=2.847696304321289\n",
      "Epoch 100: loss=2.8604745864868164\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7033855482566953\n",
      "------------------------------------------\n",
      "Attention-heads: 3\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.7957675457000732\n",
      "Epoch 20: loss=3.460641860961914\n",
      "Epoch 30: loss=3.3361265659332275\n",
      "Epoch 40: loss=3.2873618602752686\n",
      "Epoch 50: loss=3.201653480529785\n",
      "Epoch 60: loss=3.2033748626708984\n",
      "Epoch 70: loss=3.1885504722595215\n",
      "Epoch 80: loss=3.1173746585845947\n",
      "Epoch 90: loss=3.0913126468658447\n",
      "Epoch 100: loss=3.0768070220947266\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6988377968671046\n",
      "------------------------------------------\n",
      "Attention-heads: 4\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.9485561847686768\n",
      "Epoch 20: loss=3.6239590644836426\n",
      "Epoch 30: loss=3.4910624027252197\n",
      "Epoch 40: loss=3.436763048171997\n",
      "Epoch 50: loss=3.38328218460083\n",
      "Epoch 60: loss=3.3528666496276855\n",
      "Epoch 70: loss=3.2582805156707764\n",
      "Epoch 80: loss=3.285879611968994\n",
      "Epoch 90: loss=3.2224185466766357\n",
      "Epoch 100: loss=3.231947422027588\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6927741283476503\n",
      "------------------------------------------\n",
      "Attention-heads: 5\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.136570453643799\n",
      "Epoch 20: loss=3.8119313716888428\n",
      "Epoch 30: loss=3.675264358520508\n",
      "Epoch 40: loss=3.5603246688842773\n",
      "Epoch 50: loss=3.5190420150756836\n",
      "Epoch 60: loss=3.477907419204712\n",
      "Epoch 70: loss=3.40067458152771\n",
      "Epoch 80: loss=3.413917303085327\n",
      "Epoch 90: loss=3.346050977706909\n",
      "Epoch 100: loss=3.3365726470947266\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6958059626073775\n",
      "------------------------------------------\n",
      "Attention-heads: 6\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.252723693847656\n",
      "Epoch 20: loss=3.867908239364624\n",
      "Epoch 30: loss=3.7371978759765625\n",
      "Epoch 40: loss=3.6166985034942627\n",
      "Epoch 50: loss=3.6036386489868164\n",
      "Epoch 60: loss=3.523648738861084\n",
      "Epoch 70: loss=3.5240495204925537\n",
      "Epoch 80: loss=3.5145626068115234\n",
      "Epoch 90: loss=3.465183973312378\n",
      "Epoch 100: loss=3.5049755573272705\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6978271854471956\n",
      "------------------------------------------\n",
      "Attention-heads: 7\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.335760593414307\n",
      "Epoch 20: loss=3.9811859130859375\n",
      "Epoch 30: loss=3.8578941822052\n",
      "Epoch 40: loss=3.7629127502441406\n",
      "Epoch 50: loss=3.6898510456085205\n",
      "Epoch 60: loss=3.631002187728882\n",
      "Epoch 70: loss=3.5850915908813477\n",
      "Epoch 80: loss=3.5846898555755615\n",
      "Epoch 90: loss=3.552938461303711\n",
      "Epoch 100: loss=3.5308516025543213\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6993431025770591\n",
      "------------------------------------------\n",
      "Attention-heads: 8\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.4731879234313965\n",
      "Epoch 20: loss=4.055534362792969\n",
      "Epoch 30: loss=3.887359857559204\n",
      "Epoch 40: loss=3.8179080486297607\n",
      "Epoch 50: loss=3.7765209674835205\n",
      "Epoch 60: loss=3.7258408069610596\n",
      "Epoch 70: loss=3.6772334575653076\n",
      "Epoch 80: loss=3.6667098999023438\n",
      "Epoch 90: loss=3.6802730560302734\n",
      "Epoch 100: loss=3.583092451095581\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7008590197069227\n",
      "------------------------------------------\n",
      "Attention-heads: 9\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.583664417266846\n",
      "Epoch 20: loss=4.193665027618408\n",
      "Epoch 30: loss=4.030940055847168\n",
      "Epoch 40: loss=3.9504618644714355\n",
      "Epoch 50: loss=3.8780386447906494\n",
      "Epoch 60: loss=3.818296432495117\n",
      "Epoch 70: loss=3.777270793914795\n",
      "Epoch 80: loss=3.757460355758667\n",
      "Epoch 90: loss=3.728752374649048\n",
      "Epoch 100: loss=3.7018234729766846\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7018696311268318\n",
      "------------------------------------------\n",
      "Attention-heads: 10\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.630310535430908\n",
      "Epoch 20: loss=4.270742893218994\n",
      "Epoch 30: loss=4.096713066101074\n",
      "Epoch 40: loss=4.004220008850098\n",
      "Epoch 50: loss=3.8995537757873535\n",
      "Epoch 60: loss=3.869279146194458\n",
      "Epoch 70: loss=3.8325538635253906\n",
      "Epoch 80: loss=3.8040053844451904\n",
      "Epoch 90: loss=3.741048812866211\n",
      "Epoch 100: loss=3.7520570755004883\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6978271854471956\n",
      "------------------------------------------\n",
      "Best GATOneLayer with Variable Attention Heads(2) Test Accuracy : 0.7032078807779742\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **GATTwoLayer**"
   ],
   "metadata": {
    "id": "VUqjM4d_-O33",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the two-layer GAT model\n",
    "class GATTwoLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_heads=1):\n",
    "        super(GATTwoLayer, self).__init__()\n",
    "        self.conv1 = GATConv(input_size, hidden_size, heads=num_heads, dropout=0.6)\n",
    "        self.conv2 = GATConv(hidden_size * num_heads, output_size, heads=1, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # First graph attention layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # Second graph attention layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "metadata": {
    "id": "ulBtoazz-KiX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cite\n",
    "print('Dataset: CiteSeer')\n",
    "\n",
    "# Define training parameters\n",
    "layers_size = [8,16,32,64,128]\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Training Loop\n",
    "for layer_size in layers_size:\n",
    "\n",
    "    # Define model\n",
    "    model = GATTwoLayer(dataset.num_features, layer_size, dataset.num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Model with hidden size({layer_size}):\\n\")\n",
    "    print(f\"...Training Start...\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(dataset)\n",
    "        loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Printing Every 10 epochs\n",
    "        if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "          print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(dataset)\n",
    "        _, predicted = logits.max(dim=1)\n",
    "        correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "        acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "    print(f\"...Training End...\")\n",
    "    print(f\"\\nValidation accuracy= {acc}\")\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Updateing best model\n",
    "    if best_model is None:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid = layer_size\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid = layer_size\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Best model with hidden size({best_hid}): Test accuracy= {acc}\")"
   ],
   "metadata": {
    "id": "JBl-WdK7-R7O",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CiteSeer\n",
      "Model with hidden size(8):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.5718200206756592\n",
      "Epoch 20: loss=1.479872226715088\n",
      "Epoch 30: loss=1.4276626110076904\n",
      "Epoch 40: loss=1.532223105430603\n",
      "Epoch 50: loss=1.426151156425476\n",
      "Epoch 60: loss=1.4082568883895874\n",
      "Epoch 70: loss=1.4887439012527466\n",
      "Epoch 80: loss=1.339945912361145\n",
      "Epoch 90: loss=1.2117427587509155\n",
      "Epoch 100: loss=1.289684772491455\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.646\n",
      "------------------------------------------\n",
      "Model with hidden size(16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.555171251296997\n",
      "Epoch 20: loss=1.4747158288955688\n",
      "Epoch 30: loss=1.1940035820007324\n",
      "Epoch 40: loss=1.341963529586792\n",
      "Epoch 50: loss=1.2209889888763428\n",
      "Epoch 60: loss=1.2888282537460327\n",
      "Epoch 70: loss=1.2757395505905151\n",
      "Epoch 80: loss=1.2291855812072754\n",
      "Epoch 90: loss=1.2222059965133667\n",
      "Epoch 100: loss=1.244329810142517\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.678\n",
      "------------------------------------------\n",
      "Model with hidden size(32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.537047028541565\n",
      "Epoch 20: loss=1.2843009233474731\n",
      "Epoch 30: loss=1.1569819450378418\n",
      "Epoch 40: loss=1.3084406852722168\n",
      "Epoch 50: loss=1.2070611715316772\n",
      "Epoch 60: loss=1.1827996969223022\n",
      "Epoch 70: loss=1.2182881832122803\n",
      "Epoch 80: loss=1.0670524835586548\n",
      "Epoch 90: loss=1.235555648803711\n",
      "Epoch 100: loss=1.104714274406433\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.642\n",
      "------------------------------------------\n",
      "Model with hidden size(64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.2804681062698364\n",
      "Epoch 20: loss=1.3012583255767822\n",
      "Epoch 30: loss=1.1482093334197998\n",
      "Epoch 40: loss=1.277209758758545\n",
      "Epoch 50: loss=1.2115825414657593\n",
      "Epoch 60: loss=1.0838167667388916\n",
      "Epoch 70: loss=1.1961779594421387\n",
      "Epoch 80: loss=0.9883615970611572\n",
      "Epoch 90: loss=1.1587955951690674\n",
      "Epoch 100: loss=1.0891342163085938\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.648\n",
      "------------------------------------------\n",
      "Model with hidden size(128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.461812138557434\n",
      "Epoch 20: loss=1.3902186155319214\n",
      "Epoch 30: loss=1.116926908493042\n",
      "Epoch 40: loss=1.1902828216552734\n",
      "Epoch 50: loss=1.1986229419708252\n",
      "Epoch 60: loss=1.1306283473968506\n",
      "Epoch 70: loss=1.0543464422225952\n",
      "Epoch 80: loss=1.1143414974212646\n",
      "Epoch 90: loss=1.1375086307525635\n",
      "Epoch 100: loss=1.1126658916473389\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.652\n",
      "------------------------------------------\n",
      "Best model with hidden size(16): Test accuracy= 0.671\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "num_heads = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Train and evaluate GAT with variable attention heads\n",
    "best_accuracy = 0.0\n",
    "best_num_heads = None\n",
    "best_model = None\n",
    "best_acc = None\n",
    "\n",
    "for num_head in num_heads:\n",
    "\n",
    "  # Define model\n",
    "  model = GATTwoLayer(dataset.num_features, best_hid, dataset.num_classes, num_heads=num_head)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  print(f\"Attention-heads: {num_head}\")\n",
    "  print(f\"...Training Start...\")\n",
    "\n",
    "  # Training\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset)\n",
    "      loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Printing Every 10 epochs\n",
    "      if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "        print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "  # Evaluation\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      logits = model(dataset)\n",
    "      _, predicted = logits.max(dim=1)\n",
    "      correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "      acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "  print(f\"...Training End...\")\n",
    "  print(f\"\\nValidation accuracy= {acc}\")\n",
    "  print(\"------------------------------------------\")\n",
    "\n",
    "  # Updateing best model\n",
    "  if best_model is None:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "  if acc > best_acc:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f'Best GATTowLayer with Variable Attention Heads({best_num_heads}) Test Accuracy : {acc}')"
   ],
   "metadata": {
    "id": "ymnt7RBjQ6Pg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention-heads: 1\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.6684595346450806\n",
      "Epoch 20: loss=1.4612420797348022\n",
      "Epoch 30: loss=1.2364237308502197\n",
      "Epoch 40: loss=1.351349115371704\n",
      "Epoch 50: loss=1.2170580625534058\n",
      "Epoch 60: loss=1.3679684400558472\n",
      "Epoch 70: loss=1.2562278509140015\n",
      "Epoch 80: loss=1.2470791339874268\n",
      "Epoch 90: loss=1.3140788078308105\n",
      "Epoch 100: loss=1.2524895668029785\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.646\n",
      "------------------------------------------\n",
      "Attention-heads: 2\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.4192824363708496\n",
      "Epoch 20: loss=1.2832330465316772\n",
      "Epoch 30: loss=1.3397940397262573\n",
      "Epoch 40: loss=1.1280068159103394\n",
      "Epoch 50: loss=0.9699046015739441\n",
      "Epoch 60: loss=1.1388609409332275\n",
      "Epoch 70: loss=1.1568490266799927\n",
      "Epoch 80: loss=0.981903612613678\n",
      "Epoch 90: loss=1.0848554372787476\n",
      "Epoch 100: loss=1.1018767356872559\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.676\n",
      "------------------------------------------\n",
      "Attention-heads: 3\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.2205281257629395\n",
      "Epoch 20: loss=1.1532310247421265\n",
      "Epoch 30: loss=1.1274769306182861\n",
      "Epoch 40: loss=1.0738362073898315\n",
      "Epoch 50: loss=1.0837769508361816\n",
      "Epoch 60: loss=1.219218373298645\n",
      "Epoch 70: loss=1.0768238306045532\n",
      "Epoch 80: loss=1.0180854797363281\n",
      "Epoch 90: loss=0.9365115761756897\n",
      "Epoch 100: loss=1.1077666282653809\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.672\n",
      "------------------------------------------\n",
      "Attention-heads: 4\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.2871631383895874\n",
      "Epoch 20: loss=1.1059211492538452\n",
      "Epoch 30: loss=1.2152999639511108\n",
      "Epoch 40: loss=1.0529969930648804\n",
      "Epoch 50: loss=1.103880763053894\n",
      "Epoch 60: loss=1.085371494293213\n",
      "Epoch 70: loss=1.0477889776229858\n",
      "Epoch 80: loss=1.0216206312179565\n",
      "Epoch 90: loss=0.9623817801475525\n",
      "Epoch 100: loss=1.0319067239761353\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.624\n",
      "------------------------------------------\n",
      "Attention-heads: 5\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.1937038898468018\n",
      "Epoch 20: loss=1.1014904975891113\n",
      "Epoch 30: loss=0.9471538662910461\n",
      "Epoch 40: loss=0.9489316344261169\n",
      "Epoch 50: loss=1.2095272541046143\n",
      "Epoch 60: loss=1.034122109413147\n",
      "Epoch 70: loss=0.9968856573104858\n",
      "Epoch 80: loss=1.079671025276184\n",
      "Epoch 90: loss=1.012790322303772\n",
      "Epoch 100: loss=1.011364221572876\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.662\n",
      "------------------------------------------\n",
      "Attention-heads: 6\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.2271978855133057\n",
      "Epoch 20: loss=1.3283976316452026\n",
      "Epoch 30: loss=1.151387333869934\n",
      "Epoch 40: loss=0.9736589789390564\n",
      "Epoch 50: loss=1.0236504077911377\n",
      "Epoch 60: loss=1.0504130125045776\n",
      "Epoch 70: loss=0.9313839077949524\n",
      "Epoch 80: loss=0.9603134989738464\n",
      "Epoch 90: loss=1.024213194847107\n",
      "Epoch 100: loss=0.9574868679046631\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.65\n",
      "------------------------------------------\n",
      "Attention-heads: 7\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.1702712774276733\n",
      "Epoch 20: loss=1.2011123895645142\n",
      "Epoch 30: loss=1.168370008468628\n",
      "Epoch 40: loss=1.1266151666641235\n",
      "Epoch 50: loss=0.9995632767677307\n",
      "Epoch 60: loss=0.963416337966919\n",
      "Epoch 70: loss=1.0282624959945679\n",
      "Epoch 80: loss=0.8626108765602112\n",
      "Epoch 90: loss=0.9733215570449829\n",
      "Epoch 100: loss=0.971532940864563\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.664\n",
      "------------------------------------------\n",
      "Attention-heads: 8\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.222712755203247\n",
      "Epoch 20: loss=1.2023721933364868\n",
      "Epoch 30: loss=1.0125232934951782\n",
      "Epoch 40: loss=1.0118703842163086\n",
      "Epoch 50: loss=1.2838025093078613\n",
      "Epoch 60: loss=0.8650568127632141\n",
      "Epoch 70: loss=1.0738812685012817\n",
      "Epoch 80: loss=1.06116783618927\n",
      "Epoch 90: loss=0.990993082523346\n",
      "Epoch 100: loss=1.0136171579360962\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.642\n",
      "------------------------------------------\n",
      "Attention-heads: 9\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.223270058631897\n",
      "Epoch 20: loss=1.1660248041152954\n",
      "Epoch 30: loss=1.1848853826522827\n",
      "Epoch 40: loss=1.0557936429977417\n",
      "Epoch 50: loss=1.0020698308944702\n",
      "Epoch 60: loss=1.088923692703247\n",
      "Epoch 70: loss=1.038100004196167\n",
      "Epoch 80: loss=1.0378329753875732\n",
      "Epoch 90: loss=1.1093885898590088\n",
      "Epoch 100: loss=0.9907036423683167\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.658\n",
      "------------------------------------------\n",
      "Attention-heads: 10\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.2490360736846924\n",
      "Epoch 20: loss=1.0586633682250977\n",
      "Epoch 30: loss=0.9696188569068909\n",
      "Epoch 40: loss=1.036253571510315\n",
      "Epoch 50: loss=1.0786643028259277\n",
      "Epoch 60: loss=1.1967296600341797\n",
      "Epoch 70: loss=0.9861614108085632\n",
      "Epoch 80: loss=1.0553820133209229\n",
      "Epoch 90: loss=1.031620979309082\n",
      "Epoch 100: loss=0.8115106821060181\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.662\n",
      "------------------------------------------\n",
      "Best GATTowLayer with Variable Attention Heads(2) Test Accuracy : 0.68\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cora\n",
    "print('Dataset: CoraFull')\n",
    "\n",
    "# Define training parameters\n",
    "layers_size = [8,16,32,64,128]\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Training Loop\n",
    "for layer_size in layers_size:\n",
    "\n",
    "    # Define model\n",
    "    model = GATTwoLayer(dataset.num_features, layer_size, dataset.num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Model with hidden size({layer_size}):\\n\")\n",
    "    print(f\"...Training Start...\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(dataset)\n",
    "        loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Printing Every 10 epochs\n",
    "        if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "          print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(dataset)\n",
    "        _, predicted = logits.max(dim=1)\n",
    "        correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "        acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "    print(f\"...Training End...\")\n",
    "    print(f\"\\nValidation accuracy= {acc}\")\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Updateing best model\n",
    "    if best_model is None:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid = layer_size\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid = layer_size\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Best model with hidden size({best_hid}): Test accuracy= {acc}\")"
   ],
   "metadata": {
    "id": "aSZLmBTABGeB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CoraFull\n",
      "Model with hidden size(8):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.915342330932617\n",
      "Epoch 20: loss=3.754348039627075\n",
      "Epoch 30: loss=3.6859259605407715\n",
      "Epoch 40: loss=3.646625518798828\n",
      "Epoch 50: loss=3.6059815883636475\n",
      "Epoch 60: loss=3.5974695682525635\n",
      "Epoch 70: loss=3.572605609893799\n",
      "Epoch 80: loss=3.5378501415252686\n",
      "Epoch 90: loss=3.5125198364257812\n",
      "Epoch 100: loss=3.5273988246917725\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.5932289034866094\n",
      "------------------------------------------\n",
      "Model with hidden size(16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.7546627521514893\n",
      "Epoch 20: loss=3.595989465713501\n",
      "Epoch 30: loss=3.4730114936828613\n",
      "Epoch 40: loss=3.3767857551574707\n",
      "Epoch 50: loss=3.335536003112793\n",
      "Epoch 60: loss=3.3043675422668457\n",
      "Epoch 70: loss=3.289062261581421\n",
      "Epoch 80: loss=3.2340149879455566\n",
      "Epoch 90: loss=3.2455813884735107\n",
      "Epoch 100: loss=3.209557294845581\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.686710459828196\n",
      "------------------------------------------\n",
      "Model with hidden size(32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.5274908542633057\n",
      "Epoch 20: loss=3.326538324356079\n",
      "Epoch 30: loss=3.231546640396118\n",
      "Epoch 40: loss=3.131345748901367\n",
      "Epoch 50: loss=3.105700731277466\n",
      "Epoch 60: loss=3.0856027603149414\n",
      "Epoch 70: loss=3.0471465587615967\n",
      "Epoch 80: loss=3.0177717208862305\n",
      "Epoch 90: loss=3.0545706748962402\n",
      "Epoch 100: loss=3.012517213821411\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7064173825164224\n",
      "------------------------------------------\n",
      "Model with hidden size(64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.3165125846862793\n",
      "Epoch 20: loss=3.140331983566284\n",
      "Epoch 30: loss=3.0105538368225098\n",
      "Epoch 40: loss=3.0164098739624023\n",
      "Epoch 50: loss=2.961749792098999\n",
      "Epoch 60: loss=2.948072671890259\n",
      "Epoch 70: loss=2.916465997695923\n",
      "Epoch 80: loss=2.90936017036438\n",
      "Epoch 90: loss=2.922529458999634\n",
      "Epoch 100: loss=2.8873541355133057\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7008590197069227\n",
      "------------------------------------------\n",
      "Model with hidden size(128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.220066547393799\n",
      "Epoch 20: loss=3.0729024410247803\n",
      "Epoch 30: loss=3.000343084335327\n",
      "Epoch 40: loss=2.926340103149414\n",
      "Epoch 50: loss=2.9161911010742188\n",
      "Epoch 60: loss=2.89066219329834\n",
      "Epoch 70: loss=2.855684518814087\n",
      "Epoch 80: loss=2.868631362915039\n",
      "Epoch 90: loss=2.847693681716919\n",
      "Epoch 100: loss=2.861456871032715\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7043961596766043\n",
      "------------------------------------------\n",
      "Best model with hidden size(32): Test accuracy= 0.7019449355897954\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "num_heads = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Train and evaluate GAT with variable attention heads\n",
    "best_accuracy = 0.0\n",
    "best_num_heads = None\n",
    "best_model = None\n",
    "best_acc = None\n",
    "\n",
    "for num_head in num_heads:\n",
    "\n",
    "  # Define model\n",
    "  model = GATTwoLayer(dataset.num_features, best_hid, dataset.num_classes, num_heads=num_head)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  print(f\"Attention-heads: {num_head}\")\n",
    "  print(f\"...Training Start...\")\n",
    "\n",
    "  # Training\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset)\n",
    "      loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Printing Every 10 epochs\n",
    "      if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "        print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "  # Evaluation\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      logits = model(dataset)\n",
    "      _, predicted = logits.max(dim=1)\n",
    "      correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "      acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "  print(f\"...Training End...\")\n",
    "  print(f\"\\nValidation accuracy= {acc}\")\n",
    "  print(\"------------------------------------------\")\n",
    "\n",
    "  # Updateing best model\n",
    "  if best_model is None:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "  if acc > best_acc:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f'Best GATTowLayer with Variable Attention Heads({best_num_heads}) Test Accuracy : {acc}')"
   ],
   "metadata": {
    "id": "y1f20XicR7r1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention-heads: 1\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.5409531593322754\n",
      "Epoch 20: loss=3.2976059913635254\n",
      "Epoch 30: loss=3.1866261959075928\n",
      "Epoch 40: loss=3.136183261871338\n",
      "Epoch 50: loss=3.1057233810424805\n",
      "Epoch 60: loss=3.048611640930176\n",
      "Epoch 70: loss=3.042970895767212\n",
      "Epoch 80: loss=3.034773111343384\n",
      "Epoch 90: loss=2.991997003555298\n",
      "Epoch 100: loss=3.01548433303833\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6998484082870137\n",
      "------------------------------------------\n",
      "Attention-heads: 2\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.4008564949035645\n",
      "Epoch 20: loss=3.1386685371398926\n",
      "Epoch 30: loss=3.0418198108673096\n",
      "Epoch 40: loss=2.9628145694732666\n",
      "Epoch 50: loss=2.9577221870422363\n",
      "Epoch 60: loss=2.9288175106048584\n",
      "Epoch 70: loss=2.8705670833587646\n",
      "Epoch 80: loss=2.9003748893737793\n",
      "Epoch 90: loss=2.853228807449341\n",
      "Epoch 100: loss=2.8566524982452393\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7109651339060131\n",
      "------------------------------------------\n",
      "Attention-heads: 3\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.2722058296203613\n",
      "Epoch 20: loss=3.0347139835357666\n",
      "Epoch 30: loss=2.9739272594451904\n",
      "Epoch 40: loss=2.896315336227417\n",
      "Epoch 50: loss=2.8701767921447754\n",
      "Epoch 60: loss=2.8378794193267822\n",
      "Epoch 70: loss=2.8383095264434814\n",
      "Epoch 80: loss=2.8064777851104736\n",
      "Epoch 90: loss=2.7906007766723633\n",
      "Epoch 100: loss=2.7849173545837402\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7134916624557858\n",
      "------------------------------------------\n",
      "Attention-heads: 4\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.2386813163757324\n",
      "Epoch 20: loss=3.010822296142578\n",
      "Epoch 30: loss=2.9281466007232666\n",
      "Epoch 40: loss=2.855581283569336\n",
      "Epoch 50: loss=2.8377416133880615\n",
      "Epoch 60: loss=2.7869138717651367\n",
      "Epoch 70: loss=2.769444704055786\n",
      "Epoch 80: loss=2.786329984664917\n",
      "Epoch 90: loss=2.762716770172119\n",
      "Epoch 100: loss=2.7390873432159424\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7119757453259222\n",
      "------------------------------------------\n",
      "Attention-heads: 5\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.118443250656128\n",
      "Epoch 20: loss=2.942640781402588\n",
      "Epoch 30: loss=2.855036497116089\n",
      "Epoch 40: loss=2.7884931564331055\n",
      "Epoch 50: loss=2.7693288326263428\n",
      "Epoch 60: loss=2.739440679550171\n",
      "Epoch 70: loss=2.749422550201416\n",
      "Epoch 80: loss=2.7412993907928467\n",
      "Epoch 90: loss=2.681615114212036\n",
      "Epoch 100: loss=2.7051239013671875\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.707933299646286\n",
      "------------------------------------------\n",
      "Attention-heads: 6\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.1683671474456787\n",
      "Epoch 20: loss=2.96494460105896\n",
      "Epoch 30: loss=2.86139178276062\n",
      "Epoch 40: loss=2.7899954319000244\n",
      "Epoch 50: loss=2.7593164443969727\n",
      "Epoch 60: loss=2.7641024589538574\n",
      "Epoch 70: loss=2.75075101852417\n",
      "Epoch 80: loss=2.709784746170044\n",
      "Epoch 90: loss=2.6979897022247314\n",
      "Epoch 100: loss=2.695499897003174\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7049014653865588\n",
      "------------------------------------------\n",
      "Attention-heads: 7\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.2788074016571045\n",
      "Epoch 20: loss=2.9945456981658936\n",
      "Epoch 30: loss=2.9075284004211426\n",
      "Epoch 40: loss=2.8409931659698486\n",
      "Epoch 50: loss=2.779944896697998\n",
      "Epoch 60: loss=2.7765052318573\n",
      "Epoch 70: loss=2.7432360649108887\n",
      "Epoch 80: loss=2.7219772338867188\n",
      "Epoch 90: loss=2.696230888366699\n",
      "Epoch 100: loss=2.6825308799743652\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7084386053562405\n",
      "------------------------------------------\n",
      "Attention-heads: 8\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.2570202350616455\n",
      "Epoch 20: loss=2.9734978675842285\n",
      "Epoch 30: loss=2.883180618286133\n",
      "Epoch 40: loss=2.8377580642700195\n",
      "Epoch 50: loss=2.783755302429199\n",
      "Epoch 60: loss=2.7711055278778076\n",
      "Epoch 70: loss=2.69742488861084\n",
      "Epoch 80: loss=2.715566873550415\n",
      "Epoch 90: loss=2.693289041519165\n",
      "Epoch 100: loss=2.6936264038085938\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.707933299646286\n",
      "------------------------------------------\n",
      "Attention-heads: 9\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.3191606998443604\n",
      "Epoch 20: loss=2.998932123184204\n",
      "Epoch 30: loss=2.889662504196167\n",
      "Epoch 40: loss=2.7905821800231934\n",
      "Epoch 50: loss=2.7792108058929443\n",
      "Epoch 60: loss=2.7369513511657715\n",
      "Epoch 70: loss=2.6969494819641113\n",
      "Epoch 80: loss=2.6825144290924072\n",
      "Epoch 90: loss=2.668733835220337\n",
      "Epoch 100: loss=2.6708743572235107\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7023749368367862\n",
      "------------------------------------------\n",
      "Attention-heads: 10\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.1842706203460693\n",
      "Epoch 20: loss=2.937044620513916\n",
      "Epoch 30: loss=2.8665013313293457\n",
      "Epoch 40: loss=2.7746288776397705\n",
      "Epoch 50: loss=2.7414753437042236\n",
      "Epoch 60: loss=2.7182767391204834\n",
      "Epoch 70: loss=2.697597026824951\n",
      "Epoch 80: loss=2.688755512237549\n",
      "Epoch 90: loss=2.6575803756713867\n",
      "Epoch 100: loss=2.6872828006744385\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7018696311268318\n",
      "------------------------------------------\n",
      "Best GATTowLayer with Variable Attention Heads(3) Test Accuracy : 0.7087648396059611\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **GATThreeLayer**"
   ],
   "metadata": {
    "id": "tzR0x4iy-UnG",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the three-layer GAT model\n",
    "class GATThreeLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, num_heads=1):\n",
    "        super(GATThreeLayer, self).__init__()\n",
    "        self.conv1 = GATConv(input_size, hidden_size1, heads=num_heads, dropout=0.6)\n",
    "        self.conv2 = GATConv(hidden_size1 * num_heads, hidden_size2, heads=num_heads, dropout=0.6)\n",
    "        self.conv3 = GATConv(hidden_size2 * num_heads, output_size, heads=1, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # First graph attention layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # Second graph attention layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # Third graph attention layer\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "metadata": {
    "id": "C_MD_qvi-Sct",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cite\n",
    "print('Dataset: CiteSeer')\n",
    "\n",
    "# Define training parameters\n",
    "layers_size =filtered_list\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Training Loop\n",
    "for layer_size in layers_size:\n",
    "\n",
    "    # Define model\n",
    "    model = GATThreeLayer(dataset.num_features, layer_size[0], layer_size[1], dataset.num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Model with hidden size({layer_size[0]}, {layer_size[1]}):\\n\")\n",
    "    print(f\"...Training Start...\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(dataset)\n",
    "        loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Printing Every 10 epochs\n",
    "        if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "          print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(dataset)\n",
    "        _, predicted = logits.max(dim=1)\n",
    "        correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "        acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "    print(f\"...Training End...\")\n",
    "    print(f\"\\nValidation accuracy= {acc}\")\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Updateing best model\n",
    "    if best_model is None:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Best model with hidden size({best_hid1},{best_hid2}): Test accuracy= {acc}\")"
   ],
   "metadata": {
    "id": "Tl4TUr1fuiIL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CiteSeer\n",
      "Model with hidden size(128, 128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.3951327800750732\n",
      "Epoch 20: loss=1.410884141921997\n",
      "Epoch 30: loss=1.3862671852111816\n",
      "Epoch 40: loss=1.3144508600234985\n",
      "Epoch 50: loss=1.4712871313095093\n",
      "Epoch 60: loss=1.3808138370513916\n",
      "Epoch 70: loss=1.3672524690628052\n",
      "Epoch 80: loss=1.3222087621688843\n",
      "Epoch 90: loss=1.2961663007736206\n",
      "Epoch 100: loss=1.3711612224578857\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.624\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.8126912117004395\n",
      "Epoch 20: loss=1.617910385131836\n",
      "Epoch 30: loss=1.3287931680679321\n",
      "Epoch 40: loss=1.5827052593231201\n",
      "Epoch 50: loss=1.4415823221206665\n",
      "Epoch 60: loss=1.4202665090560913\n",
      "Epoch 70: loss=1.5208618640899658\n",
      "Epoch 80: loss=1.296335220336914\n",
      "Epoch 90: loss=1.3805757761001587\n",
      "Epoch 100: loss=1.3901206254959106\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.638\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.6262532472610474\n",
      "Epoch 20: loss=1.7324846982955933\n",
      "Epoch 30: loss=1.3822283744812012\n",
      "Epoch 40: loss=1.5332387685775757\n",
      "Epoch 50: loss=1.5764660835266113\n",
      "Epoch 60: loss=1.6998909711837769\n",
      "Epoch 70: loss=1.79948091506958\n",
      "Epoch 80: loss=1.493222951889038\n",
      "Epoch 90: loss=1.5517221689224243\n",
      "Epoch 100: loss=1.4201687574386597\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.648\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.159693717956543\n",
      "Epoch 20: loss=2.3321993350982666\n",
      "Epoch 30: loss=2.0602786540985107\n",
      "Epoch 40: loss=1.8741647005081177\n",
      "Epoch 50: loss=1.7260628938674927\n",
      "Epoch 60: loss=1.973323941230774\n",
      "Epoch 70: loss=1.7744191884994507\n",
      "Epoch 80: loss=1.5551897287368774\n",
      "Epoch 90: loss=1.5850403308868408\n",
      "Epoch 100: loss=1.6062794923782349\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.67\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.7275861501693726\n",
      "Epoch 20: loss=1.4971725940704346\n",
      "Epoch 30: loss=1.456966757774353\n",
      "Epoch 40: loss=1.321468710899353\n",
      "Epoch 50: loss=1.371002435684204\n",
      "Epoch 60: loss=1.2246195077896118\n",
      "Epoch 70: loss=1.3735318183898926\n",
      "Epoch 80: loss=1.3940995931625366\n",
      "Epoch 90: loss=1.5673822164535522\n",
      "Epoch 100: loss=1.2500622272491455\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.636\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.910409688949585\n",
      "Epoch 20: loss=1.6009538173675537\n",
      "Epoch 30: loss=1.9382405281066895\n",
      "Epoch 40: loss=1.4695512056350708\n",
      "Epoch 50: loss=1.4288527965545654\n",
      "Epoch 60: loss=1.5922653675079346\n",
      "Epoch 70: loss=1.42132568359375\n",
      "Epoch 80: loss=1.54880690574646\n",
      "Epoch 90: loss=1.3473281860351562\n",
      "Epoch 100: loss=1.473816990852356\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.628\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.5903221368789673\n",
      "Epoch 20: loss=1.7285033464431763\n",
      "Epoch 30: loss=1.678350567817688\n",
      "Epoch 40: loss=1.4657416343688965\n",
      "Epoch 50: loss=1.4370574951171875\n",
      "Epoch 60: loss=1.5059250593185425\n",
      "Epoch 70: loss=1.443551778793335\n",
      "Epoch 80: loss=1.3474217653274536\n",
      "Epoch 90: loss=1.3835182189941406\n",
      "Epoch 100: loss=1.330969214439392\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.636\n",
      "------------------------------------------\n",
      "Model with hidden size(32, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.6374319791793823\n",
      "Epoch 20: loss=1.7166287899017334\n",
      "Epoch 30: loss=1.4828790426254272\n",
      "Epoch 40: loss=1.457866907119751\n",
      "Epoch 50: loss=1.3717542886734009\n",
      "Epoch 60: loss=1.4365373849868774\n",
      "Epoch 70: loss=1.6749138832092285\n",
      "Epoch 80: loss=1.5495792627334595\n",
      "Epoch 90: loss=1.4495398998260498\n",
      "Epoch 100: loss=1.3622206449508667\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.63\n",
      "------------------------------------------\n",
      "Model with hidden size(32, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.915006399154663\n",
      "Epoch 20: loss=1.511670470237732\n",
      "Epoch 30: loss=2.113632917404175\n",
      "Epoch 40: loss=1.8807551860809326\n",
      "Epoch 50: loss=1.647214651107788\n",
      "Epoch 60: loss=1.6986809968948364\n",
      "Epoch 70: loss=1.5683695077896118\n",
      "Epoch 80: loss=1.4758282899856567\n",
      "Epoch 90: loss=1.4685332775115967\n",
      "Epoch 100: loss=1.638988971710205\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.672\n",
      "------------------------------------------\n",
      "Model with hidden size(16, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.7291399240493774\n",
      "Epoch 20: loss=1.6580684185028076\n",
      "Epoch 30: loss=1.6500996351242065\n",
      "Epoch 40: loss=1.7454930543899536\n",
      "Epoch 50: loss=1.5914483070373535\n",
      "Epoch 60: loss=1.5031126737594604\n",
      "Epoch 70: loss=1.6474119424819946\n",
      "Epoch 80: loss=1.5997508764266968\n",
      "Epoch 90: loss=1.5526249408721924\n",
      "Epoch 100: loss=1.5444029569625854\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.662\n",
      "------------------------------------------\n",
      "Best model with hidden size(32,16): Test accuracy= 0.661\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "num_heads = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Train and evaluate GAT with variable attention heads\n",
    "best_accuracy = 0.0\n",
    "best_num_heads = None\n",
    "best_model = None\n",
    "best_acc = None\n",
    "\n",
    "for num_head in num_heads:\n",
    "\n",
    "  # Define model\n",
    "  model = GATThreeLayer(dataset.num_features, best_hid1, best_hid2, dataset.num_classes, num_heads=num_head)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  print(f\"Attention-heads: {num_head}\")\n",
    "  print(f\"...Training Start...\")\n",
    "\n",
    "  # Training\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset)\n",
    "      loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Printing Every 10 epochs\n",
    "      if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "        print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "  # Evaluation\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      logits = model(dataset)\n",
    "      _, predicted = logits.max(dim=1)\n",
    "      correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "      acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "  print(f\"...Training End...\")\n",
    "  print(f\"\\nValidation accuracy= {acc}\")\n",
    "  print(\"------------------------------------------\")\n",
    "\n",
    "  # Updateing best model\n",
    "  if best_model is None:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "  if acc > best_acc:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f'Best GATThreeLayer with Variable Attention Heads({best_num_heads}) Test Accuracy : {acc}')"
   ],
   "metadata": {
    "id": "p1B9pq2DUOX8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention-heads: 1\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.69367253780365\n",
      "Epoch 20: loss=1.5853080749511719\n",
      "Epoch 30: loss=1.6584281921386719\n",
      "Epoch 40: loss=1.5028356313705444\n",
      "Epoch 50: loss=1.5223251581192017\n",
      "Epoch 60: loss=1.3478503227233887\n",
      "Epoch 70: loss=1.6328409910202026\n",
      "Epoch 80: loss=1.4328073263168335\n",
      "Epoch 90: loss=1.385282278060913\n",
      "Epoch 100: loss=1.5078105926513672\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.618\n",
      "------------------------------------------\n",
      "Attention-heads: 2\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.8353538513183594\n",
      "Epoch 20: loss=1.6683955192565918\n",
      "Epoch 30: loss=1.6289825439453125\n",
      "Epoch 40: loss=1.492751955986023\n",
      "Epoch 50: loss=1.6062244176864624\n",
      "Epoch 60: loss=1.3153635263442993\n",
      "Epoch 70: loss=1.2432379722595215\n",
      "Epoch 80: loss=1.3916147947311401\n",
      "Epoch 90: loss=1.359439730644226\n",
      "Epoch 100: loss=1.1272543668746948\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.666\n",
      "------------------------------------------\n",
      "Attention-heads: 3\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.72133469581604\n",
      "Epoch 20: loss=1.4552878141403198\n",
      "Epoch 30: loss=1.6616257429122925\n",
      "Epoch 40: loss=1.6067196130752563\n",
      "Epoch 50: loss=1.412674069404602\n",
      "Epoch 60: loss=1.4450643062591553\n",
      "Epoch 70: loss=1.4187809228897095\n",
      "Epoch 80: loss=1.3844774961471558\n",
      "Epoch 90: loss=1.3902428150177002\n",
      "Epoch 100: loss=1.101531744003296\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.668\n",
      "------------------------------------------\n",
      "Attention-heads: 4\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.5021954774856567\n",
      "Epoch 20: loss=1.4848085641860962\n",
      "Epoch 30: loss=1.9467670917510986\n",
      "Epoch 40: loss=1.3527661561965942\n",
      "Epoch 50: loss=1.4812548160552979\n",
      "Epoch 60: loss=1.5078322887420654\n",
      "Epoch 70: loss=1.0948758125305176\n",
      "Epoch 80: loss=1.3269438743591309\n",
      "Epoch 90: loss=1.009369134902954\n",
      "Epoch 100: loss=1.224838376045227\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.654\n",
      "------------------------------------------\n",
      "Attention-heads: 5\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.7028239965438843\n",
      "Epoch 20: loss=1.7521030902862549\n",
      "Epoch 30: loss=1.5187220573425293\n",
      "Epoch 40: loss=1.7876110076904297\n",
      "Epoch 50: loss=1.6527824401855469\n",
      "Epoch 60: loss=1.618461012840271\n",
      "Epoch 70: loss=1.4570380449295044\n",
      "Epoch 80: loss=1.6289193630218506\n",
      "Epoch 90: loss=1.8226007223129272\n",
      "Epoch 100: loss=1.4063034057617188\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.604\n",
      "------------------------------------------\n",
      "Attention-heads: 6\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.5489294528961182\n",
      "Epoch 20: loss=1.5944243669509888\n",
      "Epoch 30: loss=1.5050127506256104\n",
      "Epoch 40: loss=1.6891942024230957\n",
      "Epoch 50: loss=1.4211571216583252\n",
      "Epoch 60: loss=1.4739693403244019\n",
      "Epoch 70: loss=1.4896204471588135\n",
      "Epoch 80: loss=1.528567910194397\n",
      "Epoch 90: loss=1.657901644706726\n",
      "Epoch 100: loss=1.2416834831237793\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.628\n",
      "------------------------------------------\n",
      "Attention-heads: 7\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.7956820726394653\n",
      "Epoch 20: loss=1.4858698844909668\n",
      "Epoch 30: loss=1.2023179531097412\n",
      "Epoch 40: loss=1.4065660238265991\n",
      "Epoch 50: loss=1.41929292678833\n",
      "Epoch 60: loss=1.7688004970550537\n",
      "Epoch 70: loss=1.861261010169983\n",
      "Epoch 80: loss=1.7482022047042847\n",
      "Epoch 90: loss=1.3048280477523804\n",
      "Epoch 100: loss=1.3959821462631226\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.598\n",
      "------------------------------------------\n",
      "Attention-heads: 8\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.5835691690444946\n",
      "Epoch 20: loss=1.4428211450576782\n",
      "Epoch 30: loss=1.4429469108581543\n",
      "Epoch 40: loss=1.7160159349441528\n",
      "Epoch 50: loss=1.4020150899887085\n",
      "Epoch 60: loss=1.4219928979873657\n",
      "Epoch 70: loss=1.3567814826965332\n",
      "Epoch 80: loss=1.1918489933013916\n",
      "Epoch 90: loss=1.2200180292129517\n",
      "Epoch 100: loss=1.4038689136505127\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.626\n",
      "------------------------------------------\n",
      "Attention-heads: 9\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.5683891773223877\n",
      "Epoch 20: loss=1.368309497833252\n",
      "Epoch 30: loss=2.3121347427368164\n",
      "Epoch 40: loss=1.5615769624710083\n",
      "Epoch 50: loss=1.4353159666061401\n",
      "Epoch 60: loss=1.5455104112625122\n",
      "Epoch 70: loss=1.5713306665420532\n",
      "Epoch 80: loss=1.5941557884216309\n",
      "Epoch 90: loss=1.3254859447479248\n",
      "Epoch 100: loss=1.5777533054351807\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.644\n",
      "------------------------------------------\n",
      "Attention-heads: 10\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.542140245437622\n",
      "Epoch 20: loss=1.6003104448318481\n",
      "Epoch 30: loss=2.2428438663482666\n",
      "Epoch 40: loss=1.5798770189285278\n",
      "Epoch 50: loss=1.676876425743103\n",
      "Epoch 60: loss=1.812177300453186\n",
      "Epoch 70: loss=1.7303606271743774\n",
      "Epoch 80: loss=1.5451157093048096\n",
      "Epoch 90: loss=1.608940601348877\n",
      "Epoch 100: loss=1.369334101676941\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.594\n",
      "------------------------------------------\n",
      "Best GATThreeLayer with Variable Attention Heads(3) Test Accuracy : 0.665\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cora\n",
    "print('Dataset: CoraFull')\n",
    "\n",
    "# Define training parameters\n",
    "layers_size =filtered_list\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Training Loop\n",
    "for layer_size in layers_size:\n",
    "\n",
    "    # Define model\n",
    "    model = GATThreeLayer(dataset.num_features, layer_size[0], layer_size[1], dataset.num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Model with hidden size({layer_size[0]}, {layer_size[1]}):\\n\")\n",
    "    print(f\"...Training Start...\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(dataset)\n",
    "        loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Printing Every 10 epochs\n",
    "        if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "          print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(dataset)\n",
    "        _, predicted = logits.max(dim=1)\n",
    "        correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "        acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "    print(f\"...Training End...\")\n",
    "    print(f\"\\nValidation accuracy= {acc}\")\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Updateing best model\n",
    "    if best_model is None:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Best model with hidden size({best_hid1},{best_hid2}): Test accuracy= {acc}\")"
   ],
   "metadata": {
    "id": "iXE4p08YBMR6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CoraFull\n",
      "Model with hidden size(128, 128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.728876829147339\n",
      "Epoch 20: loss=3.4192488193511963\n",
      "Epoch 30: loss=3.273137331008911\n",
      "Epoch 40: loss=3.20591139793396\n",
      "Epoch 50: loss=3.1457338333129883\n",
      "Epoch 60: loss=3.1220157146453857\n",
      "Epoch 70: loss=3.0840656757354736\n",
      "Epoch 80: loss=3.046586275100708\n",
      "Epoch 90: loss=3.074793815612793\n",
      "Epoch 100: loss=3.0313637256622314\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6988377968671046\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.5644474029541016\n",
      "Epoch 20: loss=3.335432529449463\n",
      "Epoch 30: loss=3.2430832386016846\n",
      "Epoch 40: loss=3.173731565475464\n",
      "Epoch 50: loss=3.1355884075164795\n",
      "Epoch 60: loss=3.110306739807129\n",
      "Epoch 70: loss=3.086054563522339\n",
      "Epoch 80: loss=3.0827417373657227\n",
      "Epoch 90: loss=3.079172134399414\n",
      "Epoch 100: loss=3.0337941646575928\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7104598281960586\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.734189987182617\n",
      "Epoch 20: loss=3.527576446533203\n",
      "Epoch 30: loss=3.405496597290039\n",
      "Epoch 40: loss=3.341618537902832\n",
      "Epoch 50: loss=3.2546536922454834\n",
      "Epoch 60: loss=3.218839406967163\n",
      "Epoch 70: loss=3.223080635070801\n",
      "Epoch 80: loss=3.1837358474731445\n",
      "Epoch 90: loss=3.1971347332000732\n",
      "Epoch 100: loss=3.1578593254089355\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6922688226376958\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.020728588104248\n",
      "Epoch 20: loss=3.8047711849212646\n",
      "Epoch 30: loss=3.6849780082702637\n",
      "Epoch 40: loss=3.597259521484375\n",
      "Epoch 50: loss=3.550032138824463\n",
      "Epoch 60: loss=3.499345064163208\n",
      "Epoch 70: loss=3.463376998901367\n",
      "Epoch 80: loss=3.4282963275909424\n",
      "Epoch 90: loss=3.393953561782837\n",
      "Epoch 100: loss=3.3523733615875244\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6553815058110156\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.675346851348877\n",
      "Epoch 20: loss=3.4270756244659424\n",
      "Epoch 30: loss=3.288790464401245\n",
      "Epoch 40: loss=3.247136116027832\n",
      "Epoch 50: loss=3.184624195098877\n",
      "Epoch 60: loss=3.1743738651275635\n",
      "Epoch 70: loss=3.1388630867004395\n",
      "Epoch 80: loss=3.129253625869751\n",
      "Epoch 90: loss=3.126054048538208\n",
      "Epoch 100: loss=3.0973305702209473\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6983324911571501\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.676302194595337\n",
      "Epoch 20: loss=3.5002827644348145\n",
      "Epoch 30: loss=3.3972737789154053\n",
      "Epoch 40: loss=3.335951566696167\n",
      "Epoch 50: loss=3.25575852394104\n",
      "Epoch 60: loss=3.228487968444824\n",
      "Epoch 70: loss=3.2433338165283203\n",
      "Epoch 80: loss=3.1947615146636963\n",
      "Epoch 90: loss=3.1872615814208984\n",
      "Epoch 100: loss=3.1502625942230225\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6988377968671046\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.927049160003662\n",
      "Epoch 20: loss=3.7355077266693115\n",
      "Epoch 30: loss=3.6195857524871826\n",
      "Epoch 40: loss=3.5486793518066406\n",
      "Epoch 50: loss=3.478445529937744\n",
      "Epoch 60: loss=3.4532113075256348\n",
      "Epoch 70: loss=3.433318853378296\n",
      "Epoch 80: loss=3.385822296142578\n",
      "Epoch 90: loss=3.369065761566162\n",
      "Epoch 100: loss=3.382704973220825\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6659929257200606\n",
      "------------------------------------------\n",
      "Model with hidden size(32, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.754037380218506\n",
      "Epoch 20: loss=3.6014626026153564\n",
      "Epoch 30: loss=3.4672799110412598\n",
      "Epoch 40: loss=3.401309013366699\n",
      "Epoch 50: loss=3.354067802429199\n",
      "Epoch 60: loss=3.298635482788086\n",
      "Epoch 70: loss=3.3108294010162354\n",
      "Epoch 80: loss=3.2506508827209473\n",
      "Epoch 90: loss=3.255000352859497\n",
      "Epoch 100: loss=3.215951681137085\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6897422940879232\n",
      "------------------------------------------\n",
      "Model with hidden size(32, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.0902862548828125\n",
      "Epoch 20: loss=3.859769821166992\n",
      "Epoch 30: loss=3.731562852859497\n",
      "Epoch 40: loss=3.6605522632598877\n",
      "Epoch 50: loss=3.5805768966674805\n",
      "Epoch 60: loss=3.539219856262207\n",
      "Epoch 70: loss=3.513859510421753\n",
      "Epoch 80: loss=3.4671947956085205\n",
      "Epoch 90: loss=3.4730281829833984\n",
      "Epoch 100: loss=3.427130699157715\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6346639717028802\n",
      "------------------------------------------\n",
      "Model with hidden size(16, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.9757606983184814\n",
      "Epoch 20: loss=3.7976856231689453\n",
      "Epoch 30: loss=3.729708194732666\n",
      "Epoch 40: loss=3.6385579109191895\n",
      "Epoch 50: loss=3.584987163543701\n",
      "Epoch 60: loss=3.5570597648620605\n",
      "Epoch 70: loss=3.5165178775787354\n",
      "Epoch 80: loss=3.47989821434021\n",
      "Epoch 90: loss=3.5036885738372803\n",
      "Epoch 100: loss=3.46756649017334\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6503284487114704\n",
      "------------------------------------------\n",
      "Best model with hidden size(128,64): Test accuracy= 0.6956302096489012\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "num_heads = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Train and evaluate GAT with variable attention heads\n",
    "best_accuracy = 0.0\n",
    "best_num_heads = None\n",
    "best_model = None\n",
    "best_acc = None\n",
    "\n",
    "for num_head in num_heads:\n",
    "\n",
    "  # Define model\n",
    "  model = GATThreeLayer(dataset.num_features, best_hid1, best_hid2, dataset.num_classes, num_heads=num_head)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  print(f\"Attention-heads: {num_head}\")\n",
    "  print(f\"...Training Start...\")\n",
    "\n",
    "  # Training\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset)\n",
    "      loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Printing Every 10 epochs\n",
    "      if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "        print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "  # Evaluation\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      logits = model(dataset)\n",
    "      _, predicted = logits.max(dim=1)\n",
    "      correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "      acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "  print(f\"...Training End...\")\n",
    "  print(f\"\\nValidation accuracy= {acc}\")\n",
    "  print(\"------------------------------------------\")\n",
    "\n",
    "  # Updateing best model\n",
    "  if best_model is None:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "  if acc > best_acc:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f'Best GATThreeLayer with Variable Attention Heads({best_num_heads}) Test Accuracy : {acc}')"
   ],
   "metadata": {
    "id": "suw7jDHFUkU2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention-heads: 1\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.852692127227783\n",
      "Epoch 20: loss=3.548410177230835\n",
      "Epoch 30: loss=3.3885953426361084\n",
      "Epoch 40: loss=3.2584545612335205\n",
      "Epoch 50: loss=3.216054677963257\n",
      "Epoch 60: loss=3.184718132019043\n",
      "Epoch 70: loss=3.1316847801208496\n",
      "Epoch 80: loss=3.130302906036377\n",
      "Epoch 90: loss=3.108633041381836\n",
      "Epoch 100: loss=3.108652114868164\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7013643254168772\n",
      "------------------------------------------\n",
      "Attention-heads: 2\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.571305274963379\n",
      "Epoch 20: loss=3.275869846343994\n",
      "Epoch 30: loss=3.1347994804382324\n",
      "Epoch 40: loss=3.081047296524048\n",
      "Epoch 50: loss=3.0363245010375977\n",
      "Epoch 60: loss=2.987683057785034\n",
      "Epoch 70: loss=2.9534804821014404\n",
      "Epoch 80: loss=2.937516450881958\n",
      "Epoch 90: loss=2.914320707321167\n",
      "Epoch 100: loss=2.8960015773773193\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7038908539666499\n",
      "------------------------------------------\n",
      "Attention-heads: 3\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.144101142883301\n",
      "Epoch 20: loss=3.6527347564697266\n",
      "Epoch 30: loss=3.374671459197998\n",
      "Epoch 40: loss=3.2537460327148438\n",
      "Epoch 50: loss=3.173140525817871\n",
      "Epoch 60: loss=3.099350690841675\n",
      "Epoch 70: loss=3.0495121479034424\n",
      "Epoch 80: loss=3.0084688663482666\n",
      "Epoch 90: loss=2.97281813621521\n",
      "Epoch 100: loss=2.935195207595825\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6968165740272865\n",
      "------------------------------------------\n",
      "Attention-heads: 4\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.268712520599365\n",
      "Epoch 20: loss=3.7670042514801025\n",
      "Epoch 30: loss=3.538817882537842\n",
      "Epoch 40: loss=3.3536694049835205\n",
      "Epoch 50: loss=3.2256338596343994\n",
      "Epoch 60: loss=3.1435649394989014\n",
      "Epoch 70: loss=3.0830254554748535\n",
      "Epoch 80: loss=3.0323903560638428\n",
      "Epoch 90: loss=3.000368118286133\n",
      "Epoch 100: loss=2.98669171333313\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6983324911571501\n",
      "------------------------------------------\n",
      "Attention-heads: 5\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.457022666931152\n",
      "Epoch 20: loss=4.24747896194458\n",
      "Epoch 30: loss=3.907090187072754\n",
      "Epoch 40: loss=3.674687147140503\n",
      "Epoch 50: loss=3.530327796936035\n",
      "Epoch 60: loss=3.393465518951416\n",
      "Epoch 70: loss=3.279548406600952\n",
      "Epoch 80: loss=3.1977195739746094\n",
      "Epoch 90: loss=3.1423158645629883\n",
      "Epoch 100: loss=3.08010196685791\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6735725113693785\n",
      "------------------------------------------\n",
      "Attention-heads: 6\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.626973628997803\n",
      "Epoch 20: loss=4.283270835876465\n",
      "Epoch 30: loss=4.126850128173828\n",
      "Epoch 40: loss=3.949147939682007\n",
      "Epoch 50: loss=3.825904130935669\n",
      "Epoch 60: loss=3.7066385746002197\n",
      "Epoch 70: loss=3.546814441680908\n",
      "Epoch 80: loss=3.455388069152832\n",
      "Epoch 90: loss=3.3589251041412354\n",
      "Epoch 100: loss=3.242875099182129\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6366851945426983\n",
      "------------------------------------------\n",
      "Attention-heads: 7\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.615021228790283\n",
      "Epoch 20: loss=4.493330001831055\n",
      "Epoch 30: loss=4.387612819671631\n",
      "Epoch 40: loss=4.251298427581787\n",
      "Epoch 50: loss=4.150088310241699\n",
      "Epoch 60: loss=4.063244342803955\n",
      "Epoch 70: loss=3.9535698890686035\n",
      "Epoch 80: loss=3.8606910705566406\n",
      "Epoch 90: loss=3.770137310028076\n",
      "Epoch 100: loss=3.6794493198394775\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.4850934815563416\n",
      "------------------------------------------\n",
      "Attention-heads: 8\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.649743556976318\n",
      "Epoch 20: loss=4.493814945220947\n",
      "Epoch 30: loss=4.425428867340088\n",
      "Epoch 40: loss=4.365975379943848\n",
      "Epoch 50: loss=4.324014186859131\n",
      "Epoch 60: loss=4.2882819175720215\n",
      "Epoch 70: loss=4.244269371032715\n",
      "Epoch 80: loss=4.214915752410889\n",
      "Epoch 90: loss=4.170232772827148\n",
      "Epoch 100: loss=4.135583877563477\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.29156139464375946\n",
      "------------------------------------------\n",
      "Attention-heads: 9\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.883756637573242\n",
      "Epoch 20: loss=4.629194736480713\n",
      "Epoch 30: loss=4.585606575012207\n",
      "Epoch 40: loss=4.56134033203125\n",
      "Epoch 50: loss=4.546919822692871\n",
      "Epoch 60: loss=4.564040184020996\n",
      "Epoch 70: loss=4.495030403137207\n",
      "Epoch 80: loss=4.465190410614014\n",
      "Epoch 90: loss=4.40513277053833\n",
      "Epoch 100: loss=4.401766777038574\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.04699343102577059\n",
      "------------------------------------------\n",
      "Attention-heads: 10\n",
      "...Training Start...\n",
      "Epoch 10: loss=6.393575668334961\n",
      "Epoch 20: loss=4.542149543762207\n",
      "Epoch 30: loss=4.445467472076416\n",
      "Epoch 40: loss=4.4239301681518555\n",
      "Epoch 50: loss=4.426389217376709\n",
      "Epoch 60: loss=4.4131340980529785\n",
      "Epoch 70: loss=4.395932674407959\n",
      "Epoch 80: loss=4.392675876617432\n",
      "Epoch 90: loss=4.389608860015869\n",
      "Epoch 100: loss=4.3885979652404785\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.029307731177362305\n",
      "------------------------------------------\n",
      "Best GATThreeLayer with Variable Attention Heads(2) Test Accuracy : 0.6941146754230867\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **GATv2**"
   ],
   "metadata": {
    "id": "5DvSoSlsUobM",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **GATv2OneLayer**"
   ],
   "metadata": {
    "id": "2tbwhug1ZlJS",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class GATv2OneLayer(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_heads=1):\n",
    "        super(GATv2OneLayer, self).__init__()\n",
    "        self.conv = GATv2Conv(input_size, output_size, heads=num_heads, concat=True, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x = F.elu(self.conv(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "metadata": {
    "id": "MwBZdKzAw0KX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cite\n",
    "print('Dataset: CiteSeer')\n",
    "\n",
    "# Define training parameters\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Define model\n",
    "model = GATv2OneLayer(dataset.num_features, dataset.num_classes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"...Training Start...\")\n",
    "\n",
    "# Training\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(dataset[0])\n",
    "    loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Printing Every 10 epochs\n",
    "    if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "      print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(dataset[0])\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "    acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "print(f\"...Training End...\")\n",
    "print(f\"\\nValidation accuracy= {acc}\")\n",
    "\n",
    "# Updateing best model\n",
    "if best_model is None:\n",
    "  best_model = model\n",
    "  best_acc = acc\n",
    "  best_hid = layer_size\n",
    "\n",
    "if acc > best_acc:\n",
    "  best_model = model\n",
    "  best_acc = acc\n",
    "  best_hid = layer_size\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset[0])\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Test accuracy= {acc}\")"
   ],
   "metadata": {
    "id": "DCrsHoU4w0M0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CiteSeer\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.2109465599060059\n",
      "Epoch 20: loss=0.9955925345420837\n",
      "Epoch 30: loss=1.0486680269241333\n",
      "Epoch 40: loss=0.9746225476264954\n",
      "Epoch 50: loss=1.0035258531570435\n",
      "Epoch 60: loss=0.929010808467865\n",
      "Epoch 70: loss=1.0540907382965088\n",
      "Epoch 80: loss=0.9147629141807556\n",
      "Epoch 90: loss=0.9027494788169861\n",
      "Epoch 100: loss=0.9105974435806274\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.642\n",
      "Test accuracy= 0.625\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "num_heads = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Train and evaluate GAT with variable attention heads\n",
    "best_accuracy = 0.0\n",
    "best_num_heads = None\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "for num_head in num_heads:\n",
    "\n",
    "  # Define model\n",
    "  model = GATv2OneLayer(dataset.num_features, dataset.num_classes, num_heads=num_head)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  print(f\"Attention-heads: {num_head}\")\n",
    "  print(f\"...Training Start...\")\n",
    "\n",
    "  # Training\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset[0])\n",
    "      loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Printing Every 10 epochs\n",
    "      if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "        print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "  # Evaluation\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      logits = model(dataset[0])\n",
    "      _, predicted = logits.max(dim=1)\n",
    "      correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "      acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "  print(f\"...Training End...\")\n",
    "  print(f\"\\nValidation accuracy= {acc}\")\n",
    "  print(\"------------------------------------------\")\n",
    "\n",
    "  # Updateing best model\n",
    "  if best_model is None:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "  if acc > best_acc:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset[0])\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f'Best GATv2OneLayer with Variable Attention Heads({best_num_heads}) Test Accuracy : {acc}')"
   ],
   "metadata": {
    "id": "MwgQ27h_Z1zU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention-heads: 1\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.1681439876556396\n",
      "Epoch 20: loss=1.0652116537094116\n",
      "Epoch 30: loss=0.9045348763465881\n",
      "Epoch 40: loss=0.9353955984115601\n",
      "Epoch 50: loss=1.0715805292129517\n",
      "Epoch 60: loss=1.0254569053649902\n",
      "Epoch 70: loss=1.085233211517334\n",
      "Epoch 80: loss=1.0201127529144287\n",
      "Epoch 90: loss=1.000139832496643\n",
      "Epoch 100: loss=1.0226608514785767\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.614\n",
      "------------------------------------------\n",
      "Attention-heads: 2\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.5584989786148071\n",
      "Epoch 20: loss=1.365357756614685\n",
      "Epoch 30: loss=1.4440174102783203\n",
      "Epoch 40: loss=1.2590410709381104\n",
      "Epoch 50: loss=1.3721989393234253\n",
      "Epoch 60: loss=1.207844614982605\n",
      "Epoch 70: loss=1.2069382667541504\n",
      "Epoch 80: loss=1.3490396738052368\n",
      "Epoch 90: loss=1.3240054845809937\n",
      "Epoch 100: loss=1.2249958515167236\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.628\n",
      "------------------------------------------\n",
      "Attention-heads: 3\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.7949912548065186\n",
      "Epoch 20: loss=1.8300796747207642\n",
      "Epoch 30: loss=1.6596287488937378\n",
      "Epoch 40: loss=1.5780795812606812\n",
      "Epoch 50: loss=1.5465964078903198\n",
      "Epoch 60: loss=1.5767898559570312\n",
      "Epoch 70: loss=1.5198924541473389\n",
      "Epoch 80: loss=1.6210752725601196\n",
      "Epoch 90: loss=1.545530915260315\n",
      "Epoch 100: loss=1.5547159910202026\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.618\n",
      "------------------------------------------\n",
      "Attention-heads: 4\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.8850696086883545\n",
      "Epoch 20: loss=1.8820360898971558\n",
      "Epoch 30: loss=1.6417783498764038\n",
      "Epoch 40: loss=1.780181646347046\n",
      "Epoch 50: loss=1.937963843345642\n",
      "Epoch 60: loss=1.6866230964660645\n",
      "Epoch 70: loss=1.672174096107483\n",
      "Epoch 80: loss=1.7369428873062134\n",
      "Epoch 90: loss=1.7896567583084106\n",
      "Epoch 100: loss=1.6807608604431152\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.634\n",
      "------------------------------------------\n",
      "Attention-heads: 5\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.1425535678863525\n",
      "Epoch 20: loss=1.9335993528366089\n",
      "Epoch 30: loss=2.061567783355713\n",
      "Epoch 40: loss=1.947187900543213\n",
      "Epoch 50: loss=1.8400700092315674\n",
      "Epoch 60: loss=1.7756811380386353\n",
      "Epoch 70: loss=1.8324415683746338\n",
      "Epoch 80: loss=1.8004471063613892\n",
      "Epoch 90: loss=1.6598881483078003\n",
      "Epoch 100: loss=1.6593985557556152\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.62\n",
      "------------------------------------------\n",
      "Attention-heads: 6\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.460388422012329\n",
      "Epoch 20: loss=2.0928030014038086\n",
      "Epoch 30: loss=2.06905460357666\n",
      "Epoch 40: loss=1.8425675630569458\n",
      "Epoch 50: loss=1.8076636791229248\n",
      "Epoch 60: loss=1.997313380241394\n",
      "Epoch 70: loss=1.7525593042373657\n",
      "Epoch 80: loss=1.7630656957626343\n",
      "Epoch 90: loss=1.9026601314544678\n",
      "Epoch 100: loss=1.9547845125198364\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.628\n",
      "------------------------------------------\n",
      "Attention-heads: 7\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.482531785964966\n",
      "Epoch 20: loss=2.118812084197998\n",
      "Epoch 30: loss=2.4537882804870605\n",
      "Epoch 40: loss=2.208106517791748\n",
      "Epoch 50: loss=1.8507620096206665\n",
      "Epoch 60: loss=1.9519057273864746\n",
      "Epoch 70: loss=1.8184306621551514\n",
      "Epoch 80: loss=1.8088403940200806\n",
      "Epoch 90: loss=1.7930585145950317\n",
      "Epoch 100: loss=1.9004530906677246\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.634\n",
      "------------------------------------------\n",
      "Attention-heads: 8\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.476616144180298\n",
      "Epoch 20: loss=2.331798791885376\n",
      "Epoch 30: loss=1.9258147478103638\n",
      "Epoch 40: loss=2.437166452407837\n",
      "Epoch 50: loss=2.2273619174957275\n",
      "Epoch 60: loss=2.092935562133789\n",
      "Epoch 70: loss=2.1084444522857666\n",
      "Epoch 80: loss=1.9461768865585327\n",
      "Epoch 90: loss=2.105555295944214\n",
      "Epoch 100: loss=2.14577054977417\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.604\n",
      "------------------------------------------\n",
      "Attention-heads: 9\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.7340707778930664\n",
      "Epoch 20: loss=2.3139493465423584\n",
      "Epoch 30: loss=2.1862587928771973\n",
      "Epoch 40: loss=2.0422351360321045\n",
      "Epoch 50: loss=2.7293684482574463\n",
      "Epoch 60: loss=1.9581304788589478\n",
      "Epoch 70: loss=1.9932749271392822\n",
      "Epoch 80: loss=2.218747138977051\n",
      "Epoch 90: loss=1.9989787340164185\n",
      "Epoch 100: loss=1.931278944015503\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.632\n",
      "------------------------------------------\n",
      "Attention-heads: 10\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.6826374530792236\n",
      "Epoch 20: loss=2.3664209842681885\n",
      "Epoch 30: loss=2.2883689403533936\n",
      "Epoch 40: loss=2.221991539001465\n",
      "Epoch 50: loss=2.0929477214813232\n",
      "Epoch 60: loss=2.394535779953003\n",
      "Epoch 70: loss=2.0180723667144775\n",
      "Epoch 80: loss=2.4583017826080322\n",
      "Epoch 90: loss=2.367755651473999\n",
      "Epoch 100: loss=2.144869565963745\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.63\n",
      "------------------------------------------\n",
      "Best GATv2OneLayer with Variable Attention Heads(4) Test Accuracy : 0.65\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cora\n",
    "print('Dataset: CoraFull')\n",
    "\n",
    "# Define training parameters\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Define model\n",
    "model = GATv2OneLayer(dataset.num_features, dataset.num_classes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"...Training Start...\")\n",
    "\n",
    "# Training\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(dataset)\n",
    "    loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Printing Every 10 epochs\n",
    "    if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "      print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "    acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "print(f\"...Training End...\")\n",
    "print(f\"\\nValidation accuracy= {acc}\")\n",
    "\n",
    "# Updateing best model\n",
    "if best_model is None:\n",
    "  best_model = model\n",
    "  best_acc = acc\n",
    "  best_hid = layer_size\n",
    "\n",
    "if acc > best_acc:\n",
    "  best_model = model\n",
    "  best_acc = acc\n",
    "  best_hid = layer_size\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Test accuracy= {acc}\")"
   ],
   "metadata": {
    "id": "C3Ga4nGiuiKY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CoraFull\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.0002801418304443\n",
      "Epoch 20: loss=2.7800214290618896\n",
      "Epoch 30: loss=2.6596615314483643\n",
      "Epoch 40: loss=2.583801031112671\n",
      "Epoch 50: loss=2.5529885292053223\n",
      "Epoch 60: loss=2.495514392852783\n",
      "Epoch 70: loss=2.4930977821350098\n",
      "Epoch 80: loss=2.4719808101654053\n",
      "Epoch 90: loss=2.440887451171875\n",
      "Epoch 100: loss=2.441152572631836\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.705912076806468\n",
      "Test accuracy= 0.7090174286435968\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "num_heads = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Train and evaluate GAT with variable attention heads\n",
    "best_accuracy = 0.0\n",
    "best_num_heads = None\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "for num_head in num_heads:\n",
    "\n",
    "  # Define model\n",
    "  model = GATv2OneLayer(dataset.num_features, dataset.num_classes, num_heads=num_head)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  print(f\"Attention-heads: {num_head}\")\n",
    "  print(f\"...Training Start...\")\n",
    "\n",
    "  # Training\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset)\n",
    "      loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Printing Every 10 epochs\n",
    "      if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "        print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "  # Evaluation\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      logits = model(dataset)\n",
    "      _, predicted = logits.max(dim=1)\n",
    "      correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "      acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "  print(f\"...Training End...\")\n",
    "  print(f\"\\nValidation accuracy= {acc}\")\n",
    "  print(\"------------------------------------------\")\n",
    "\n",
    "  # Updateing best model\n",
    "  if best_model is None:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "  if acc > best_acc:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f'Best GATv2OneLayer with Variable Attention Heads({best_num_heads}) Test Accuracy : {acc}')"
   ],
   "metadata": {
    "id": "WYb_0mJzuiNB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention-heads: 1\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.0413506031036377\n",
      "Epoch 20: loss=2.791253089904785\n",
      "Epoch 30: loss=2.6477420330047607\n",
      "Epoch 40: loss=2.5806872844696045\n",
      "Epoch 50: loss=2.533102035522461\n",
      "Epoch 60: loss=2.5163586139678955\n",
      "Epoch 70: loss=2.501258611679077\n",
      "Epoch 80: loss=2.4689135551452637\n",
      "Epoch 90: loss=2.459242582321167\n",
      "Epoch 100: loss=2.4415929317474365\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7069226882263769\n",
      "------------------------------------------\n",
      "Attention-heads: 2\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.4602181911468506\n",
      "Epoch 20: loss=3.162766695022583\n",
      "Epoch 30: loss=3.0658273696899414\n",
      "Epoch 40: loss=3.0089597702026367\n",
      "Epoch 50: loss=2.9407501220703125\n",
      "Epoch 60: loss=2.9095845222473145\n",
      "Epoch 70: loss=2.8732025623321533\n",
      "Epoch 80: loss=2.8617660999298096\n",
      "Epoch 90: loss=2.8380258083343506\n",
      "Epoch 100: loss=2.796309471130371\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7028802425467408\n",
      "------------------------------------------\n",
      "Attention-heads: 3\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.7218503952026367\n",
      "Epoch 20: loss=3.4559271335601807\n",
      "Epoch 30: loss=3.298279047012329\n",
      "Epoch 40: loss=3.22817325592041\n",
      "Epoch 50: loss=3.181882858276367\n",
      "Epoch 60: loss=3.144327402114868\n",
      "Epoch 70: loss=3.111750602722168\n",
      "Epoch 80: loss=3.0766594409942627\n",
      "Epoch 90: loss=3.0434513092041016\n",
      "Epoch 100: loss=3.0324387550354004\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.705912076806468\n",
      "------------------------------------------\n",
      "Attention-heads: 4\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.9739418029785156\n",
      "Epoch 20: loss=3.653271436691284\n",
      "Epoch 30: loss=3.4712793827056885\n",
      "Epoch 40: loss=3.4436984062194824\n",
      "Epoch 50: loss=3.338179111480713\n",
      "Epoch 60: loss=3.316828966140747\n",
      "Epoch 70: loss=3.2670600414276123\n",
      "Epoch 80: loss=3.2490174770355225\n",
      "Epoch 90: loss=3.199035882949829\n",
      "Epoch 100: loss=3.205474615097046\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7003537139969682\n",
      "------------------------------------------\n",
      "Attention-heads: 5\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.178696155548096\n",
      "Epoch 20: loss=3.806020736694336\n",
      "Epoch 30: loss=3.714771032333374\n",
      "Epoch 40: loss=3.555429220199585\n",
      "Epoch 50: loss=3.5077736377716064\n",
      "Epoch 60: loss=3.4566948413848877\n",
      "Epoch 70: loss=3.420196533203125\n",
      "Epoch 80: loss=3.3634538650512695\n",
      "Epoch 90: loss=3.3518142700195312\n",
      "Epoch 100: loss=3.3291587829589844\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7054067710965134\n",
      "------------------------------------------\n",
      "Attention-heads: 6\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.333174705505371\n",
      "Epoch 20: loss=3.9320523738861084\n",
      "Epoch 30: loss=3.756481170654297\n",
      "Epoch 40: loss=3.727503776550293\n",
      "Epoch 50: loss=3.65421462059021\n",
      "Epoch 60: loss=3.596907615661621\n",
      "Epoch 70: loss=3.514519214630127\n",
      "Epoch 80: loss=3.496448516845703\n",
      "Epoch 90: loss=3.4595987796783447\n",
      "Epoch 100: loss=3.424490451812744\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7109651339060131\n",
      "------------------------------------------\n",
      "Attention-heads: 7\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.4484639167785645\n",
      "Epoch 20: loss=4.080801010131836\n",
      "Epoch 30: loss=3.906230926513672\n",
      "Epoch 40: loss=3.7807486057281494\n",
      "Epoch 50: loss=3.730039596557617\n",
      "Epoch 60: loss=3.669229745864868\n",
      "Epoch 70: loss=3.6273181438446045\n",
      "Epoch 80: loss=3.586050033569336\n",
      "Epoch 90: loss=3.5586133003234863\n",
      "Epoch 100: loss=3.5384676456451416\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7028802425467408\n",
      "------------------------------------------\n",
      "Attention-heads: 8\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.48855447769165\n",
      "Epoch 20: loss=4.106086254119873\n",
      "Epoch 30: loss=3.9437451362609863\n",
      "Epoch 40: loss=3.8458523750305176\n",
      "Epoch 50: loss=3.8174753189086914\n",
      "Epoch 60: loss=3.7326788902282715\n",
      "Epoch 70: loss=3.656290292739868\n",
      "Epoch 80: loss=3.646763801574707\n",
      "Epoch 90: loss=3.6545724868774414\n",
      "Epoch 100: loss=3.594003200531006\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7033855482566953\n",
      "------------------------------------------\n",
      "Attention-heads: 9\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.6166276931762695\n",
      "Epoch 20: loss=4.234760761260986\n",
      "Epoch 30: loss=4.021544456481934\n",
      "Epoch 40: loss=3.8917229175567627\n",
      "Epoch 50: loss=3.848008155822754\n",
      "Epoch 60: loss=3.8014883995056152\n",
      "Epoch 70: loss=3.7577600479125977\n",
      "Epoch 80: loss=3.7492215633392334\n",
      "Epoch 90: loss=3.683450698852539\n",
      "Epoch 100: loss=3.623401641845703\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7038908539666499\n",
      "------------------------------------------\n",
      "Attention-heads: 10\n",
      "...Training Start...\n",
      "Epoch 10: loss=4.687230587005615\n",
      "Epoch 20: loss=4.284911632537842\n",
      "Epoch 30: loss=4.07380485534668\n",
      "Epoch 40: loss=4.007518768310547\n",
      "Epoch 50: loss=3.952054738998413\n",
      "Epoch 60: loss=3.879514455795288\n",
      "Epoch 70: loss=3.825483798980713\n",
      "Epoch 80: loss=3.8239095211029053\n",
      "Epoch 90: loss=3.7376461029052734\n",
      "Epoch 100: loss=3.667774200439453\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.705912076806468\n",
      "------------------------------------------\n",
      "Best GATv2OneLayer with Variable Attention Heads(6) Test Accuracy : 0.7047234150037889\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **GATv2TwoLayers**"
   ],
   "metadata": {
    "id": "ar5VpKpobcPa",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class GATv2TwoLayers(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_heads=1):\n",
    "        super(GATv2TwoLayers, self).__init__()\n",
    "        self.conv1 = GATv2Conv(input_size, hidden_size, heads=num_heads, concat=True, dropout=0.6)\n",
    "        self.fc_out = nn.Linear(hidden_size * num_heads, output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "metadata": {
    "id": "VXb6el7kbc1r",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cite\n",
    "print('Dataset: CiteSeer')\n",
    "\n",
    "# Define training parameters\n",
    "layers_size = [8,16,32,64,128]\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Training Loop\n",
    "for layer_size in layers_size:\n",
    "\n",
    "    # Define model\n",
    "    model = GATv2TwoLayers(dataset.num_features, layer_size, dataset.num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Model with hidden size({layer_size}):\\n\")\n",
    "    print(f\"...Training Start...\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(dataset[0])\n",
    "        loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Printing Every 10 epochs\n",
    "        if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "          print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(dataset[0])\n",
    "        _, predicted = logits.max(dim=1)\n",
    "        correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "        acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "    print(f\"...Training End...\")\n",
    "    print(f\"\\nValidation accuracy= {acc}\")\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Updateing best model\n",
    "    if best_model is None:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid = layer_size\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid = layer_size\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset[0])\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Best model with hidden size({best_hid}): Test accuracy= {acc}\")"
   ],
   "metadata": {
    "id": "uXUAo-DScERR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CiteSeer\n",
      "Model with hidden size(8):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.2151631116867065\n",
      "Epoch 20: loss=0.8535587191581726\n",
      "Epoch 30: loss=0.7759020924568176\n",
      "Epoch 40: loss=0.7352535128593445\n",
      "Epoch 50: loss=0.6399480700492859\n",
      "Epoch 60: loss=0.5365914702415466\n",
      "Epoch 70: loss=0.5678050518035889\n",
      "Epoch 80: loss=0.7238366007804871\n",
      "Epoch 90: loss=0.5911661386489868\n",
      "Epoch 100: loss=0.5618512034416199\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.626\n",
      "------------------------------------------\n",
      "Model with hidden size(16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.0972903966903687\n",
      "Epoch 20: loss=0.6634604334831238\n",
      "Epoch 30: loss=0.6810731291770935\n",
      "Epoch 40: loss=0.4216062128543854\n",
      "Epoch 50: loss=0.4920482039451599\n",
      "Epoch 60: loss=0.5154551863670349\n",
      "Epoch 70: loss=0.4454532265663147\n",
      "Epoch 80: loss=0.5492525696754456\n",
      "Epoch 90: loss=0.4679131507873535\n",
      "Epoch 100: loss=0.5268263220787048\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.646\n",
      "------------------------------------------\n",
      "Model with hidden size(32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.801188051700592\n",
      "Epoch 20: loss=0.5600432753562927\n",
      "Epoch 30: loss=0.4556227922439575\n",
      "Epoch 40: loss=0.3682054877281189\n",
      "Epoch 50: loss=0.399263858795166\n",
      "Epoch 60: loss=0.38336217403411865\n",
      "Epoch 70: loss=0.42118513584136963\n",
      "Epoch 80: loss=0.3623591363430023\n",
      "Epoch 90: loss=0.3513108789920807\n",
      "Epoch 100: loss=0.4437302052974701\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.628\n",
      "------------------------------------------\n",
      "Model with hidden size(64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.6152423024177551\n",
      "Epoch 20: loss=0.4409777820110321\n",
      "Epoch 30: loss=0.4185459315776825\n",
      "Epoch 40: loss=0.5399907827377319\n",
      "Epoch 50: loss=0.2949860990047455\n",
      "Epoch 60: loss=0.41368645429611206\n",
      "Epoch 70: loss=0.4868929088115692\n",
      "Epoch 80: loss=0.42190682888031006\n",
      "Epoch 90: loss=0.34301722049713135\n",
      "Epoch 100: loss=0.3876829743385315\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.636\n",
      "------------------------------------------\n",
      "Model with hidden size(128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.5869912505149841\n",
      "Epoch 20: loss=0.4638541042804718\n",
      "Epoch 30: loss=0.4497531056404114\n",
      "Epoch 40: loss=0.3350813090801239\n",
      "Epoch 50: loss=0.38703832030296326\n",
      "Epoch 60: loss=0.30277034640312195\n",
      "Epoch 70: loss=0.45359915494918823\n",
      "Epoch 80: loss=0.3804558217525482\n",
      "Epoch 90: loss=0.4261252284049988\n",
      "Epoch 100: loss=0.4246613383293152\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.624\n",
      "------------------------------------------\n",
      "Best model with hidden size(16): Test accuracy= 0.663\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "num_heads = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Train and evaluate GAT with variable attention heads\n",
    "best_accuracy = 0.0\n",
    "best_num_heads = None\n",
    "best_model = None\n",
    "best_acc = None\n",
    "\n",
    "for num_head in num_heads:\n",
    "\n",
    "  # Define model\n",
    "  model = GATv2TwoLayers(dataset.num_features, best_hid, dataset.num_classes, num_heads=num_head)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  print(f\"Attention-heads: {num_head}\")\n",
    "  print(f\"...Training Start...\")\n",
    "\n",
    "  # Training\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset[0])\n",
    "      loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Printing Every 10 epochs\n",
    "      if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "        print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "  # Evaluation\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      logits = model(dataset[0])\n",
    "      _, predicted = logits.max(dim=1)\n",
    "      correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "      acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "  print(f\"...Training End...\")\n",
    "  print(f\"\\nValidation accuracy= {acc}\")\n",
    "  print(\"------------------------------------------\")\n",
    "\n",
    "  # Updateing best model\n",
    "  if best_model is None:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "  if acc > best_acc:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset[0])\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f'Best GATv2TwoLayers with Variable Attention Heads({best_num_heads}) Test Accuracy : {acc}')"
   ],
   "metadata": {
    "id": "TeaHihWUcEXC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention-heads: 1\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.0762356519699097\n",
      "Epoch 20: loss=0.6294386386871338\n",
      "Epoch 30: loss=0.47731536626815796\n",
      "Epoch 40: loss=0.4211123287677765\n",
      "Epoch 50: loss=0.36779165267944336\n",
      "Epoch 60: loss=0.43911486864089966\n",
      "Epoch 70: loss=0.47390130162239075\n",
      "Epoch 80: loss=0.4069523811340332\n",
      "Epoch 90: loss=0.35362643003463745\n",
      "Epoch 100: loss=0.5016305446624756\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.66\n",
      "------------------------------------------\n",
      "Attention-heads: 2\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.5518239736557007\n",
      "Epoch 20: loss=0.32223713397979736\n",
      "Epoch 30: loss=0.16100595891475677\n",
      "Epoch 40: loss=0.23967795073986053\n",
      "Epoch 50: loss=0.07195162773132324\n",
      "Epoch 60: loss=0.2042611688375473\n",
      "Epoch 70: loss=0.16214865446090698\n",
      "Epoch 80: loss=0.17527636885643005\n",
      "Epoch 90: loss=0.1184254139661789\n",
      "Epoch 100: loss=0.1730182021856308\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.67\n",
      "------------------------------------------\n",
      "Attention-heads: 3\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.4509897530078888\n",
      "Epoch 20: loss=0.13243086636066437\n",
      "Epoch 30: loss=0.13034003973007202\n",
      "Epoch 40: loss=0.06590192019939423\n",
      "Epoch 50: loss=0.035483863204717636\n",
      "Epoch 60: loss=0.06517814844846725\n",
      "Epoch 70: loss=0.07848155498504639\n",
      "Epoch 80: loss=0.029928619042038918\n",
      "Epoch 90: loss=0.047497015446424484\n",
      "Epoch 100: loss=0.0694822147488594\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.644\n",
      "------------------------------------------\n",
      "Attention-heads: 4\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.34694671630859375\n",
      "Epoch 20: loss=0.06989826261997223\n",
      "Epoch 30: loss=0.027216847985982895\n",
      "Epoch 40: loss=0.04604330286383629\n",
      "Epoch 50: loss=0.038795001804828644\n",
      "Epoch 60: loss=0.05717033892869949\n",
      "Epoch 70: loss=0.030800608918070793\n",
      "Epoch 80: loss=0.0034416690468788147\n",
      "Epoch 90: loss=0.015374948270618916\n",
      "Epoch 100: loss=0.020072298124432564\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.64\n",
      "------------------------------------------\n",
      "Attention-heads: 5\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.20471741259098053\n",
      "Epoch 20: loss=0.046323057264089584\n",
      "Epoch 30: loss=0.025007249787449837\n",
      "Epoch 40: loss=0.01743158884346485\n",
      "Epoch 50: loss=0.01470006164163351\n",
      "Epoch 60: loss=0.05418483912944794\n",
      "Epoch 70: loss=0.01943838596343994\n",
      "Epoch 80: loss=0.03080526366829872\n",
      "Epoch 90: loss=0.025699876248836517\n",
      "Epoch 100: loss=0.003931139595806599\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.656\n",
      "------------------------------------------\n",
      "Attention-heads: 6\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.13523446023464203\n",
      "Epoch 20: loss=0.008016097359359264\n",
      "Epoch 30: loss=0.024619167670607567\n",
      "Epoch 40: loss=0.0013887418899685144\n",
      "Epoch 50: loss=0.008670284412801266\n",
      "Epoch 60: loss=0.010655611753463745\n",
      "Epoch 70: loss=0.0038871990982443094\n",
      "Epoch 80: loss=0.011423914693295956\n",
      "Epoch 90: loss=0.030101485550403595\n",
      "Epoch 100: loss=0.0165607538074255\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.654\n",
      "------------------------------------------\n",
      "Attention-heads: 7\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.12437223643064499\n",
      "Epoch 20: loss=0.015493604354560375\n",
      "Epoch 30: loss=0.010527176782488823\n",
      "Epoch 40: loss=0.0013435973087325692\n",
      "Epoch 50: loss=0.002734028734266758\n",
      "Epoch 60: loss=0.0022597727365791798\n",
      "Epoch 70: loss=0.002334748627617955\n",
      "Epoch 80: loss=0.0022784641478210688\n",
      "Epoch 90: loss=0.0024255686439573765\n",
      "Epoch 100: loss=0.0035365803632885218\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.652\n",
      "------------------------------------------\n",
      "Attention-heads: 8\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.09430845081806183\n",
      "Epoch 20: loss=0.0245350394397974\n",
      "Epoch 30: loss=0.004381572362035513\n",
      "Epoch 40: loss=0.0025998305063694715\n",
      "Epoch 50: loss=0.0005594267277047038\n",
      "Epoch 60: loss=0.0011320345802232623\n",
      "Epoch 70: loss=0.0011450928868725896\n",
      "Epoch 80: loss=0.0014412496238946915\n",
      "Epoch 90: loss=0.0005018246010877192\n",
      "Epoch 100: loss=0.004014515783637762\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.636\n",
      "------------------------------------------\n",
      "Attention-heads: 9\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.048173923045396805\n",
      "Epoch 20: loss=0.009475255385041237\n",
      "Epoch 30: loss=0.004410232417285442\n",
      "Epoch 40: loss=0.01055519375950098\n",
      "Epoch 50: loss=0.0003319234529044479\n",
      "Epoch 60: loss=0.0001602244738023728\n",
      "Epoch 70: loss=0.001281405915506184\n",
      "Epoch 80: loss=0.0046043661423027515\n",
      "Epoch 90: loss=0.000616597244516015\n",
      "Epoch 100: loss=0.000852693454362452\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.64\n",
      "------------------------------------------\n",
      "Attention-heads: 10\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.03436559811234474\n",
      "Epoch 20: loss=0.0017580389976501465\n",
      "Epoch 30: loss=0.005553691182285547\n",
      "Epoch 40: loss=0.0001548822328913957\n",
      "Epoch 50: loss=0.0012115382123738527\n",
      "Epoch 60: loss=0.0018441962311044335\n",
      "Epoch 70: loss=0.0031359854619950056\n",
      "Epoch 80: loss=0.0002846286224666983\n",
      "Epoch 90: loss=0.01139065995812416\n",
      "Epoch 100: loss=0.00021275259496178478\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.656\n",
      "------------------------------------------\n",
      "Best GATv2TwoLayers with Variable Attention Heads(2) Test Accuracy : 0.656\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cora\n",
    "print('Dataset: CoraFull')\n",
    "\n",
    "# Define training parameters\n",
    "layers_size = [8,16,32,64,128]\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Training Loop\n",
    "for layer_size in layers_size:\n",
    "\n",
    "    # Define model\n",
    "    model = GATv2TwoLayers(dataset.num_features, layer_size, dataset.num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Model with hidden size({layer_size}):\\n\")\n",
    "    print(f\"...Training Start...\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(dataset)\n",
    "        loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Printing Every 10 epochs\n",
    "        if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "          print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(dataset)\n",
    "        _, predicted = logits.max(dim=1)\n",
    "        correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "        acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "    print(f\"...Training End...\")\n",
    "    print(f\"\\nValidation accuracy= {acc}\")\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Updateing best model\n",
    "    if best_model is None:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid = layer_size\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid = layer_size\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Best model with hidden size({best_hid}): Test accuracy= {acc}\")"
   ],
   "metadata": {
    "id": "L29eJW4UhXba",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CoraFull\n",
      "Model with hidden size(8):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.7068426609039307\n",
      "Epoch 20: loss=3.2706665992736816\n",
      "Epoch 30: loss=3.032485246658325\n",
      "Epoch 40: loss=2.8281962871551514\n",
      "Epoch 50: loss=2.705458402633667\n",
      "Epoch 60: loss=2.601210832595825\n",
      "Epoch 70: loss=2.5312016010284424\n",
      "Epoch 80: loss=2.469297409057617\n",
      "Epoch 90: loss=2.4177803993225098\n",
      "Epoch 100: loss=2.3864083290100098\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.5952501263264275\n",
      "------------------------------------------\n",
      "Model with hidden size(16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.306546926498413\n",
      "Epoch 20: loss=2.687863349914551\n",
      "Epoch 30: loss=2.321965217590332\n",
      "Epoch 40: loss=2.1057751178741455\n",
      "Epoch 50: loss=1.949520230293274\n",
      "Epoch 60: loss=1.8239492177963257\n",
      "Epoch 70: loss=1.7201666831970215\n",
      "Epoch 80: loss=1.6529502868652344\n",
      "Epoch 90: loss=1.5924063920974731\n",
      "Epoch 100: loss=1.5448663234710693\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.685699848408287\n",
      "------------------------------------------\n",
      "Model with hidden size(32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.798452615737915\n",
      "Epoch 20: loss=2.034024238586426\n",
      "Epoch 30: loss=1.6750493049621582\n",
      "Epoch 40: loss=1.4560836553573608\n",
      "Epoch 50: loss=1.3478336334228516\n",
      "Epoch 60: loss=1.2552207708358765\n",
      "Epoch 70: loss=1.1681045293807983\n",
      "Epoch 80: loss=1.0961966514587402\n",
      "Epoch 90: loss=1.0876178741455078\n",
      "Epoch 100: loss=1.0574246644973755\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7054067710965134\n",
      "------------------------------------------\n",
      "Model with hidden size(64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.2980737686157227\n",
      "Epoch 20: loss=1.5793706178665161\n",
      "Epoch 30: loss=1.2858188152313232\n",
      "Epoch 40: loss=1.132615327835083\n",
      "Epoch 50: loss=1.0456929206848145\n",
      "Epoch 60: loss=1.0049933195114136\n",
      "Epoch 70: loss=0.9622594118118286\n",
      "Epoch 80: loss=0.9112502336502075\n",
      "Epoch 90: loss=0.9123393893241882\n",
      "Epoch 100: loss=0.90900719165802\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7266296109146033\n",
      "------------------------------------------\n",
      "Model with hidden size(128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.9209474325180054\n",
      "Epoch 20: loss=1.301557183265686\n",
      "Epoch 30: loss=1.0774977207183838\n",
      "Epoch 40: loss=0.9573652744293213\n",
      "Epoch 50: loss=0.9049783945083618\n",
      "Epoch 60: loss=0.8648985624313354\n",
      "Epoch 70: loss=0.8632009029388428\n",
      "Epoch 80: loss=0.8239963054656982\n",
      "Epoch 90: loss=0.8218467831611633\n",
      "Epoch 100: loss=0.7937065958976746\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7145022738756948\n",
      "------------------------------------------\n",
      "Best model with hidden size(64): Test accuracy= 0.7155847436221268\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "num_heads = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Train and evaluate GAT with variable attention heads\n",
    "best_accuracy = 0.0\n",
    "best_num_heads = None\n",
    "best_model = None\n",
    "best_acc = None\n",
    "\n",
    "for num_head in num_heads:\n",
    "\n",
    "  # Define model\n",
    "  model = GATv2TwoLayers(dataset.num_features, best_hid, dataset.num_classes, num_heads=num_head)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  print(f\"Attention-heads: {num_head}\")\n",
    "  print(f\"...Training Start...\")\n",
    "\n",
    "  # Training\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset)\n",
    "      loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Printing Every 10 epochs\n",
    "      if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "        print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "  # Evaluation\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      logits = model(dataset)\n",
    "      _, predicted = logits.max(dim=1)\n",
    "      correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "      acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "  print(f\"...Training End...\")\n",
    "  print(f\"\\nValidation accuracy= {acc}\")\n",
    "  print(\"------------------------------------------\")\n",
    "\n",
    "  # Updateing best model\n",
    "  if best_model is None:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "  if acc > best_acc:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f'Best GATv2TwoLayers with Variable Attention Heads({best_num_heads}) Test Accuracy : {acc}')"
   ],
   "metadata": {
    "id": "O746vTNQhdtq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention-heads: 1\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.342730760574341\n",
      "Epoch 20: loss=1.5850911140441895\n",
      "Epoch 30: loss=1.2751606702804565\n",
      "Epoch 40: loss=1.1335372924804688\n",
      "Epoch 50: loss=1.0381673574447632\n",
      "Epoch 60: loss=0.9882774353027344\n",
      "Epoch 70: loss=0.9556747078895569\n",
      "Epoch 80: loss=0.9213327765464783\n",
      "Epoch 90: loss=0.9063174724578857\n",
      "Epoch 100: loss=0.8686981201171875\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7150075795856493\n",
      "------------------------------------------\n",
      "Attention-heads: 2\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.6512678861618042\n",
      "Epoch 20: loss=0.954054594039917\n",
      "Epoch 30: loss=0.6820456981658936\n",
      "Epoch 40: loss=0.5533021092414856\n",
      "Epoch 50: loss=0.4851570725440979\n",
      "Epoch 60: loss=0.43489569425582886\n",
      "Epoch 70: loss=0.40944379568099976\n",
      "Epoch 80: loss=0.39288759231567383\n",
      "Epoch 90: loss=0.3777724802494049\n",
      "Epoch 100: loss=0.3652268946170807\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.720565942395149\n",
      "------------------------------------------\n",
      "Attention-heads: 3\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.3178576231002808\n",
      "Epoch 20: loss=0.6911654472351074\n",
      "Epoch 30: loss=0.44140395522117615\n",
      "Epoch 40: loss=0.34265410900115967\n",
      "Epoch 50: loss=0.2646591365337372\n",
      "Epoch 60: loss=0.23509354889392853\n",
      "Epoch 70: loss=0.20842811465263367\n",
      "Epoch 80: loss=0.2099975198507309\n",
      "Epoch 90: loss=0.191513791680336\n",
      "Epoch 100: loss=0.18793557584285736\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.718544719555331\n",
      "------------------------------------------\n",
      "Attention-heads: 4\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.1074353456497192\n",
      "Epoch 20: loss=0.5386805534362793\n",
      "Epoch 30: loss=0.29890134930610657\n",
      "Epoch 40: loss=0.2175213098526001\n",
      "Epoch 50: loss=0.17590251564979553\n",
      "Epoch 60: loss=0.15035808086395264\n",
      "Epoch 70: loss=0.13003884255886078\n",
      "Epoch 80: loss=0.12816596031188965\n",
      "Epoch 90: loss=0.12540686130523682\n",
      "Epoch 100: loss=0.11789173632860184\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.717534108135422\n",
      "------------------------------------------\n",
      "Attention-heads: 5\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.9864003658294678\n",
      "Epoch 20: loss=0.4270017445087433\n",
      "Epoch 30: loss=0.23146604001522064\n",
      "Epoch 40: loss=0.15959280729293823\n",
      "Epoch 50: loss=0.1246090680360794\n",
      "Epoch 60: loss=0.1059962809085846\n",
      "Epoch 70: loss=0.08889007568359375\n",
      "Epoch 80: loss=0.08309710025787354\n",
      "Epoch 90: loss=0.078428715467453\n",
      "Epoch 100: loss=0.07482538372278214\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.708943911066195\n",
      "------------------------------------------\n",
      "Attention-heads: 6\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.9198073148727417\n",
      "Epoch 20: loss=0.37753036618232727\n",
      "Epoch 30: loss=0.19013434648513794\n",
      "Epoch 40: loss=0.12136124819517136\n",
      "Epoch 50: loss=0.09435701370239258\n",
      "Epoch 60: loss=0.0724739134311676\n",
      "Epoch 70: loss=0.06760751456022263\n",
      "Epoch 80: loss=0.06147335097193718\n",
      "Epoch 90: loss=0.053102221339941025\n",
      "Epoch 100: loss=0.05254240334033966\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7104598281960586\n",
      "------------------------------------------\n",
      "Attention-heads: 7\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.8640956282615662\n",
      "Epoch 20: loss=0.33898481726646423\n",
      "Epoch 30: loss=0.15775223076343536\n",
      "Epoch 40: loss=0.09453734010457993\n",
      "Epoch 50: loss=0.07012677937746048\n",
      "Epoch 60: loss=0.0677097737789154\n",
      "Epoch 70: loss=0.050262145698070526\n",
      "Epoch 80: loss=0.043515171855688095\n",
      "Epoch 90: loss=0.046427056193351746\n",
      "Epoch 100: loss=0.035891711711883545\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.708943911066195\n",
      "------------------------------------------\n",
      "Attention-heads: 8\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.7802761793136597\n",
      "Epoch 20: loss=0.2857082784175873\n",
      "Epoch 30: loss=0.13215816020965576\n",
      "Epoch 40: loss=0.07105999439954758\n",
      "Epoch 50: loss=0.05652236193418503\n",
      "Epoch 60: loss=0.04767567291855812\n",
      "Epoch 70: loss=0.03923831135034561\n",
      "Epoch 80: loss=0.03805733472108841\n",
      "Epoch 90: loss=0.035271186381578445\n",
      "Epoch 100: loss=0.02911483310163021\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7043961596766043\n",
      "------------------------------------------\n",
      "Attention-heads: 9\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.7502202391624451\n",
      "Epoch 20: loss=0.2613406479358673\n",
      "Epoch 30: loss=0.11047723889350891\n",
      "Epoch 40: loss=0.060096777975559235\n",
      "Epoch 50: loss=0.04337695240974426\n",
      "Epoch 60: loss=0.037898626178503036\n",
      "Epoch 70: loss=0.03233905881643295\n",
      "Epoch 80: loss=0.030731137841939926\n",
      "Epoch 90: loss=0.026187581941485405\n",
      "Epoch 100: loss=0.02249017357826233\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7145022738756948\n",
      "------------------------------------------\n",
      "Attention-heads: 10\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.7182998061180115\n",
      "Epoch 20: loss=0.23089486360549927\n",
      "Epoch 30: loss=0.09626743942499161\n",
      "Epoch 40: loss=0.053680166602134705\n",
      "Epoch 50: loss=0.03363241255283356\n",
      "Epoch 60: loss=0.0327879898250103\n",
      "Epoch 70: loss=0.02460545487701893\n",
      "Epoch 80: loss=0.02295737713575363\n",
      "Epoch 90: loss=0.016222357749938965\n",
      "Epoch 100: loss=0.021229751408100128\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.708943911066195\n",
      "------------------------------------------\n",
      "Best GATv2TwoLayers with Variable Attention Heads(2) Test Accuracy : 0.7171002778479414\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **GATv2ThreeLayers**"
   ],
   "metadata": {
    "id": "4_palmjLii_x",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class GATv2ThreeLayers(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, num_heads=1):\n",
    "        super(GATv2ThreeLayers, self).__init__()\n",
    "        self.conv1 = GATv2Conv(input_size, hidden_size1, heads=num_heads, concat=True, dropout=0.6)\n",
    "        self.conv2 = GATv2Conv(hidden_size1 * num_heads, hidden_size2, heads=num_heads, concat=True, dropout=0.6)\n",
    "        self.fc_out = nn.Linear(hidden_size2 * num_heads, output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.elu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "metadata": {
    "id": "Li0tnQFCheDm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cite\n",
    "print('Dataset: CiteSeer')\n",
    "\n",
    "# Define training parameters\n",
    "layers_size =filtered_list\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Training Loop\n",
    "for layer_size in layers_size:\n",
    "\n",
    "    # Define model\n",
    "    model = GATv2ThreeLayers(dataset.num_features, layer_size[0], layer_size[1], dataset.num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Model with hidden size({layer_size[0]}, {layer_size[1]}):\\n\")\n",
    "    print(f\"...Training Start...\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(dataset[0])\n",
    "        loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Printing Every 10 epochs\n",
    "        if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "          print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(dataset[0])\n",
    "        _, predicted = logits.max(dim=1)\n",
    "        correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "        acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "    print(f\"...Training End...\")\n",
    "    print(f\"\\nValidation accuracy= {acc}\")\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Updateing best model\n",
    "    if best_model is None:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset[0])\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Best model with hidden size({best_hid1},{best_hid2}): Test accuracy= {acc}\")"
   ],
   "metadata": {
    "id": "jUmCGbXFheGh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CiteSeer\n",
      "Model with hidden size(128, 128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.8713670969009399\n",
      "Epoch 20: loss=0.7744399905204773\n",
      "Epoch 30: loss=0.8323773741722107\n",
      "Epoch 40: loss=0.6007691025733948\n",
      "Epoch 50: loss=0.7079378366470337\n",
      "Epoch 60: loss=0.6750494241714478\n",
      "Epoch 70: loss=0.692152738571167\n",
      "Epoch 80: loss=0.678004801273346\n",
      "Epoch 90: loss=0.7213009595870972\n",
      "Epoch 100: loss=0.9789405465126038\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.62\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.0094325542449951\n",
      "Epoch 20: loss=0.8128147721290588\n",
      "Epoch 30: loss=0.6742841601371765\n",
      "Epoch 40: loss=0.6406611800193787\n",
      "Epoch 50: loss=0.5902281999588013\n",
      "Epoch 60: loss=0.7741738557815552\n",
      "Epoch 70: loss=0.7015390396118164\n",
      "Epoch 80: loss=0.5589835047721863\n",
      "Epoch 90: loss=0.5416778922080994\n",
      "Epoch 100: loss=0.6691002249717712\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.61\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.9952005743980408\n",
      "Epoch 20: loss=0.8096920251846313\n",
      "Epoch 30: loss=0.9541254639625549\n",
      "Epoch 40: loss=0.6234461069107056\n",
      "Epoch 50: loss=0.6821644306182861\n",
      "Epoch 60: loss=0.573309063911438\n",
      "Epoch 70: loss=0.7337813973426819\n",
      "Epoch 80: loss=0.661548912525177\n",
      "Epoch 90: loss=0.6339782476425171\n",
      "Epoch 100: loss=0.6726999282836914\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.642\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.1695054769515991\n",
      "Epoch 20: loss=1.1235054731369019\n",
      "Epoch 30: loss=0.9535362720489502\n",
      "Epoch 40: loss=0.7500919699668884\n",
      "Epoch 50: loss=0.6811875700950623\n",
      "Epoch 60: loss=0.7169297337532043\n",
      "Epoch 70: loss=0.7325361967086792\n",
      "Epoch 80: loss=0.6961320638656616\n",
      "Epoch 90: loss=0.7959323525428772\n",
      "Epoch 100: loss=0.6201230883598328\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.63\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.9697573781013489\n",
      "Epoch 20: loss=0.7413368225097656\n",
      "Epoch 30: loss=0.6638520359992981\n",
      "Epoch 40: loss=0.7010892629623413\n",
      "Epoch 50: loss=0.6018139123916626\n",
      "Epoch 60: loss=0.6921759843826294\n",
      "Epoch 70: loss=0.5199092626571655\n",
      "Epoch 80: loss=0.8090959191322327\n",
      "Epoch 90: loss=0.6935043931007385\n",
      "Epoch 100: loss=0.4975418448448181\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.64\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.983391523361206\n",
      "Epoch 20: loss=0.8160525560379028\n",
      "Epoch 30: loss=0.8535832166671753\n",
      "Epoch 40: loss=0.6771758198738098\n",
      "Epoch 50: loss=0.5673525333404541\n",
      "Epoch 60: loss=0.5997455716133118\n",
      "Epoch 70: loss=0.5859153270721436\n",
      "Epoch 80: loss=0.6111587285995483\n",
      "Epoch 90: loss=0.794035017490387\n",
      "Epoch 100: loss=0.5779116153717041\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.65\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.0737816095352173\n",
      "Epoch 20: loss=1.0383038520812988\n",
      "Epoch 30: loss=0.8085911870002747\n",
      "Epoch 40: loss=0.7075673341751099\n",
      "Epoch 50: loss=0.7251609563827515\n",
      "Epoch 60: loss=0.5982930064201355\n",
      "Epoch 70: loss=0.6772730946540833\n",
      "Epoch 80: loss=0.8794999718666077\n",
      "Epoch 90: loss=0.70896315574646\n",
      "Epoch 100: loss=0.7110822200775146\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.658\n",
      "------------------------------------------\n",
      "Model with hidden size(32, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.192810297012329\n",
      "Epoch 20: loss=0.9908290505409241\n",
      "Epoch 30: loss=0.8115686178207397\n",
      "Epoch 40: loss=0.7027705311775208\n",
      "Epoch 50: loss=0.6462001204490662\n",
      "Epoch 60: loss=0.6355383396148682\n",
      "Epoch 70: loss=0.6856710910797119\n",
      "Epoch 80: loss=0.6976543068885803\n",
      "Epoch 90: loss=0.7217271327972412\n",
      "Epoch 100: loss=0.5547472834587097\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.662\n",
      "------------------------------------------\n",
      "Model with hidden size(32, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.2311514616012573\n",
      "Epoch 20: loss=1.0231754779815674\n",
      "Epoch 30: loss=0.9088542461395264\n",
      "Epoch 40: loss=0.9150912165641785\n",
      "Epoch 50: loss=0.7565262317657471\n",
      "Epoch 60: loss=0.7441640496253967\n",
      "Epoch 70: loss=0.6621905565261841\n",
      "Epoch 80: loss=0.761820375919342\n",
      "Epoch 90: loss=0.693549394607544\n",
      "Epoch 100: loss=0.7898175716400146\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.646\n",
      "------------------------------------------\n",
      "Model with hidden size(16, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.3756402730941772\n",
      "Epoch 20: loss=1.1538532972335815\n",
      "Epoch 30: loss=0.9179567694664001\n",
      "Epoch 40: loss=0.9983922243118286\n",
      "Epoch 50: loss=0.7859512567520142\n",
      "Epoch 60: loss=1.038373351097107\n",
      "Epoch 70: loss=0.8226960897445679\n",
      "Epoch 80: loss=0.7430068850517273\n",
      "Epoch 90: loss=0.701397716999054\n",
      "Epoch 100: loss=0.7654172778129578\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.65\n",
      "------------------------------------------\n",
      "Best model with hidden size(32,32): Test accuracy= 0.671\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "num_heads = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Train and evaluate GAT with variable attention heads\n",
    "best_accuracy = 0.0\n",
    "best_num_heads = None\n",
    "best_model = None\n",
    "best_acc = None\n",
    "\n",
    "for num_head in num_heads:\n",
    "\n",
    "  # Define model\n",
    "  model = GATv2ThreeLayers(dataset.num_features, best_hid1, best_hid2, dataset.num_classes, num_heads=num_head)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  print(f\"Attention-heads: {num_head}\")\n",
    "  print(f\"...Training Start...\")\n",
    "\n",
    "  # Training\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset[0])\n",
    "      loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Printing Every 10 epochs\n",
    "      if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "        print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "  # Evaluation\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      logits = model(dataset[0])\n",
    "      _, predicted = logits.max(dim=1)\n",
    "      correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "      acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "  print(f\"...Training End...\")\n",
    "  print(f\"\\nValidation accuracy= {acc}\")\n",
    "  print(\"------------------------------------------\")\n",
    "\n",
    "  # Updateing best model\n",
    "  if best_model is None:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "  if acc > best_acc:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset[0])\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f'Best GATv2ThreeLayers with Variable Attention Heads({best_num_heads}) Test Accuracy : {acc}')"
   ],
   "metadata": {
    "id": "lRTR-h0AheJo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention-heads: 1\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.363036036491394\n",
      "Epoch 20: loss=0.9007967114448547\n",
      "Epoch 30: loss=0.8101269602775574\n",
      "Epoch 40: loss=0.8018590807914734\n",
      "Epoch 50: loss=0.8521273732185364\n",
      "Epoch 60: loss=0.627833366394043\n",
      "Epoch 70: loss=0.48209047317504883\n",
      "Epoch 80: loss=0.5937157869338989\n",
      "Epoch 90: loss=0.6328123807907104\n",
      "Epoch 100: loss=0.6936011910438538\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.638\n",
      "------------------------------------------\n",
      "Attention-heads: 2\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.6738702058792114\n",
      "Epoch 20: loss=0.5200614929199219\n",
      "Epoch 30: loss=0.3038300573825836\n",
      "Epoch 40: loss=0.3505098223686218\n",
      "Epoch 50: loss=0.3527774214744568\n",
      "Epoch 60: loss=0.29422852396965027\n",
      "Epoch 70: loss=0.21309657394886017\n",
      "Epoch 80: loss=0.2595929503440857\n",
      "Epoch 90: loss=0.2520323693752289\n",
      "Epoch 100: loss=0.4918353259563446\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.648\n",
      "------------------------------------------\n",
      "Attention-heads: 3\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.411798894405365\n",
      "Epoch 20: loss=0.26187416911125183\n",
      "Epoch 30: loss=0.1917894035577774\n",
      "Epoch 40: loss=0.25794023275375366\n",
      "Epoch 50: loss=0.13043680787086487\n",
      "Epoch 60: loss=0.18025055527687073\n",
      "Epoch 70: loss=0.11280462145805359\n",
      "Epoch 80: loss=0.19331733882427216\n",
      "Epoch 90: loss=0.1867610365152359\n",
      "Epoch 100: loss=0.18134433031082153\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.618\n",
      "------------------------------------------\n",
      "Attention-heads: 4\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.243103489279747\n",
      "Epoch 20: loss=0.22919170558452606\n",
      "Epoch 30: loss=0.31346064805984497\n",
      "Epoch 40: loss=0.2924562990665436\n",
      "Epoch 50: loss=0.2543281316757202\n",
      "Epoch 60: loss=0.25671565532684326\n",
      "Epoch 70: loss=0.19448915123939514\n",
      "Epoch 80: loss=0.3224669396877289\n",
      "Epoch 90: loss=0.1064269170165062\n",
      "Epoch 100: loss=0.32820120453834534\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.634\n",
      "------------------------------------------\n",
      "Attention-heads: 5\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.1691606342792511\n",
      "Epoch 20: loss=0.13553062081336975\n",
      "Epoch 30: loss=0.08504875749349594\n",
      "Epoch 40: loss=0.2449878305196762\n",
      "Epoch 50: loss=0.1684974730014801\n",
      "Epoch 60: loss=0.08108001202344894\n",
      "Epoch 70: loss=0.2606711685657501\n",
      "Epoch 80: loss=0.08584251254796982\n",
      "Epoch 90: loss=0.19471235573291779\n",
      "Epoch 100: loss=0.3134114444255829\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.638\n",
      "------------------------------------------\n",
      "Attention-heads: 6\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.15949542820453644\n",
      "Epoch 20: loss=0.10840936005115509\n",
      "Epoch 30: loss=0.07659440487623215\n",
      "Epoch 40: loss=0.09476204961538315\n",
      "Epoch 50: loss=0.5444687008857727\n",
      "Epoch 60: loss=0.12453445792198181\n",
      "Epoch 70: loss=0.4446278214454651\n",
      "Epoch 80: loss=0.20561105012893677\n",
      "Epoch 90: loss=0.08039139956235886\n",
      "Epoch 100: loss=0.3800707161426544\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.588\n",
      "------------------------------------------\n",
      "Attention-heads: 7\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.06752920150756836\n",
      "Epoch 20: loss=0.06416501104831696\n",
      "Epoch 30: loss=0.13248704373836517\n",
      "Epoch 40: loss=0.03286447748541832\n",
      "Epoch 50: loss=0.4605244994163513\n",
      "Epoch 60: loss=0.24366337060928345\n",
      "Epoch 70: loss=0.10575098544359207\n",
      "Epoch 80: loss=0.4274609386920929\n",
      "Epoch 90: loss=0.15013481676578522\n",
      "Epoch 100: loss=0.3786584734916687\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.644\n",
      "------------------------------------------\n",
      "Attention-heads: 8\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.060262277722358704\n",
      "Epoch 20: loss=0.2544366121292114\n",
      "Epoch 30: loss=0.31968435645103455\n",
      "Epoch 40: loss=0.35992375016212463\n",
      "Epoch 50: loss=0.1457454413175583\n",
      "Epoch 60: loss=0.39226552844047546\n",
      "Epoch 70: loss=0.3957042098045349\n",
      "Epoch 80: loss=0.8826398849487305\n",
      "Epoch 90: loss=0.6345990896224976\n",
      "Epoch 100: loss=1.1362433433532715\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.604\n",
      "------------------------------------------\n",
      "Attention-heads: 9\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.10087752342224121\n",
      "Epoch 20: loss=0.24052618443965912\n",
      "Epoch 30: loss=0.2982587218284607\n",
      "Epoch 40: loss=0.12741823494434357\n",
      "Epoch 50: loss=0.05979181453585625\n",
      "Epoch 60: loss=0.124125175178051\n",
      "Epoch 70: loss=0.28182756900787354\n",
      "Epoch 80: loss=0.6889317035675049\n",
      "Epoch 90: loss=0.4419272840023041\n",
      "Epoch 100: loss=0.5502100586891174\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.598\n",
      "------------------------------------------\n",
      "Attention-heads: 10\n",
      "...Training Start...\n",
      "Epoch 10: loss=0.07839879393577576\n",
      "Epoch 20: loss=0.18420200049877167\n",
      "Epoch 30: loss=0.009442836046218872\n",
      "Epoch 40: loss=0.12435375154018402\n",
      "Epoch 50: loss=0.2229464054107666\n",
      "Epoch 60: loss=0.2193593978881836\n",
      "Epoch 70: loss=0.4810992479324341\n",
      "Epoch 80: loss=0.41829049587249756\n",
      "Epoch 90: loss=0.6251037120819092\n",
      "Epoch 100: loss=0.18543784320354462\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.646\n",
      "------------------------------------------\n",
      "Best GATv2ThreeLayers with Variable Attention Heads(2) Test Accuracy : 0.658\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset_cora\n",
    "print('Dataset: CoraFull')\n",
    "\n",
    "# Define training parameters\n",
    "layers_size =filtered_list\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_model = None\n",
    "best_acc = None\n",
    "best_hid1 = None\n",
    "best_hid2 = None\n",
    "\n",
    "# Training Loop\n",
    "for layer_size in layers_size:\n",
    "\n",
    "    # Define model\n",
    "    model = GATv2ThreeLayers(dataset.num_features, layer_size[0], layer_size[1], dataset.num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Model with hidden size({layer_size[0]}, {layer_size[1]}):\\n\")\n",
    "    print(f\"...Training Start...\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(dataset)\n",
    "        loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Printing Every 10 epochs\n",
    "        if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "          print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(dataset)\n",
    "        _, predicted = logits.max(dim=1)\n",
    "        correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "        acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "    print(f\"...Training End...\")\n",
    "    print(f\"\\nValidation accuracy= {acc}\")\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # Updateing best model\n",
    "    if best_model is None:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]\n",
    "\n",
    "    if acc > best_acc:\n",
    "      best_model = model\n",
    "      best_acc = acc\n",
    "      best_hid1 = layer_size[0]\n",
    "      best_hid2 = layer_size[1]\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f\"Best model with hidden size({best_hid1},{best_hid2}): Test accuracy= {acc}\")"
   ],
   "metadata": {
    "id": "pwkpZd8slX-U",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CoraFull\n",
      "Model with hidden size(128, 128):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.2621073722839355\n",
      "Epoch 20: loss=1.8332853317260742\n",
      "Epoch 30: loss=1.640994906425476\n",
      "Epoch 40: loss=1.5349726676940918\n",
      "Epoch 50: loss=1.5019539594650269\n",
      "Epoch 60: loss=1.4415055513381958\n",
      "Epoch 70: loss=1.4210712909698486\n",
      "Epoch 80: loss=1.4131653308868408\n",
      "Epoch 90: loss=1.3764276504516602\n",
      "Epoch 100: loss=1.364251971244812\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7018696311268318\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.476548433303833\n",
      "Epoch 20: loss=1.9700698852539062\n",
      "Epoch 30: loss=1.7551101446151733\n",
      "Epoch 40: loss=1.642764925956726\n",
      "Epoch 50: loss=1.601146936416626\n",
      "Epoch 60: loss=1.5517343282699585\n",
      "Epoch 70: loss=1.53791344165802\n",
      "Epoch 80: loss=1.4996236562728882\n",
      "Epoch 90: loss=1.4631143808364868\n",
      "Epoch 100: loss=1.4774444103240967\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6968165740272865\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.8412821292877197\n",
      "Epoch 20: loss=2.2736153602600098\n",
      "Epoch 30: loss=2.031193494796753\n",
      "Epoch 40: loss=1.9226024150848389\n",
      "Epoch 50: loss=1.8542934656143188\n",
      "Epoch 60: loss=1.7883058786392212\n",
      "Epoch 70: loss=1.7134371995925903\n",
      "Epoch 80: loss=1.7029905319213867\n",
      "Epoch 90: loss=1.680045247077942\n",
      "Epoch 100: loss=1.6561176776885986\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6877210712481051\n",
      "------------------------------------------\n",
      "Model with hidden size(128, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.2942779064178467\n",
      "Epoch 20: loss=2.80377197265625\n",
      "Epoch 30: loss=2.556177854537964\n",
      "Epoch 40: loss=2.400383472442627\n",
      "Epoch 50: loss=2.2721052169799805\n",
      "Epoch 60: loss=2.2473297119140625\n",
      "Epoch 70: loss=2.1802990436553955\n",
      "Epoch 80: loss=2.1429171562194824\n",
      "Epoch 90: loss=2.1012110710144043\n",
      "Epoch 100: loss=2.063544750213623\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6766043456291057\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 64):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.702777147293091\n",
      "Epoch 20: loss=2.1028690338134766\n",
      "Epoch 30: loss=1.886475682258606\n",
      "Epoch 40: loss=1.7815150022506714\n",
      "Epoch 50: loss=1.682851791381836\n",
      "Epoch 60: loss=1.6530952453613281\n",
      "Epoch 70: loss=1.6239185333251953\n",
      "Epoch 80: loss=1.590145230293274\n",
      "Epoch 90: loss=1.5726836919784546\n",
      "Epoch 100: loss=1.5565924644470215\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7064173825164224\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.0323123931884766\n",
      "Epoch 20: loss=2.4331090450286865\n",
      "Epoch 30: loss=2.183164119720459\n",
      "Epoch 40: loss=2.020674467086792\n",
      "Epoch 50: loss=1.9529600143432617\n",
      "Epoch 60: loss=1.8809360265731812\n",
      "Epoch 70: loss=1.8341727256774902\n",
      "Epoch 80: loss=1.7954611778259277\n",
      "Epoch 90: loss=1.7827727794647217\n",
      "Epoch 100: loss=1.7492016553878784\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6917635169277413\n",
      "------------------------------------------\n",
      "Model with hidden size(64, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.3165810108184814\n",
      "Epoch 20: loss=2.8554141521453857\n",
      "Epoch 30: loss=2.5979220867156982\n",
      "Epoch 40: loss=2.4372050762176514\n",
      "Epoch 50: loss=2.349764347076416\n",
      "Epoch 60: loss=2.281712293624878\n",
      "Epoch 70: loss=2.253727436065674\n",
      "Epoch 80: loss=2.189382553100586\n",
      "Epoch 90: loss=2.158414125442505\n",
      "Epoch 100: loss=2.1564409732818604\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6654876200101061\n",
      "------------------------------------------\n",
      "Model with hidden size(32, 32):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.269489049911499\n",
      "Epoch 20: loss=2.623661994934082\n",
      "Epoch 30: loss=2.33941388130188\n",
      "Epoch 40: loss=2.219449996948242\n",
      "Epoch 50: loss=2.135676860809326\n",
      "Epoch 60: loss=2.0568196773529053\n",
      "Epoch 70: loss=2.000635862350464\n",
      "Epoch 80: loss=1.9928255081176758\n",
      "Epoch 90: loss=1.9520196914672852\n",
      "Epoch 100: loss=1.9332880973815918\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6947953511874684\n",
      "------------------------------------------\n",
      "Model with hidden size(32, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.608206272125244\n",
      "Epoch 20: loss=3.133857250213623\n",
      "Epoch 30: loss=2.8435940742492676\n",
      "Epoch 40: loss=2.6483066082000732\n",
      "Epoch 50: loss=2.5485341548919678\n",
      "Epoch 60: loss=2.4727227687835693\n",
      "Epoch 70: loss=2.416548728942871\n",
      "Epoch 80: loss=2.3649346828460693\n",
      "Epoch 90: loss=2.337877035140991\n",
      "Epoch 100: loss=2.306093692779541\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6589186457806974\n",
      "------------------------------------------\n",
      "Model with hidden size(16, 16):\n",
      "\n",
      "...Training Start...\n",
      "Epoch 10: loss=3.727335214614868\n",
      "Epoch 20: loss=3.2891383171081543\n",
      "Epoch 30: loss=3.0051400661468506\n",
      "Epoch 40: loss=2.8550498485565186\n",
      "Epoch 50: loss=2.730518102645874\n",
      "Epoch 60: loss=2.652587413787842\n",
      "Epoch 70: loss=2.61136794090271\n",
      "Epoch 80: loss=2.609982967376709\n",
      "Epoch 90: loss=2.572977304458618\n",
      "Epoch 100: loss=2.536597728729248\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6291056088933805\n",
      "------------------------------------------\n",
      "Best model with hidden size(64,64): Test accuracy= 0.6928517302349078\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "num_heads = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Train and evaluate GAT with variable attention heads\n",
    "best_accuracy = 0.0\n",
    "best_num_heads = None\n",
    "best_model = None\n",
    "best_acc = None\n",
    "\n",
    "for num_head in num_heads:\n",
    "\n",
    "  # Define model\n",
    "  model = GATv2ThreeLayers(dataset.num_features, best_hid1, best_hid2, dataset.num_classes, num_heads=num_head)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  print(f\"Attention-heads: {num_head}\")\n",
    "  print(f\"...Training Start...\")\n",
    "\n",
    "  # Training\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "      optimizer.zero_grad()\n",
    "      out = model(dataset)\n",
    "      loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Printing Every 10 epochs\n",
    "      if ((epoch+1) % 10) == 0 or epoch+1 == epochs:\n",
    "        print(f\"Epoch {epoch+1}: loss={loss.item()}\")\n",
    "\n",
    "  # Evaluation\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      logits = model(dataset)\n",
    "      _, predicted = logits.max(dim=1)\n",
    "      correct = predicted[dataset.val_mask] == dataset.y[dataset.val_mask]\n",
    "      acc = correct.sum().item() / dataset.val_mask.sum().item()\n",
    "\n",
    "  print(f\"...Training End...\")\n",
    "  print(f\"\\nValidation accuracy= {acc}\")\n",
    "  print(\"------------------------------------------\")\n",
    "\n",
    "  # Updateing best model\n",
    "  if best_model is None:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "  if acc > best_acc:\n",
    "    best_model = model\n",
    "    best_acc = acc\n",
    "    best_num_heads = num_head\n",
    "\n",
    "# Test Evaluation for the Best Model\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = best_model(dataset)\n",
    "    _, predicted = logits.max(dim=1)\n",
    "    correct = predicted[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "    acc = correct.sum().item() / dataset.test_mask.sum().item()\n",
    "\n",
    "print(f'Best GATv2ThreeLayers with Variable Attention Heads({best_num_heads}) Test Accuracy : {acc}')"
   ],
   "metadata": {
    "id": "agg1EZqQlaSZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention-heads: 1\n",
      "...Training Start...\n",
      "Epoch 10: loss=2.6765100955963135\n",
      "Epoch 20: loss=2.082151174545288\n",
      "Epoch 30: loss=1.8728524446487427\n",
      "Epoch 40: loss=1.7698818445205688\n",
      "Epoch 50: loss=1.7091933488845825\n",
      "Epoch 60: loss=1.6560806035995483\n",
      "Epoch 70: loss=1.6312350034713745\n",
      "Epoch 80: loss=1.6096343994140625\n",
      "Epoch 90: loss=1.582025170326233\n",
      "Epoch 100: loss=1.5414514541625977\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.7033855482566953\n",
      "------------------------------------------\n",
      "Attention-heads: 2\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.975282073020935\n",
      "Epoch 20: loss=1.4035160541534424\n",
      "Epoch 30: loss=1.1806517839431763\n",
      "Epoch 40: loss=1.0723105669021606\n",
      "Epoch 50: loss=0.9808129072189331\n",
      "Epoch 60: loss=0.9267470240592957\n",
      "Epoch 70: loss=0.8883423805236816\n",
      "Epoch 80: loss=0.8573037981987\n",
      "Epoch 90: loss=0.8395189642906189\n",
      "Epoch 100: loss=0.8263108730316162\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6927741283476503\n",
      "------------------------------------------\n",
      "Attention-heads: 3\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.6434965133666992\n",
      "Epoch 20: loss=1.1073845624923706\n",
      "Epoch 30: loss=0.8767632842063904\n",
      "Epoch 40: loss=0.759726345539093\n",
      "Epoch 50: loss=0.6797785758972168\n",
      "Epoch 60: loss=0.6313177347183228\n",
      "Epoch 70: loss=0.5999974012374878\n",
      "Epoch 80: loss=0.5807457566261292\n",
      "Epoch 90: loss=0.5657445788383484\n",
      "Epoch 100: loss=0.5443435311317444\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6922688226376958\n",
      "------------------------------------------\n",
      "Attention-heads: 4\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.5554873943328857\n",
      "Epoch 20: loss=1.032480239868164\n",
      "Epoch 30: loss=0.7801548838615417\n",
      "Epoch 40: loss=0.6337361335754395\n",
      "Epoch 50: loss=0.549951434135437\n",
      "Epoch 60: loss=0.486005961894989\n",
      "Epoch 70: loss=0.47094136476516724\n",
      "Epoch 80: loss=0.4507872760295868\n",
      "Epoch 90: loss=0.4309007525444031\n",
      "Epoch 100: loss=0.4287930130958557\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6912582112177867\n",
      "------------------------------------------\n",
      "Attention-heads: 5\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.4615956544876099\n",
      "Epoch 20: loss=0.9357043504714966\n",
      "Epoch 30: loss=0.6702471375465393\n",
      "Epoch 40: loss=0.5443724393844604\n",
      "Epoch 50: loss=0.4602690041065216\n",
      "Epoch 60: loss=0.3916797637939453\n",
      "Epoch 70: loss=0.3793473541736603\n",
      "Epoch 80: loss=0.3468145728111267\n",
      "Epoch 90: loss=0.33975300192832947\n",
      "Epoch 100: loss=0.3269914388656616\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6887316826680141\n",
      "------------------------------------------\n",
      "Attention-heads: 6\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.5257272720336914\n",
      "Epoch 20: loss=0.9464277029037476\n",
      "Epoch 30: loss=0.6604878306388855\n",
      "Epoch 40: loss=0.5119032859802246\n",
      "Epoch 50: loss=0.4161112606525421\n",
      "Epoch 60: loss=0.3659280240535736\n",
      "Epoch 70: loss=0.3378177881240845\n",
      "Epoch 80: loss=0.3237256407737732\n",
      "Epoch 90: loss=0.29505035281181335\n",
      "Epoch 100: loss=0.2770504951477051\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6816574027286508\n",
      "------------------------------------------\n",
      "Attention-heads: 7\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.4751815795898438\n",
      "Epoch 20: loss=0.9037154912948608\n",
      "Epoch 30: loss=0.6321835517883301\n",
      "Epoch 40: loss=0.47318223118782043\n",
      "Epoch 50: loss=0.39094310998916626\n",
      "Epoch 60: loss=0.3253032863140106\n",
      "Epoch 70: loss=0.29809215664863586\n",
      "Epoch 80: loss=0.2732599079608917\n",
      "Epoch 90: loss=0.2523479163646698\n",
      "Epoch 100: loss=0.2350827157497406\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6887316826680141\n",
      "------------------------------------------\n",
      "Attention-heads: 8\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.4714215993881226\n",
      "Epoch 20: loss=0.8610822558403015\n",
      "Epoch 30: loss=0.5772770643234253\n",
      "Epoch 40: loss=0.4250261187553406\n",
      "Epoch 50: loss=0.32918843626976013\n",
      "Epoch 60: loss=0.2774699628353119\n",
      "Epoch 70: loss=0.25340935587882996\n",
      "Epoch 80: loss=0.23069892823696136\n",
      "Epoch 90: loss=0.22034317255020142\n",
      "Epoch 100: loss=0.2222166508436203\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6902475997978778\n",
      "------------------------------------------\n",
      "Attention-heads: 9\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.6134544610977173\n",
      "Epoch 20: loss=0.9261569976806641\n",
      "Epoch 30: loss=0.615123450756073\n",
      "Epoch 40: loss=0.42422428727149963\n",
      "Epoch 50: loss=0.3375091850757599\n",
      "Epoch 60: loss=0.28075462579727173\n",
      "Epoch 70: loss=0.24851152300834656\n",
      "Epoch 80: loss=0.22654356062412262\n",
      "Epoch 90: loss=0.21091999113559723\n",
      "Epoch 100: loss=0.1944429576396942\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6862051541182416\n",
      "------------------------------------------\n",
      "Attention-heads: 10\n",
      "...Training Start...\n",
      "Epoch 10: loss=1.9371201992034912\n",
      "Epoch 20: loss=1.126597285270691\n",
      "Epoch 30: loss=0.7436952590942383\n",
      "Epoch 40: loss=0.5308157801628113\n",
      "Epoch 50: loss=0.4049859344959259\n",
      "Epoch 60: loss=0.31688499450683594\n",
      "Epoch 70: loss=0.26664456725120544\n",
      "Epoch 80: loss=0.2340935617685318\n",
      "Epoch 90: loss=0.21945606172084808\n",
      "Epoch 100: loss=0.19318290054798126\n",
      "...Training End...\n",
      "\n",
      "Validation accuracy= 0.6907529055078322\n",
      "------------------------------------------\n",
      "Best GATv2ThreeLayers with Variable Attention Heads(1) Test Accuracy : 0.6966405657994443\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "82_Q2Jwuuqg4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}